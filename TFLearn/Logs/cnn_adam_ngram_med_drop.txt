Training Step: 108  | total loss: 1.58794 | time: 9.909s
| Adam | epoch: 001 | loss: 1.58794 - acc: 0.3878 | val_loss: 1.58290 - val_acc: 0.3780 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 216  | total loss: 1.46185 | time: 9.406s
| Adam | epoch: 002 | loss: 1.46185 - acc: 0.4311 | val_loss: 1.49219 - val_acc: 0.4304 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 324  | total loss: 1.29604 | time: 9.170s
| Adam | epoch: 003 | loss: 1.29604 - acc: 0.5234 | val_loss: 1.42513 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 432  | total loss: 1.02633 | time: 9.072s
| Adam | epoch: 004 | loss: 1.02633 - acc: 0.6313 | val_loss: 1.35665 - val_acc: 0.5171 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 540  | total loss: 0.70113 | time: 9.083s
| Adam | epoch: 005 | loss: 0.70113 - acc: 0.7496 | val_loss: 1.31099 - val_acc: 0.5276 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 648  | total loss: 0.45548 | time: 9.051s
| Adam | epoch: 006 | loss: 0.45548 - acc: 0.8684 | val_loss: 1.40661 - val_acc: 0.5066 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 756  | total loss: 0.29430 | time: 9.082s
| Adam | epoch: 007 | loss: 0.29430 - acc: 0.9189 | val_loss: 1.47038 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 864  | total loss: 0.20761 | time: 9.104s
| Adam | epoch: 008 | loss: 0.20761 - acc: 0.9483 | val_loss: 1.56104 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 972  | total loss: 0.15522 | time: 9.064s
| Adam | epoch: 009 | loss: 0.15522 - acc: 0.9701 | val_loss: 1.63016 - val_acc: 0.4462 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1080  | total loss: 0.08177 | time: 9.109s
| Adam | epoch: 010 | loss: 0.08177 - acc: 0.9856 | val_loss: 1.65208 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1188  | total loss: 0.06855 | time: 9.084s
| Adam | epoch: 011 | loss: 0.06855 - acc: 0.9926 | val_loss: 1.67917 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1296  | total loss: 0.05968 | time: 9.120s
| Adam | epoch: 012 | loss: 0.05968 - acc: 0.9989 | val_loss: 1.70807 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1404  | total loss: 0.05235 | time: 9.020s
| Adam | epoch: 013 | loss: 0.05235 - acc: 0.9979 | val_loss: 1.72365 - val_acc: 0.4777 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1512  | total loss: 0.04110 | time: 9.043s
| Adam | epoch: 014 | loss: 0.04110 - acc: 0.9982 | val_loss: 1.74744 - val_acc: 0.4803 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1620  | total loss: 0.03558 | time: 9.024s
| Adam | epoch: 015 | loss: 0.03558 - acc: 0.9957 | val_loss: 1.76629 - val_acc: 0.4934 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1728  | total loss: 0.03185 | time: 9.046s
| Adam | epoch: 016 | loss: 0.03185 - acc: 0.9978 | val_loss: 1.76003 - val_acc: 0.4934 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1836  | total loss: 0.02739 | time: 9.033s
| Adam | epoch: 017 | loss: 0.02739 - acc: 1.0000 | val_loss: 1.79256 - val_acc: 0.4882 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1944  | total loss: 0.02607 | time: 9.017s
| Adam | epoch: 018 | loss: 0.02607 - acc: 0.9990 | val_loss: 1.80741 - val_acc: 0.4856 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2052  | total loss: 0.02458 | time: 9.040s
| Adam | epoch: 019 | loss: 0.02458 - acc: 0.9995 | val_loss: 1.84701 - val_acc: 0.4882 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2160  | total loss: 0.02360 | time: 9.023s
| Adam | epoch: 020 | loss: 0.02360 - acc: 1.0000 | val_loss: 1.85419 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2268  | total loss: 0.02076 | time: 9.051s
| Adam | epoch: 021 | loss: 0.02076 - acc: 0.9988 | val_loss: 1.82867 - val_acc: 0.4829 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2376  | total loss: 0.01861 | time: 9.033s
| Adam | epoch: 022 | loss: 0.01861 - acc: 0.9993 | val_loss: 1.84878 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2484  | total loss: 0.01584 | time: 9.049s
| Adam | epoch: 023 | loss: 0.01584 - acc: 0.9996 | val_loss: 1.87052 - val_acc: 0.4803 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2592  | total loss: 0.01892 | time: 9.054s
| Adam | epoch: 024 | loss: 0.01892 - acc: 0.9999 | val_loss: 1.87967 - val_acc: 0.4803 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2700  | total loss: 0.01811 | time: 9.072s
| Adam | epoch: 025 | loss: 0.01811 - acc: 0.9970 | val_loss: 1.86694 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2808  | total loss: 0.01227 | time: 9.124s
| Adam | epoch: 026 | loss: 0.01227 - acc: 0.9994 | val_loss: 1.89349 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2916  | total loss: 0.45131 | time: 9.059s
| Adam | epoch: 027 | loss: 0.45131 - acc: 0.9506 | val_loss: 1.70536 - val_acc: 0.4829 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3024  | total loss: 0.01699 | time: 9.052s
| Adam | epoch: 028 | loss: 0.01699 - acc: 0.9987 | val_loss: 1.93435 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3132  | total loss: 0.01221 | time: 9.033s
| Adam | epoch: 029 | loss: 0.01221 - acc: 1.0000 | val_loss: 1.92226 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3240  | total loss: 0.01097 | time: 9.030s
| Adam | epoch: 030 | loss: 0.01097 - acc: 1.0000 | val_loss: 1.96755 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3348  | total loss: 0.00839 | time: 9.033s
| Adam | epoch: 031 | loss: 0.00839 - acc: 1.0000 | val_loss: 1.95234 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3456  | total loss: 0.01013 | time: 9.046s
| Adam | epoch: 032 | loss: 0.01013 - acc: 1.0000 | val_loss: 1.96338 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3564  | total loss: 0.01154 | time: 9.034s
| Adam | epoch: 033 | loss: 0.01154 - acc: 0.9999 | val_loss: 1.98311 - val_acc: 0.4856 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3672  | total loss: 0.00925 | time: 9.021s
| Adam | epoch: 034 | loss: 0.00925 - acc: 1.0000 | val_loss: 1.99318 - val_acc: 0.4724 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3780  | total loss: 0.01067 | time: 9.069s
| Adam | epoch: 035 | loss: 0.01067 - acc: 0.9981 | val_loss: 1.99156 - val_acc: 0.4856 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3888  | total loss: 0.01791 | time: 9.046s
| Adam | epoch: 036 | loss: 0.01791 - acc: 0.9970 | val_loss: 2.04647 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3996  | total loss: 0.00812 | time: 9.028s
| Adam | epoch: 037 | loss: 0.00812 - acc: 0.9996 | val_loss: 2.01820 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4104  | total loss: 0.00679 | time: 9.013s
| Adam | epoch: 038 | loss: 0.00679 - acc: 0.9997 | val_loss: 2.04511 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4212  | total loss: 0.00610 | time: 9.039s
| Adam | epoch: 039 | loss: 0.00610 - acc: 0.9997 | val_loss: 2.05345 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4320  | total loss: 0.00826 | time: 9.077s
| Adam | epoch: 040 | loss: 0.00826 - acc: 0.9999 | val_loss: 2.03771 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4428  | total loss: 0.00925 | time: 9.065s
| Adam | epoch: 041 | loss: 0.00925 - acc: 0.9999 | val_loss: 2.05346 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4536  | total loss: 0.00830 | time: 9.031s
| Adam | epoch: 042 | loss: 0.00830 - acc: 0.9998 | val_loss: 2.04128 - val_acc: 0.4409 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4644  | total loss: 0.00516 | time: 9.018s
| Adam | epoch: 043 | loss: 0.00516 - acc: 0.9996 | val_loss: 2.05183 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4752  | total loss: 0.00568 | time: 9.039s
| Adam | epoch: 044 | loss: 0.00568 - acc: 1.0000 | val_loss: 2.06645 - val_acc: 0.4462 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4860  | total loss: 0.00666 | time: 9.032s
| Adam | epoch: 045 | loss: 0.00666 - acc: 1.0000 | val_loss: 2.12971 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4968  | total loss: 0.01534 | time: 9.120s
| Adam | epoch: 046 | loss: 0.01534 - acc: 0.9960 | val_loss: 2.27808 - val_acc: 0.4751 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5076  | total loss: 0.00622 | time: 9.498s
| Adam | epoch: 047 | loss: 0.00622 - acc: 0.9997 | val_loss: 2.15831 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5184  | total loss: 0.00542 | time: 9.083s
| Adam | epoch: 048 | loss: 0.00542 - acc: 1.0000 | val_loss: 2.15118 - val_acc: 0.4383 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5292  | total loss: 0.00513 | time: 9.029s
| Adam | epoch: 049 | loss: 0.00513 - acc: 1.0000 | val_loss: 2.09491 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5400  | total loss: 0.00648 | time: 9.047s
| Adam | epoch: 050 | loss: 0.00648 - acc: 1.0000 | val_loss: 2.10302 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5508  | total loss: 0.00498 | time: 9.025s
| Adam | epoch: 051 | loss: 0.00498 - acc: 1.0000 | val_loss: 2.12461 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5616  | total loss: 0.00561 | time: 9.016s
| Adam | epoch: 052 | loss: 0.00561 - acc: 1.0000 | val_loss: 2.11563 - val_acc: 0.4462 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5724  | total loss: 0.00497 | time: 9.060s
| Adam | epoch: 053 | loss: 0.00497 - acc: 1.0000 | val_loss: 2.08821 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5832  | total loss: 0.00390 | time: 9.058s
| Adam | epoch: 054 | loss: 0.00390 - acc: 1.0000 | val_loss: 2.08893 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5940  | total loss: 0.00466 | time: 9.027s
| Adam | epoch: 055 | loss: 0.00466 - acc: 1.0000 | val_loss: 2.11120 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6048  | total loss: 0.00388 | time: 9.012s
| Adam | epoch: 056 | loss: 0.00388 - acc: 1.0000 | val_loss: 2.11341 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6156  | total loss: 0.00357 | time: 9.031s
| Adam | epoch: 057 | loss: 0.00357 - acc: 1.0000 | val_loss: 2.09892 - val_acc: 0.4724 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6264  | total loss: 0.00362 | time: 9.034s
| Adam | epoch: 058 | loss: 0.00362 - acc: 1.0000 | val_loss: 2.10191 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6372  | total loss: 0.00283 | time: 9.186s
| Adam | epoch: 059 | loss: 0.00283 - acc: 1.0000 | val_loss: 2.10878 - val_acc: 0.4777 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6480  | total loss: 0.00384 | time: 9.625s
| Adam | epoch: 060 | loss: 0.00384 - acc: 1.0000 | val_loss: 2.14653 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6588  | total loss: 0.00287 | time: 9.430s
| Adam | epoch: 061 | loss: 0.00287 - acc: 1.0000 | val_loss: 2.12245 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6696  | total loss: 0.00382 | time: 9.093s
| Adam | epoch: 062 | loss: 0.00382 - acc: 1.0000 | val_loss: 2.16014 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6804  | total loss: 0.00280 | time: 9.053s
| Adam | epoch: 063 | loss: 0.00280 - acc: 1.0000 | val_loss: 2.21334 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6912  | total loss: 0.00282 | time: 9.120s
| Adam | epoch: 064 | loss: 0.00282 - acc: 1.0000 | val_loss: 2.21062 - val_acc: 0.4436 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7020  | total loss: 0.00272 | time: 9.046s
| Adam | epoch: 065 | loss: 0.00272 - acc: 1.0000 | val_loss: 2.11790 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7128  | total loss: 0.00197 | time: 9.039s
| Adam | epoch: 066 | loss: 0.00197 - acc: 1.0000 | val_loss: 2.16828 - val_acc: 0.4462 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7236  | total loss: 0.00262 | time: 9.012s
| Adam | epoch: 067 | loss: 0.00262 - acc: 1.0000 | val_loss: 2.15845 - val_acc: 0.4383 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7344  | total loss: 0.00187 | time: 9.037s
| Adam | epoch: 068 | loss: 0.00187 - acc: 1.0000 | val_loss: 2.17295 - val_acc: 0.4724 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7452  | total loss: 0.00324 | time: 9.027s
| Adam | epoch: 069 | loss: 0.00324 - acc: 0.9999 | val_loss: 2.22168 - val_acc: 0.4488 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7560  | total loss: 0.00324 | time: 9.033s
| Adam | epoch: 070 | loss: 0.00324 - acc: 1.0000 | val_loss: 2.26262 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7668  | total loss: 0.00266 | time: 9.018s
| Adam | epoch: 071 | loss: 0.00266 - acc: 1.0000 | val_loss: 2.28762 - val_acc: 0.4436 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7776  | total loss: 0.00262 | time: 9.034s
| Adam | epoch: 072 | loss: 0.00262 - acc: 1.0000 | val_loss: 2.32012 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7884  | total loss: 0.00273 | time: 9.040s
| Adam | epoch: 073 | loss: 0.00273 - acc: 1.0000 | val_loss: 2.24004 - val_acc: 0.4462 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7992  | total loss: 0.00178 | time: 9.033s
| Adam | epoch: 074 | loss: 0.00178 - acc: 1.0000 | val_loss: 2.21751 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8100  | total loss: 0.00230 | time: 9.020s
| Adam | epoch: 075 | loss: 0.00230 - acc: 1.0000 | val_loss: 2.28619 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8208  | total loss: 0.00207 | time: 9.033s
| Adam | epoch: 076 | loss: 0.00207 - acc: 1.0000 | val_loss: 2.33340 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8316  | total loss: 0.00238 | time: 9.042s
| Adam | epoch: 077 | loss: 0.00238 - acc: 1.0000 | val_loss: 2.30389 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8424  | total loss: 0.00200 | time: 9.022s
| Adam | epoch: 078 | loss: 0.00200 - acc: 1.0000 | val_loss: 2.36616 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8532  | total loss: 0.00179 | time: 9.009s
| Adam | epoch: 079 | loss: 0.00179 - acc: 1.0000 | val_loss: 2.22765 - val_acc: 0.4751 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8640  | total loss: 0.01161 | time: 9.016s
| Adam | epoch: 080 | loss: 0.01161 - acc: 0.9970 | val_loss: 3.10504 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8748  | total loss: 0.00205 | time: 9.105s
| Adam | epoch: 081 | loss: 0.00205 - acc: 1.0000 | val_loss: 3.07146 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8856  | total loss: 0.00157 | time: 9.059s
| Adam | epoch: 082 | loss: 0.00157 - acc: 1.0000 | val_loss: 2.80185 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8964  | total loss: 0.02368 | time: 9.029s
| Adam | epoch: 083 | loss: 0.02368 - acc: 0.9970 | val_loss: 2.52976 - val_acc: 0.4462 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9072  | total loss: 0.00184 | time: 8.991s
| Adam | epoch: 084 | loss: 0.00184 - acc: 1.0000 | val_loss: 2.69609 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9180  | total loss: 0.00348 | time: 9.060s
| Adam | epoch: 085 | loss: 0.00348 - acc: 1.0000 | val_loss: 2.61020 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9288  | total loss: 0.00130 | time: 9.029s
| Adam | epoch: 086 | loss: 0.00130 - acc: 0.9999 | val_loss: 2.52582 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9396  | total loss: 0.00191 | time: 9.004s
| Adam | epoch: 087 | loss: 0.00191 - acc: 1.0000 | val_loss: 2.42233 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9504  | total loss: 0.00173 | time: 9.023s
| Adam | epoch: 088 | loss: 0.00173 - acc: 1.0000 | val_loss: 2.39775 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9612  | total loss: 0.00169 | time: 8.997s
| Adam | epoch: 089 | loss: 0.00169 - acc: 1.0000 | val_loss: 2.36289 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9720  | total loss: 0.00174 | time: 9.008s
| Adam | epoch: 090 | loss: 0.00174 - acc: 1.0000 | val_loss: 2.33949 - val_acc: 0.4436 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9828  | total loss: 0.00134 | time: 9.014s
| Adam | epoch: 091 | loss: 0.00134 - acc: 1.0000 | val_loss: 2.35844 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9936  | total loss: 0.00130 | time: 9.012s
| Adam | epoch: 092 | loss: 0.00130 - acc: 1.0000 | val_loss: 2.35024 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10044  | total loss: 0.00172 | time: 9.026s
| Adam | epoch: 093 | loss: 0.00172 - acc: 1.0000 | val_loss: 2.33022 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10152  | total loss: 0.00159 | time: 9.640s
| Adam | epoch: 094 | loss: 0.00159 - acc: 1.0000 | val_loss: 2.31748 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10260  | total loss: 0.00148 | time: 9.080s
| Adam | epoch: 095 | loss: 0.00148 - acc: 1.0000 | val_loss: 2.31229 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10368  | total loss: 0.00139 | time: 9.020s
| Adam | epoch: 096 | loss: 0.00139 - acc: 1.0000 | val_loss: 2.28527 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10476  | total loss: 0.00124 | time: 8.991s
| Adam | epoch: 097 | loss: 0.00124 - acc: 1.0000 | val_loss: 2.35098 - val_acc: 0.4436 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10584  | total loss: 0.00122 | time: 8.996s
| Adam | epoch: 098 | loss: 0.00122 - acc: 1.0000 | val_loss: 2.35761 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10692  | total loss: 0.02343 | time: 8.976s
| Adam | epoch: 099 | loss: 0.02343 - acc: 0.9971 | val_loss: 3.03180 - val_acc: 0.4436 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10800  | total loss: 0.00435 | time: 8.999s
| Adam | epoch: 100 | loss: 0.00435 - acc: 0.9990 | val_loss: 3.58695 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

