Training Step: 107  | total loss: 1.60268 | time: 77.409s
| Adam | epoch: 001 | loss: 1.60268 - acc: 0.3548 | val_loss: 1.61748 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 214  | total loss: 1.60187 | time: 27.205s
| Adam | epoch: 002 | loss: 1.60187 - acc: 0.3415 | val_loss: 1.61997 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 321  | total loss: 1.61986 | time: 26.741s
| Adam | epoch: 003 | loss: 1.61986 - acc: 0.3140 | val_loss: 1.61230 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 428  | total loss: 1.62157 | time: 26.544s
| Adam | epoch: 004 | loss: 1.62157 - acc: 0.3339 | val_loss: 1.61448 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 535  | total loss: 1.58893 | time: 26.350s
| Adam | epoch: 005 | loss: 1.58893 - acc: 0.3667 | val_loss: 1.62122 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 642  | total loss: 1.59730 | time: 25.851s
| Adam | epoch: 006 | loss: 1.59730 - acc: 0.3561 | val_loss: 1.61248 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 749  | total loss: 1.61141 | time: 25.597s
| Adam | epoch: 007 | loss: 1.61141 - acc: 0.3378 | val_loss: 1.61685 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 856  | total loss: 1.59693 | time: 25.568s
| Adam | epoch: 008 | loss: 1.59693 - acc: 0.3498 | val_loss: 1.61797 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 963  | total loss: 1.61255 | time: 26.700s
| Adam | epoch: 009 | loss: 1.61255 - acc: 0.3284 | val_loss: 1.61311 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1070  | total loss: 1.59413 | time: 25.554s
| Adam | epoch: 010 | loss: 1.59413 - acc: 0.3364 | val_loss: 1.61430 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1177  | total loss: 1.58778 | time: 25.571s
| Adam | epoch: 011 | loss: 1.58778 - acc: 0.3422 | val_loss: 1.61706 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1284  | total loss: 1.60183 | time: 26.705s
| Adam | epoch: 012 | loss: 1.60183 - acc: 0.3379 | val_loss: 1.61671 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1391  | total loss: 1.62748 | time: 26.579s
| Adam | epoch: 013 | loss: 1.62748 - acc: 0.3644 | val_loss: 1.62060 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1498  | total loss: 1.61702 | time: 25.779s
| Adam | epoch: 014 | loss: 1.61702 - acc: 0.3332 | val_loss: 1.60931 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1605  | total loss: 1.60771 | time: 26.691s
| Adam | epoch: 015 | loss: 1.60771 - acc: 0.3587 | val_loss: 1.61990 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1712  | total loss: 1.60096 | time: 26.560s
| Adam | epoch: 016 | loss: 1.60096 - acc: 0.3489 | val_loss: 1.60996 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1819  | total loss: 1.63331 | time: 25.615s
| Adam | epoch: 017 | loss: 1.63331 - acc: 0.3487 | val_loss: 1.61180 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1926  | total loss: 1.60918 | time: 24.544s
| Adam | epoch: 018 | loss: 1.60918 - acc: 0.3388 | val_loss: 1.61051 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2033  | total loss: 1.58394 | time: 28.117s
| Adam | epoch: 019 | loss: 1.58394 - acc: 0.3575 | val_loss: 1.61710 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2140  | total loss: 1.65733 | time: 26.147s
| Adam | epoch: 020 | loss: 1.65733 - acc: 0.3151 | val_loss: 1.61422 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2247  | total loss: 1.54826 | time: 26.627s
| Adam | epoch: 021 | loss: 1.54826 - acc: 0.3573 | val_loss: 1.61997 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2354  | total loss: 1.56236 | time: 26.386s
| Adam | epoch: 022 | loss: 1.56236 - acc: 0.3886 | val_loss: 1.62016 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2461  | total loss: 1.59280 | time: 26.983s
| Adam | epoch: 023 | loss: 1.59280 - acc: 0.3496 | val_loss: 1.61565 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2568  | total loss: 1.60166 | time: 25.548s
| Adam | epoch: 024 | loss: 1.60166 - acc: 0.3642 | val_loss: 1.61317 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2675  | total loss: 1.59063 | time: 25.950s
| Adam | epoch: 025 | loss: 1.59063 - acc: 0.3321 | val_loss: 1.61323 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2782  | total loss: 1.60604 | time: 25.371s
| Adam | epoch: 026 | loss: 1.60604 - acc: 0.3355 | val_loss: 1.61482 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2889  | total loss: 1.60121 | time: 26.914s
| Adam | epoch: 027 | loss: 1.60121 - acc: 0.3460 | val_loss: 1.61324 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2996  | total loss: 1.64144 | time: 27.340s
| Adam | epoch: 028 | loss: 1.64144 - acc: 0.3487 | val_loss: 1.61425 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3103  | total loss: 1.61476 | time: 26.091s
| Adam | epoch: 029 | loss: 1.61476 - acc: 0.3434 | val_loss: 1.61117 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3210  | total loss: 1.60676 | time: 26.642s
| Adam | epoch: 030 | loss: 1.60676 - acc: 0.3411 | val_loss: 1.61192 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3317  | total loss: 1.59861 | time: 26.358s
| Adam | epoch: 031 | loss: 1.59861 - acc: 0.3540 | val_loss: 1.61212 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3424  | total loss: 1.60904 | time: 26.583s
| Adam | epoch: 032 | loss: 1.60904 - acc: 0.3310 | val_loss: 1.61762 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3531  | total loss: 1.59092 | time: 26.212s
| Adam | epoch: 033 | loss: 1.59092 - acc: 0.3520 | val_loss: 1.61714 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3638  | total loss: 1.61890 | time: 27.086s
| Adam | epoch: 034 | loss: 1.61890 - acc: 0.3295 | val_loss: 1.61313 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3745  | total loss: 1.60488 | time: 26.592s
| Adam | epoch: 035 | loss: 1.60488 - acc: 0.3449 | val_loss: 1.61106 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3852  | total loss: 1.57225 | time: 26.069s
| Adam | epoch: 036 | loss: 1.57225 - acc: 0.3846 | val_loss: 1.61802 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3959  | total loss: 1.60007 | time: 26.869s
| Adam | epoch: 037 | loss: 1.60007 - acc: 0.3879 | val_loss: 1.61998 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4066  | total loss: 1.62209 | time: 26.879s
| Adam | epoch: 038 | loss: 1.62209 - acc: 0.3418 | val_loss: 1.61373 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4173  | total loss: 1.59634 | time: 26.168s
| Adam | epoch: 039 | loss: 1.59634 - acc: 0.3694 | val_loss: 1.61857 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4280  | total loss: 1.59830 | time: 25.899s
| Adam | epoch: 040 | loss: 1.59830 - acc: 0.3601 | val_loss: 1.61749 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4387  | total loss: 1.60952 | time: 27.856s
| Adam | epoch: 041 | loss: 1.60952 - acc: 0.3263 | val_loss: 1.61166 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4494  | total loss: 1.57021 | time: 27.636s
| Adam | epoch: 042 | loss: 1.57021 - acc: 0.3419 | val_loss: 1.61758 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4601  | total loss: 1.60240 | time: 26.297s
| Adam | epoch: 043 | loss: 1.60240 - acc: 0.3475 | val_loss: 1.61370 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4708  | total loss: 1.60087 | time: 26.015s
| Adam | epoch: 044 | loss: 1.60087 - acc: 0.3612 | val_loss: 1.61262 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4815  | total loss: 1.59361 | time: 26.840s
| Adam | epoch: 045 | loss: 1.59361 - acc: 0.3429 | val_loss: 1.61479 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4922  | total loss: 1.59134 | time: 26.603s
| Adam | epoch: 046 | loss: 1.59134 - acc: 0.3575 | val_loss: 1.61226 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5029  | total loss: 1.61595 | time: 26.107s
| Adam | epoch: 047 | loss: 1.61595 - acc: 0.3509 | val_loss: 1.61746 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5136  | total loss: 1.62733 | time: 26.003s
| Adam | epoch: 048 | loss: 1.62733 - acc: 0.3442 | val_loss: 1.61644 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5243  | total loss: 1.58580 | time: 26.014s
| Adam | epoch: 049 | loss: 1.58580 - acc: 0.3595 | val_loss: 1.61621 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5350  | total loss: 1.60828 | time: 26.369s
| Adam | epoch: 050 | loss: 1.60828 - acc: 0.3332 | val_loss: 1.61484 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5457  | total loss: 1.54537 | time: 25.139s
| Adam | epoch: 051 | loss: 1.54537 - acc: 0.3838 | val_loss: 1.61904 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5564  | total loss: 1.58953 | time: 26.558s
| Adam | epoch: 052 | loss: 1.58953 - acc: 0.3746 | val_loss: 1.61198 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5671  | total loss: 1.58628 | time: 26.792s
| Adam | epoch: 053 | loss: 1.58628 - acc: 0.3395 | val_loss: 1.61345 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5778  | total loss: 1.63005 | time: 27.629s
| Adam | epoch: 054 | loss: 1.63005 - acc: 0.3337 | val_loss: 1.61454 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5885  | total loss: 1.58388 | time: 28.179s
| Adam | epoch: 055 | loss: 1.58388 - acc: 0.3457 | val_loss: 1.61490 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5992  | total loss: 1.60221 | time: 26.051s
| Adam | epoch: 056 | loss: 1.60221 - acc: 0.3316 | val_loss: 1.61284 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6099  | total loss: 1.62971 | time: 26.419s
| Adam | epoch: 057 | loss: 1.62971 - acc: 0.3426 | val_loss: 1.61372 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6206  | total loss: 1.60748 | time: 27.137s
| Adam | epoch: 058 | loss: 1.60748 - acc: 0.3670 | val_loss: 1.61664 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6313  | total loss: 1.59807 | time: 26.286s
| Adam | epoch: 059 | loss: 1.59807 - acc: 0.3647 | val_loss: 1.61694 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6420  | total loss: 1.59427 | time: 26.494s
| Adam | epoch: 060 | loss: 1.59427 - acc: 0.3503 | val_loss: 1.61269 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6527  | total loss: 1.59684 | time: 26.811s
| Adam | epoch: 061 | loss: 1.59684 - acc: 0.3581 | val_loss: 1.61253 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6634  | total loss: 1.59675 | time: 27.270s
| Adam | epoch: 062 | loss: 1.59675 - acc: 0.3697 | val_loss: 1.61798 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6741  | total loss: 1.59800 | time: 26.900s
| Adam | epoch: 063 | loss: 1.59800 - acc: 0.3767 | val_loss: 1.61556 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6848  | total loss: 1.63090 | time: 26.378s
| Adam | epoch: 064 | loss: 1.63090 - acc: 0.3324 | val_loss: 1.61244 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6955  | total loss: 1.59282 | time: 27.148s
| Adam | epoch: 065 | loss: 1.59282 - acc: 0.3502 | val_loss: 1.61431 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7062  | total loss: 1.60384 | time: 26.299s
| Adam | epoch: 066 | loss: 1.60384 - acc: 0.3482 | val_loss: 1.61848 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7169  | total loss: 1.52945 | time: 27.504s
| Adam | epoch: 067 | loss: 1.52945 - acc: 0.4296 | val_loss: 1.62745 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7276  | total loss: 1.62596 | time: 26.510s
| Adam | epoch: 068 | loss: 1.62596 - acc: 0.3266 | val_loss: 1.58892 - val_acc: 0.3316 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7383  | total loss: 1.58531 | time: 25.245s
| Adam | epoch: 069 | loss: 1.58531 - acc: 0.3757 | val_loss: 1.60136 - val_acc: 0.3316 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7490  | total loss: 1.58021 | time: 25.153s
| Adam | epoch: 070 | loss: 1.58021 - acc: 0.3582 | val_loss: 1.59080 - val_acc: 0.3316 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7597  | total loss: 1.54299 | time: 25.184s
| Adam | epoch: 071 | loss: 1.54299 - acc: 0.3966 | val_loss: 1.59521 - val_acc: 0.3316 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7704  | total loss: 1.53880 | time: 25.436s
| Adam | epoch: 072 | loss: 1.53880 - acc: 0.4032 | val_loss: 1.59476 - val_acc: 0.3263 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7811  | total loss: 1.59815 | time: 27.620s
| Adam | epoch: 073 | loss: 1.59815 - acc: 0.3698 | val_loss: 1.58637 - val_acc: 0.3316 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7918  | total loss: 1.54197 | time: 26.994s
| Adam | epoch: 074 | loss: 1.54197 - acc: 0.3751 | val_loss: 1.58831 - val_acc: 0.3316 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8025  | total loss: 1.54336 | time: 26.704s
| Adam | epoch: 075 | loss: 1.54336 - acc: 0.4228 | val_loss: 1.58677 - val_acc: 0.3316 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8132  | total loss: 1.60050 | time: 26.051s
| Adam | epoch: 076 | loss: 1.60050 - acc: 0.3712 | val_loss: 1.58796 - val_acc: 0.3263 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8239  | total loss: 1.53930 | time: 26.827s
| Adam | epoch: 077 | loss: 1.53930 - acc: 0.3948 | val_loss: 1.59133 - val_acc: 0.3342 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8346  | total loss: 1.57022 | time: 25.950s
| Adam | epoch: 078 | loss: 1.57022 - acc: 0.3638 | val_loss: 1.58377 - val_acc: 0.3316 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8453  | total loss: 1.61055 | time: 26.539s
| Adam | epoch: 079 | loss: 1.61055 - acc: 0.3680 | val_loss: 1.58619 - val_acc: 0.3342 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8560  | total loss: 1.59152 | time: 27.025s
| Adam | epoch: 080 | loss: 1.59152 - acc: 0.3888 | val_loss: 1.57066 - val_acc: 0.3579 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8667  | total loss: 1.50188 | time: 26.615s
| Adam | epoch: 081 | loss: 1.50188 - acc: 0.4388 | val_loss: 1.54563 - val_acc: 0.3816 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8774  | total loss: 1.44393 | time: 25.945s
| Adam | epoch: 082 | loss: 1.44393 - acc: 0.4918 | val_loss: 1.54501 - val_acc: 0.4000 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8881  | total loss: 1.53405 | time: 25.947s
| Adam | epoch: 083 | loss: 1.53405 - acc: 0.4392 | val_loss: 1.55889 - val_acc: 0.4053 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8988  | total loss: 1.54053 | time: 24.857s
| Adam | epoch: 084 | loss: 1.54053 - acc: 0.4184 | val_loss: 1.54839 - val_acc: 0.3895 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9095  | total loss: 1.54341 | time: 26.433s
| Adam | epoch: 085 | loss: 1.54341 - acc: 0.4248 | val_loss: 1.54358 - val_acc: 0.4026 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9202  | total loss: 1.51643 | time: 24.890s
| Adam | epoch: 086 | loss: 1.51643 - acc: 0.4359 | val_loss: 1.55014 - val_acc: 0.4026 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9309  | total loss: 1.55717 | time: 24.585s
| Adam | epoch: 087 | loss: 1.55717 - acc: 0.4161 | val_loss: 1.54843 - val_acc: 0.4079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9416  | total loss: 1.46588 | time: 25.102s
| Adam | epoch: 088 | loss: 1.46588 - acc: 0.4713 | val_loss: 1.55346 - val_acc: 0.4158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9523  | total loss: 1.49156 | time: 24.863s
| Adam | epoch: 089 | loss: 1.49156 - acc: 0.4441 | val_loss: 1.54945 - val_acc: 0.4105 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9630  | total loss: 1.46472 | time: 26.337s
| Adam | epoch: 090 | loss: 1.46472 - acc: 0.4747 | val_loss: 1.55834 - val_acc: 0.4053 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9737  | total loss: 1.51914 | time: 25.805s
| Adam | epoch: 091 | loss: 1.51914 - acc: 0.4148 | val_loss: 1.56869 - val_acc: 0.4026 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9844  | total loss: 1.47160 | time: 24.341s
| Adam | epoch: 092 | loss: 1.47160 - acc: 0.4560 | val_loss: 1.54977 - val_acc: 0.4105 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9951  | total loss: 1.50611 | time: 24.332s
| Adam | epoch: 093 | loss: 1.50611 - acc: 0.4501 | val_loss: 1.55241 - val_acc: 0.4079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10058  | total loss: 1.45290 | time: 24.995s
| Adam | epoch: 094 | loss: 1.45290 - acc: 0.4651 | val_loss: 1.56027 - val_acc: 0.4000 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10165  | total loss: 1.47925 | time: 25.328s
| Adam | epoch: 095 | loss: 1.47925 - acc: 0.4567 | val_loss: 1.53760 - val_acc: 0.4132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10272  | total loss: 1.52651 | time: 25.587s
| Adam | epoch: 096 | loss: 1.52651 - acc: 0.4220 | val_loss: 1.55616 - val_acc: 0.4184 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10379  | total loss: 1.48608 | time: 25.808s
| Adam | epoch: 097 | loss: 1.48608 - acc: 0.4517 | val_loss: 1.54519 - val_acc: 0.4132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10486  | total loss: 1.48316 | time: 25.567s
| Adam | epoch: 098 | loss: 1.48316 - acc: 0.4451 | val_loss: 1.54416 - val_acc: 0.4079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10593  | total loss: 1.44796 | time: 25.497s
| Adam | epoch: 099 | loss: 1.44796 - acc: 0.4506 | val_loss: 1.53927 - val_acc: 0.4105 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10700  | total loss: 1.44880 | time: 24.472s
| Adam | epoch: 100 | loss: 1.44880 - acc: 0.4777 | val_loss: 1.54519 - val_acc: 0.4184 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

