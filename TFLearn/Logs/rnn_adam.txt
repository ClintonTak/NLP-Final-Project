Training Step: 108  | total loss: 1.60526 | time: 71.587s
| Adam | epoch: 001 | loss: 1.60526 - acc: 0.3519 | val_loss: 1.61598 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 216  | total loss: 1.60657 | time: 23.534s
| Adam | epoch: 002 | loss: 1.60657 - acc: 0.3499 | val_loss: 1.61303 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 324  | total loss: 1.61180 | time: 23.319s
| Adam | epoch: 003 | loss: 1.61180 - acc: 0.3612 | val_loss: 1.61942 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 432  | total loss: 1.61883 | time: 23.255s
| Adam | epoch: 004 | loss: 1.61883 - acc: 0.3414 | val_loss: 1.61270 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 540  | total loss: 1.60823 | time: 23.070s
| Adam | epoch: 005 | loss: 1.60823 - acc: 0.3247 | val_loss: 1.61097 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 648  | total loss: 1.62267 | time: 23.011s
| Adam | epoch: 006 | loss: 1.62267 - acc: 0.3361 | val_loss: 1.61325 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 756  | total loss: 1.60322 | time: 23.098s
| Adam | epoch: 007 | loss: 1.60322 - acc: 0.3678 | val_loss: 1.61119 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 864  | total loss: 1.60838 | time: 23.036s
| Adam | epoch: 008 | loss: 1.60838 - acc: 0.3551 | val_loss: 1.61302 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 972  | total loss: 1.60128 | time: 23.128s
| Adam | epoch: 009 | loss: 1.60128 - acc: 0.3459 | val_loss: 1.61271 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1080  | total loss: 1.62878 | time: 23.089s
| Adam | epoch: 010 | loss: 1.62878 - acc: 0.3181 | val_loss: 1.61501 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1188  | total loss: 1.62618 | time: 23.095s
| Adam | epoch: 011 | loss: 1.62618 - acc: 0.3190 | val_loss: 1.61369 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1296  | total loss: 1.61880 | time: 23.086s
| Adam | epoch: 012 | loss: 1.61880 - acc: 0.3187 | val_loss: 1.61240 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1404  | total loss: 1.63685 | time: 23.059s
| Adam | epoch: 013 | loss: 1.63685 - acc: 0.3421 | val_loss: 1.61686 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1512  | total loss: 1.57590 | time: 23.128s
| Adam | epoch: 014 | loss: 1.57590 - acc: 0.3547 | val_loss: 1.61339 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1620  | total loss: 1.57711 | time: 23.072s
| Adam | epoch: 015 | loss: 1.57711 - acc: 0.3546 | val_loss: 1.61223 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1728  | total loss: 1.56830 | time: 23.061s
| Adam | epoch: 016 | loss: 1.56830 - acc: 0.3772 | val_loss: 1.61703 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1836  | total loss: 1.58709 | time: 23.066s
| Adam | epoch: 017 | loss: 1.58709 - acc: 0.3372 | val_loss: 1.61197 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1944  | total loss: 1.58409 | time: 23.056s
| Adam | epoch: 018 | loss: 1.58409 - acc: 0.3609 | val_loss: 1.61412 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2052  | total loss: 1.60272 | time: 23.026s
| Adam | epoch: 019 | loss: 1.60272 - acc: 0.3635 | val_loss: 1.61464 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2160  | total loss: 1.64518 | time: 23.035s
| Adam | epoch: 020 | loss: 1.64518 - acc: 0.3292 | val_loss: 1.61332 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2268  | total loss: 1.62345 | time: 23.013s
| Adam | epoch: 021 | loss: 1.62345 - acc: 0.3401 | val_loss: 1.61423 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2376  | total loss: 1.57191 | time: 23.090s
| Adam | epoch: 022 | loss: 1.57191 - acc: 0.3760 | val_loss: 1.61423 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2484  | total loss: 1.59413 | time: 23.040s
| Adam | epoch: 023 | loss: 1.59413 - acc: 0.3270 | val_loss: 1.61374 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2592  | total loss: 1.59411 | time: 23.142s
| Adam | epoch: 024 | loss: 1.59411 - acc: 0.3718 | val_loss: 1.61497 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2700  | total loss: 1.59846 | time: 22.999s
| Adam | epoch: 025 | loss: 1.59846 - acc: 0.3413 | val_loss: 1.61465 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2808  | total loss: 1.59365 | time: 23.061s
| Adam | epoch: 026 | loss: 1.59365 - acc: 0.3658 | val_loss: 1.61268 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2916  | total loss: 1.60768 | time: 22.998s
| Adam | epoch: 027 | loss: 1.60768 - acc: 0.3118 | val_loss: 1.61307 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3024  | total loss: 1.60074 | time: 23.037s
| Adam | epoch: 028 | loss: 1.60074 - acc: 0.3428 | val_loss: 1.61462 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3132  | total loss: 1.57495 | time: 23.045s
| Adam | epoch: 029 | loss: 1.57495 - acc: 0.3715 | val_loss: 1.61521 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3240  | total loss: 1.61070 | time: 23.094s
| Adam | epoch: 030 | loss: 1.61070 - acc: 0.3326 | val_loss: 1.61202 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3348  | total loss: 1.57405 | time: 23.052s
| Adam | epoch: 031 | loss: 1.57405 - acc: 0.3882 | val_loss: 1.61359 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3456  | total loss: 1.59890 | time: 23.014s
| Adam | epoch: 032 | loss: 1.59890 - acc: 0.3560 | val_loss: 1.61269 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3564  | total loss: 1.61713 | time: 23.062s
| Adam | epoch: 033 | loss: 1.61713 - acc: 0.3290 | val_loss: 1.61369 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3672  | total loss: 1.65569 | time: 23.004s
| Adam | epoch: 034 | loss: 1.65569 - acc: 0.3121 | val_loss: 1.61397 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3780  | total loss: 1.61248 | time: 23.098s
| Adam | epoch: 035 | loss: 1.61248 - acc: 0.3462 | val_loss: 1.61352 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3888  | total loss: 1.57273 | time: 23.021s
| Adam | epoch: 036 | loss: 1.57273 - acc: 0.3593 | val_loss: 1.61453 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3996  | total loss: 1.56479 | time: 23.217s
| Adam | epoch: 037 | loss: 1.56479 - acc: 0.3643 | val_loss: 1.61488 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4104  | total loss: 1.60470 | time: 23.065s
| Adam | epoch: 038 | loss: 1.60470 - acc: 0.3571 | val_loss: 1.61327 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4212  | total loss: 1.59164 | time: 22.989s
| Adam | epoch: 039 | loss: 1.59164 - acc: 0.3519 | val_loss: 1.61344 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4320  | total loss: 1.62045 | time: 23.080s
| Adam | epoch: 040 | loss: 1.62045 - acc: 0.3423 | val_loss: 1.61030 - val_acc: 0.3307 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4428  | total loss: 1.61989 | time: 23.138s
| Adam | epoch: 041 | loss: 1.61989 - acc: 0.3504 | val_loss: 1.60587 - val_acc: 0.3281 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4536  | total loss: 1.58795 | time: 23.018s
| Adam | epoch: 042 | loss: 1.58795 - acc: 0.3459 | val_loss: 1.60204 - val_acc: 0.3307 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4644  | total loss: 1.59876 | time: 23.112s
| Adam | epoch: 043 | loss: 1.59876 - acc: 0.3500 | val_loss: 1.59376 - val_acc: 0.3596 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4752  | total loss: 1.58461 | time: 23.013s
| Adam | epoch: 044 | loss: 1.58461 - acc: 0.3650 | val_loss: 1.58478 - val_acc: 0.3858 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4860  | total loss: 1.58833 | time: 23.088s
| Adam | epoch: 045 | loss: 1.58833 - acc: 0.3497 | val_loss: 1.57983 - val_acc: 0.3858 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4968  | total loss: 1.56260 | time: 23.026s
| Adam | epoch: 046 | loss: 1.56260 - acc: 0.3897 | val_loss: 1.57598 - val_acc: 0.3727 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5076  | total loss: 1.53174 | time: 23.115s
| Adam | epoch: 047 | loss: 1.53174 - acc: 0.4075 | val_loss: 1.57028 - val_acc: 0.4068 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5184  | total loss: 1.55336 | time: 23.113s
| Adam | epoch: 048 | loss: 1.55336 - acc: 0.3652 | val_loss: 1.56364 - val_acc: 0.4121 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5292  | total loss: 1.55436 | time: 23.010s
| Adam | epoch: 049 | loss: 1.55436 - acc: 0.3864 | val_loss: 1.54867 - val_acc: 0.4173 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5400  | total loss: 1.47570 | time: 23.109s
| Adam | epoch: 050 | loss: 1.47570 - acc: 0.4329 | val_loss: 1.58335 - val_acc: 0.3806 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5508  | total loss: 1.54466 | time: 23.070s
| Adam | epoch: 051 | loss: 1.54466 - acc: 0.3881 | val_loss: 1.56138 - val_acc: 0.3570 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5616  | total loss: 1.49707 | time: 23.098s
| Adam | epoch: 052 | loss: 1.49707 - acc: 0.4122 | val_loss: 1.51081 - val_acc: 0.4278 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5724  | total loss: 1.45266 | time: 23.018s
| Adam | epoch: 053 | loss: 1.45266 - acc: 0.4615 | val_loss: 1.48795 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5832  | total loss: 1.47242 | time: 23.013s
| Adam | epoch: 054 | loss: 1.47242 - acc: 0.4478 | val_loss: 1.49881 - val_acc: 0.4488 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5940  | total loss: 1.41759 | time: 23.097s
| Adam | epoch: 055 | loss: 1.41759 - acc: 0.4491 | val_loss: 1.48691 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6048  | total loss: 1.41934 | time: 23.147s
| Adam | epoch: 056 | loss: 1.41934 - acc: 0.4619 | val_loss: 1.45799 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6156  | total loss: 1.39274 | time: 23.082s
| Adam | epoch: 057 | loss: 1.39274 - acc: 0.4831 | val_loss: 1.46596 - val_acc: 0.4331 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6264  | total loss: 1.36458 | time: 23.095s
| Adam | epoch: 058 | loss: 1.36458 - acc: 0.5013 | val_loss: 1.45663 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6372  | total loss: 1.40343 | time: 23.081s
| Adam | epoch: 059 | loss: 1.40343 - acc: 0.4585 | val_loss: 1.46672 - val_acc: 0.4751 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6480  | total loss: 1.44313 | time: 23.055s
| Adam | epoch: 060 | loss: 1.44313 - acc: 0.4556 | val_loss: 1.49175 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6588  | total loss: 1.36312 | time: 23.028s
| Adam | epoch: 061 | loss: 1.36312 - acc: 0.4913 | val_loss: 1.44141 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6696  | total loss: 1.38984 | time: 23.054s
| Adam | epoch: 062 | loss: 1.38984 - acc: 0.4657 | val_loss: 1.43661 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6804  | total loss: 1.31106 | time: 23.119s
| Adam | epoch: 063 | loss: 1.31106 - acc: 0.5082 | val_loss: 1.45226 - val_acc: 0.4777 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6912  | total loss: 1.36801 | time: 23.016s
| Adam | epoch: 064 | loss: 1.36801 - acc: 0.4918 | val_loss: 1.45352 - val_acc: 0.4488 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7020  | total loss: 1.29865 | time: 23.119s
| Adam | epoch: 065 | loss: 1.29865 - acc: 0.5011 | val_loss: 1.44866 - val_acc: 0.4751 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7128  | total loss: 1.35408 | time: 23.156s
| Adam | epoch: 066 | loss: 1.35408 - acc: 0.4746 | val_loss: 1.45067 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7236  | total loss: 1.35476 | time: 23.146s
| Adam | epoch: 067 | loss: 1.35476 - acc: 0.5012 | val_loss: 1.43396 - val_acc: 0.4436 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7344  | total loss: 1.33799 | time: 23.065s
| Adam | epoch: 068 | loss: 1.33799 - acc: 0.5068 | val_loss: 1.44189 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7452  | total loss: 1.28519 | time: 23.115s
| Adam | epoch: 069 | loss: 1.28519 - acc: 0.5026 | val_loss: 1.41762 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7560  | total loss: 1.30137 | time: 23.089s
| Adam | epoch: 070 | loss: 1.30137 - acc: 0.5298 | val_loss: 1.41109 - val_acc: 0.4829 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7668  | total loss: 1.32410 | time: 23.095s
| Adam | epoch: 071 | loss: 1.32410 - acc: 0.5153 | val_loss: 1.47961 - val_acc: 0.4436 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7776  | total loss: 1.27920 | time: 23.108s
| Adam | epoch: 072 | loss: 1.27920 - acc: 0.5028 | val_loss: 1.42297 - val_acc: 0.4961 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7884  | total loss: 1.26980 | time: 23.082s
| Adam | epoch: 073 | loss: 1.26980 - acc: 0.5472 | val_loss: 1.43592 - val_acc: 0.4856 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7992  | total loss: 1.31612 | time: 23.057s
| Adam | epoch: 074 | loss: 1.31612 - acc: 0.5147 | val_loss: 1.43588 - val_acc: 0.4829 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8100  | total loss: 1.23212 | time: 23.079s
| Adam | epoch: 075 | loss: 1.23212 - acc: 0.5299 | val_loss: 1.38085 - val_acc: 0.4934 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8208  | total loss: 1.26860 | time: 23.110s
| Adam | epoch: 076 | loss: 1.26860 - acc: 0.5279 | val_loss: 1.40498 - val_acc: 0.4803 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8316  | total loss: 1.25116 | time: 23.171s
| Adam | epoch: 077 | loss: 1.25116 - acc: 0.5164 | val_loss: 1.40084 - val_acc: 0.4777 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8424  | total loss: 1.19585 | time: 23.089s
| Adam | epoch: 078 | loss: 1.19585 - acc: 0.5364 | val_loss: 1.40669 - val_acc: 0.4882 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8532  | total loss: 1.17686 | time: 23.140s
| Adam | epoch: 079 | loss: 1.17686 - acc: 0.5790 | val_loss: 1.38896 - val_acc: 0.5066 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8640  | total loss: 1.14510 | time: 23.121s
| Adam | epoch: 080 | loss: 1.14510 - acc: 0.5718 | val_loss: 1.41759 - val_acc: 0.4987 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8748  | total loss: 1.20835 | time: 23.112s
| Adam | epoch: 081 | loss: 1.20835 - acc: 0.5354 | val_loss: 1.45389 - val_acc: 0.4856 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8856  | total loss: 1.22678 | time: 23.112s
| Adam | epoch: 082 | loss: 1.22678 - acc: 0.5224 | val_loss: 1.40562 - val_acc: 0.4829 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8964  | total loss: 1.20885 | time: 23.112s
| Adam | epoch: 083 | loss: 1.20885 - acc: 0.5572 | val_loss: 1.41393 - val_acc: 0.4987 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9072  | total loss: 1.11847 | time: 23.160s
| Adam | epoch: 084 | loss: 1.11847 - acc: 0.5825 | val_loss: 1.40648 - val_acc: 0.5039 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9180  | total loss: 1.16207 | time: 23.095s
| Adam | epoch: 085 | loss: 1.16207 - acc: 0.5540 | val_loss: 1.41103 - val_acc: 0.4961 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9288  | total loss: 1.09646 | time: 23.160s
| Adam | epoch: 086 | loss: 1.09646 - acc: 0.5672 | val_loss: 1.40329 - val_acc: 0.5144 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9396  | total loss: 1.11270 | time: 23.193s
| Adam | epoch: 087 | loss: 1.11270 - acc: 0.5750 | val_loss: 1.44914 - val_acc: 0.4987 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9504  | total loss: 1.11008 | time: 23.076s
| Adam | epoch: 088 | loss: 1.11008 - acc: 0.5725 | val_loss: 1.43585 - val_acc: 0.5039 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9612  | total loss: 1.11635 | time: 23.170s
| Adam | epoch: 089 | loss: 1.11635 - acc: 0.5757 | val_loss: 1.44723 - val_acc: 0.4777 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9720  | total loss: 1.06939 | time: 23.197s
| Adam | epoch: 090 | loss: 1.06939 - acc: 0.5820 | val_loss: 1.39888 - val_acc: 0.5197 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9828  | total loss: 1.07032 | time: 23.145s
| Adam | epoch: 091 | loss: 1.07032 - acc: 0.5842 | val_loss: 1.42929 - val_acc: 0.5092 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9936  | total loss: 0.99347 | time: 23.057s
| Adam | epoch: 092 | loss: 0.99347 - acc: 0.6322 | val_loss: 1.38699 - val_acc: 0.5354 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10044  | total loss: 1.00564 | time: 23.146s
| Adam | epoch: 093 | loss: 1.00564 - acc: 0.5950 | val_loss: 1.42546 - val_acc: 0.5092 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10152  | total loss: 0.97940 | time: 23.084s
| Adam | epoch: 094 | loss: 0.97940 - acc: 0.6266 | val_loss: 1.45288 - val_acc: 0.5118 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10260  | total loss: 0.94231 | time: 23.158s
| Adam | epoch: 095 | loss: 0.94231 - acc: 0.6467 | val_loss: 1.51030 - val_acc: 0.5118 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10368  | total loss: 1.01617 | time: 23.159s
| Adam | epoch: 096 | loss: 1.01617 - acc: 0.5864 | val_loss: 1.49607 - val_acc: 0.4934 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10476  | total loss: 1.07788 | time: 23.143s
| Adam | epoch: 097 | loss: 1.07788 - acc: 0.6248 | val_loss: 1.44244 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10584  | total loss: 0.87787 | time: 23.152s
| Adam | epoch: 098 | loss: 0.87787 - acc: 0.6637 | val_loss: 1.46562 - val_acc: 0.4751 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10692  | total loss: 0.86171 | time: 23.173s
| Adam | epoch: 099 | loss: 0.86171 - acc: 0.6625 | val_loss: 1.47325 - val_acc: 0.4987 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10800  | total loss: 0.94306 | time: 23.149s
| Adam | epoch: 100 | loss: 0.94306 - acc: 0.6549 | val_loss: 1.45154 - val_acc: 0.4803 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

