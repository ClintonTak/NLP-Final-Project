Training Step: 107  | total loss: 1.62201 | time: 69.375s
| Adam | epoch: 001 | loss: 1.62201 - acc: 0.3524 | val_loss: 1.61087 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 214  | total loss: 1.60687 | time: 24.129s
| Adam | epoch: 002 | loss: 1.60687 - acc: 0.3466 | val_loss: 1.61363 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 321  | total loss: 1.61546 | time: 24.288s
| Adam | epoch: 003 | loss: 1.61546 - acc: 0.3492 | val_loss: 1.61315 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 428  | total loss: 1.59602 | time: 23.953s
| Adam | epoch: 004 | loss: 1.59602 - acc: 0.3711 | val_loss: 1.61667 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 535  | total loss: 1.63421 | time: 24.527s
| Adam | epoch: 005 | loss: 1.63421 - acc: 0.3447 | val_loss: 1.61526 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 642  | total loss: 1.63169 | time: 24.990s
| Adam | epoch: 006 | loss: 1.63169 - acc: 0.3406 | val_loss: 1.61208 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 749  | total loss: 1.61491 | time: 24.787s
| Adam | epoch: 007 | loss: 1.61491 - acc: 0.3495 | val_loss: 1.60905 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 856  | total loss: 1.62594 | time: 24.209s
| Adam | epoch: 008 | loss: 1.62594 - acc: 0.3585 | val_loss: 1.61372 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 963  | total loss: 1.63898 | time: 24.622s
| Adam | epoch: 009 | loss: 1.63898 - acc: 0.3353 | val_loss: 1.61229 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1070  | total loss: 1.56515 | time: 26.584s
| Adam | epoch: 010 | loss: 1.56515 - acc: 0.3843 | val_loss: 1.61551 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1177  | total loss: 1.59547 | time: 29.481s
| Adam | epoch: 011 | loss: 1.59547 - acc: 0.3465 | val_loss: 1.60977 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1284  | total loss: 1.58103 | time: 29.511s
| Adam | epoch: 012 | loss: 1.58103 - acc: 0.3594 | val_loss: 1.60740 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1391  | total loss: 1.60566 | time: 29.304s
| Adam | epoch: 013 | loss: 1.60566 - acc: 0.3418 | val_loss: 1.61105 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1498  | total loss: 1.57908 | time: 30.011s
| Adam | epoch: 014 | loss: 1.57908 - acc: 0.3707 | val_loss: 1.61159 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1605  | total loss: 1.59791 | time: 29.448s
| Adam | epoch: 015 | loss: 1.59791 - acc: 0.3412 | val_loss: 1.61306 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1712  | total loss: 1.61577 | time: 29.022s
| Adam | epoch: 016 | loss: 1.61577 - acc: 0.3396 | val_loss: 1.61000 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1819  | total loss: 1.62097 | time: 23.874s
| Adam | epoch: 017 | loss: 1.62097 - acc: 0.3487 | val_loss: 1.61247 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1926  | total loss: 1.58476 | time: 23.815s
| Adam | epoch: 018 | loss: 1.58476 - acc: 0.3727 | val_loss: 1.61518 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2033  | total loss: 1.58292 | time: 23.868s
| Adam | epoch: 019 | loss: 1.58292 - acc: 0.3606 | val_loss: 1.61118 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2140  | total loss: 1.61338 | time: 23.858s
| Adam | epoch: 020 | loss: 1.61338 - acc: 0.3576 | val_loss: 1.60984 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2247  | total loss: 1.62449 | time: 24.018s
| Adam | epoch: 021 | loss: 1.62449 - acc: 0.3653 | val_loss: 1.61243 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2354  | total loss: 1.60583 | time: 23.843s
| Adam | epoch: 022 | loss: 1.60583 - acc: 0.3462 | val_loss: 1.61041 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2461  | total loss: 1.59860 | time: 23.854s
| Adam | epoch: 023 | loss: 1.59860 - acc: 0.3483 | val_loss: 1.61249 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2568  | total loss: 1.63825 | time: 23.829s
| Adam | epoch: 024 | loss: 1.63825 - acc: 0.3257 | val_loss: 1.61494 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2675  | total loss: 1.63306 | time: 23.836s
| Adam | epoch: 025 | loss: 1.63306 - acc: 0.3447 | val_loss: 1.61136 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2782  | total loss: 1.64475 | time: 23.794s
| Adam | epoch: 026 | loss: 1.64475 - acc: 0.3259 | val_loss: 1.60840 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2889  | total loss: 1.60132 | time: 23.859s
| Adam | epoch: 027 | loss: 1.60132 - acc: 0.3336 | val_loss: 1.60932 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2996  | total loss: 1.61151 | time: 23.845s
| Adam | epoch: 028 | loss: 1.61151 - acc: 0.3482 | val_loss: 1.61209 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3103  | total loss: 1.60507 | time: 23.836s
| Adam | epoch: 029 | loss: 1.60507 - acc: 0.3388 | val_loss: 1.60800 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3210  | total loss: 1.61152 | time: 23.883s
| Adam | epoch: 030 | loss: 1.61152 - acc: 0.3552 | val_loss: 1.60926 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3317  | total loss: 1.59878 | time: 23.878s
| Adam | epoch: 031 | loss: 1.59878 - acc: 0.3534 | val_loss: 1.60424 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3424  | total loss: 1.56113 | time: 23.912s
| Adam | epoch: 032 | loss: 1.56113 - acc: 0.3772 | val_loss: 1.59259 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3531  | total loss: 1.55691 | time: 23.813s
| Adam | epoch: 033 | loss: 1.55691 - acc: 0.4131 | val_loss: 1.54733 - val_acc: 0.4605 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3638  | total loss: 1.52137 | time: 23.866s
| Adam | epoch: 034 | loss: 1.52137 - acc: 0.4387 | val_loss: 1.57438 - val_acc: 0.4079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3745  | total loss: 1.55123 | time: 23.775s
| Adam | epoch: 035 | loss: 1.55123 - acc: 0.4142 | val_loss: 1.51735 - val_acc: 0.4526 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3852  | total loss: 1.51527 | time: 23.845s
| Adam | epoch: 036 | loss: 1.51527 - acc: 0.4716 | val_loss: 1.52510 - val_acc: 0.4447 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3959  | total loss: 1.48763 | time: 23.776s
| Adam | epoch: 037 | loss: 1.48763 - acc: 0.4570 | val_loss: 1.50006 - val_acc: 0.4579 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4066  | total loss: 1.50857 | time: 23.808s
| Adam | epoch: 038 | loss: 1.50857 - acc: 0.4424 | val_loss: 1.51710 - val_acc: 0.4605 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4173  | total loss: 1.50228 | time: 23.805s
| Adam | epoch: 039 | loss: 1.50228 - acc: 0.4561 | val_loss: 1.51269 - val_acc: 0.4474 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4280  | total loss: 1.49390 | time: 23.803s
| Adam | epoch: 040 | loss: 1.49390 - acc: 0.4458 | val_loss: 1.51272 - val_acc: 0.4579 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4387  | total loss: 1.47398 | time: 23.868s
| Adam | epoch: 041 | loss: 1.47398 - acc: 0.4387 | val_loss: 1.51249 - val_acc: 0.4368 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4494  | total loss: 1.45002 | time: 23.848s
| Adam | epoch: 042 | loss: 1.45002 - acc: 0.4739 | val_loss: 1.50692 - val_acc: 0.4526 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4601  | total loss: 1.46471 | time: 23.843s
| Adam | epoch: 043 | loss: 1.46471 - acc: 0.4688 | val_loss: 1.48663 - val_acc: 0.4684 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4708  | total loss: 1.49287 | time: 23.827s
| Adam | epoch: 044 | loss: 1.49287 - acc: 0.4507 | val_loss: 1.51061 - val_acc: 0.4368 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4815  | total loss: 1.46283 | time: 23.910s
| Adam | epoch: 045 | loss: 1.46283 - acc: 0.4769 | val_loss: 1.49988 - val_acc: 0.4368 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4922  | total loss: 1.45820 | time: 23.826s
| Adam | epoch: 046 | loss: 1.45820 - acc: 0.4592 | val_loss: 1.48665 - val_acc: 0.4526 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5029  | total loss: 1.45094 | time: 23.821s
| Adam | epoch: 047 | loss: 1.45094 - acc: 0.4704 | val_loss: 1.50377 - val_acc: 0.4447 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5136  | total loss: 1.38334 | time: 23.834s
| Adam | epoch: 048 | loss: 1.38334 - acc: 0.5145 | val_loss: 1.51805 - val_acc: 0.4368 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5243  | total loss: 1.38891 | time: 23.878s
| Adam | epoch: 049 | loss: 1.38891 - acc: 0.5147 | val_loss: 1.52790 - val_acc: 0.4289 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5350  | total loss: 1.34547 | time: 23.817s
| Adam | epoch: 050 | loss: 1.34547 - acc: 0.5098 | val_loss: 1.53825 - val_acc: 0.4342 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5457  | total loss: 1.28005 | time: 23.768s
| Adam | epoch: 051 | loss: 1.28005 - acc: 0.5402 | val_loss: 1.58250 - val_acc: 0.4289 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5564  | total loss: 1.36936 | time: 23.791s
| Adam | epoch: 052 | loss: 1.36936 - acc: 0.5162 | val_loss: 1.54096 - val_acc: 0.4289 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5671  | total loss: 1.40028 | time: 23.874s
| Adam | epoch: 053 | loss: 1.40028 - acc: 0.4844 | val_loss: 1.53927 - val_acc: 0.4316 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5778  | total loss: 1.40183 | time: 23.828s
| Adam | epoch: 054 | loss: 1.40183 - acc: 0.4965 | val_loss: 1.55297 - val_acc: 0.4184 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5885  | total loss: 1.30588 | time: 23.862s
| Adam | epoch: 055 | loss: 1.30588 - acc: 0.5127 | val_loss: 1.60755 - val_acc: 0.4289 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5992  | total loss: 1.33697 | time: 23.799s
| Adam | epoch: 056 | loss: 1.33697 - acc: 0.5206 | val_loss: 1.59458 - val_acc: 0.4184 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6099  | total loss: 1.23290 | time: 23.755s
| Adam | epoch: 057 | loss: 1.23290 - acc: 0.5614 | val_loss: 1.62808 - val_acc: 0.4316 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6206  | total loss: 1.21545 | time: 23.794s
| Adam | epoch: 058 | loss: 1.21545 - acc: 0.5571 | val_loss: 1.67264 - val_acc: 0.4079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6313  | total loss: 1.25539 | time: 23.811s
| Adam | epoch: 059 | loss: 1.25539 - acc: 0.5441 | val_loss: 1.65839 - val_acc: 0.4289 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6420  | total loss: 1.24332 | time: 23.810s
| Adam | epoch: 060 | loss: 1.24332 - acc: 0.5423 | val_loss: 1.67009 - val_acc: 0.4237 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6527  | total loss: 1.13189 | time: 23.816s
| Adam | epoch: 061 | loss: 1.13189 - acc: 0.5744 | val_loss: 1.80565 - val_acc: 0.4053 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6634  | total loss: 1.18790 | time: 23.841s
| Adam | epoch: 062 | loss: 1.18790 - acc: 0.5578 | val_loss: 1.69996 - val_acc: 0.4026 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6741  | total loss: 1.18250 | time: 24.051s
| Adam | epoch: 063 | loss: 1.18250 - acc: 0.5644 | val_loss: 1.83004 - val_acc: 0.4132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6848  | total loss: 1.13737 | time: 24.808s
| Adam | epoch: 064 | loss: 1.13737 - acc: 0.5607 | val_loss: 1.78835 - val_acc: 0.4237 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6955  | total loss: 1.12819 | time: 25.212s
| Adam | epoch: 065 | loss: 1.12819 - acc: 0.5753 | val_loss: 1.78581 - val_acc: 0.3974 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7062  | total loss: 1.05148 | time: 24.900s
| Adam | epoch: 066 | loss: 1.05148 - acc: 0.5920 | val_loss: 1.88364 - val_acc: 0.3947 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7169  | total loss: 1.12044 | time: 24.760s
| Adam | epoch: 067 | loss: 1.12044 - acc: 0.5983 | val_loss: 1.87075 - val_acc: 0.3921 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7276  | total loss: 1.03172 | time: 24.767s
| Adam | epoch: 068 | loss: 1.03172 - acc: 0.6055 | val_loss: 2.01015 - val_acc: 0.3474 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7383  | total loss: 0.98943 | time: 24.738s
| Adam | epoch: 069 | loss: 0.98943 - acc: 0.6222 | val_loss: 1.97998 - val_acc: 0.3763 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7490  | total loss: 1.08303 | time: 24.875s
| Adam | epoch: 070 | loss: 1.08303 - acc: 0.5750 | val_loss: 2.01130 - val_acc: 0.3605 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7597  | total loss: 1.07024 | time: 24.934s
| Adam | epoch: 071 | loss: 1.07024 - acc: 0.6062 | val_loss: 2.09520 - val_acc: 0.3737 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7704  | total loss: 1.00066 | time: 24.952s
| Adam | epoch: 072 | loss: 1.00066 - acc: 0.6237 | val_loss: 2.02773 - val_acc: 0.3684 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7811  | total loss: 0.97986 | time: 24.776s
| Adam | epoch: 073 | loss: 0.97986 - acc: 0.6386 | val_loss: 2.11162 - val_acc: 0.3474 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7918  | total loss: 0.98793 | time: 25.070s
| Adam | epoch: 074 | loss: 0.98793 - acc: 0.6128 | val_loss: 2.09543 - val_acc: 0.3342 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8025  | total loss: 0.92266 | time: 24.895s
| Adam | epoch: 075 | loss: 0.92266 - acc: 0.6589 | val_loss: 2.13427 - val_acc: 0.3553 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8132  | total loss: 1.01009 | time: 25.031s
| Adam | epoch: 076 | loss: 1.01009 - acc: 0.6144 | val_loss: 2.15581 - val_acc: 0.3526 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8239  | total loss: 0.91149 | time: 24.923s
| Adam | epoch: 077 | loss: 0.91149 - acc: 0.6517 | val_loss: 2.22791 - val_acc: 0.3474 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8346  | total loss: 0.89040 | time: 24.702s
| Adam | epoch: 078 | loss: 0.89040 - acc: 0.6632 | val_loss: 2.13478 - val_acc: 0.3421 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8453  | total loss: 0.87314 | time: 24.913s
| Adam | epoch: 079 | loss: 0.87314 - acc: 0.6701 | val_loss: 2.18120 - val_acc: 0.3553 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8560  | total loss: 0.91770 | time: 25.134s
| Adam | epoch: 080 | loss: 0.91770 - acc: 0.6594 | val_loss: 2.38543 - val_acc: 0.3579 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8667  | total loss: 0.82696 | time: 25.104s
| Adam | epoch: 081 | loss: 0.82696 - acc: 0.6915 | val_loss: 2.33322 - val_acc: 0.3368 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8774  | total loss: 0.85846 | time: 25.163s
| Adam | epoch: 082 | loss: 0.85846 - acc: 0.6773 | val_loss: 2.43006 - val_acc: 0.3316 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8881  | total loss: 0.86106 | time: 24.587s
| Adam | epoch: 083 | loss: 0.86106 - acc: 0.6790 | val_loss: 2.35062 - val_acc: 0.3553 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8988  | total loss: 0.83699 | time: 24.931s
| Adam | epoch: 084 | loss: 0.83699 - acc: 0.6937 | val_loss: 2.45249 - val_acc: 0.3447 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9095  | total loss: 0.78932 | time: 24.755s
| Adam | epoch: 085 | loss: 0.78932 - acc: 0.7182 | val_loss: 2.45245 - val_acc: 0.3395 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9202  | total loss: 0.78100 | time: 24.942s
| Adam | epoch: 086 | loss: 0.78100 - acc: 0.7040 | val_loss: 2.45348 - val_acc: 0.3368 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9309  | total loss: 0.78414 | time: 24.887s
| Adam | epoch: 087 | loss: 0.78414 - acc: 0.7201 | val_loss: 2.49096 - val_acc: 0.3342 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9416  | total loss: 0.78583 | time: 24.902s
| Adam | epoch: 088 | loss: 0.78583 - acc: 0.7183 | val_loss: 2.53325 - val_acc: 0.3553 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9523  | total loss: 0.86342 | time: 25.121s
| Adam | epoch: 089 | loss: 0.86342 - acc: 0.6826 | val_loss: 2.50483 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9630  | total loss: 0.74302 | time: 25.131s
| Adam | epoch: 090 | loss: 0.74302 - acc: 0.7072 | val_loss: 2.49362 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9737  | total loss: 0.81154 | time: 24.711s
| Adam | epoch: 091 | loss: 0.81154 - acc: 0.7047 | val_loss: 2.58564 - val_acc: 0.3553 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9844  | total loss: 0.71720 | time: 24.815s
| Adam | epoch: 092 | loss: 0.71720 - acc: 0.7596 | val_loss: 2.55343 - val_acc: 0.3211 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9951  | total loss: 0.69463 | time: 25.018s
| Adam | epoch: 093 | loss: 0.69463 - acc: 0.7420 | val_loss: 2.67115 - val_acc: 0.3237 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10058  | total loss: 0.72201 | time: 25.081s
| Adam | epoch: 094 | loss: 0.72201 - acc: 0.7444 | val_loss: 2.68094 - val_acc: 0.3026 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10165  | total loss: 0.69053 | time: 24.925s
| Adam | epoch: 095 | loss: 0.69053 - acc: 0.7696 | val_loss: 2.75806 - val_acc: 0.3184 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10272  | total loss: 0.77439 | time: 24.986s
| Adam | epoch: 096 | loss: 0.77439 - acc: 0.7130 | val_loss: 2.57708 - val_acc: 0.3211 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10379  | total loss: 0.74994 | time: 24.809s
| Adam | epoch: 097 | loss: 0.74994 - acc: 0.7389 | val_loss: 2.64544 - val_acc: 0.3132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10486  | total loss: 0.68328 | time: 24.872s
| Adam | epoch: 098 | loss: 0.68328 - acc: 0.7732 | val_loss: 2.77776 - val_acc: 0.3158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10593  | total loss: 0.74746 | time: 25.002s
| Adam | epoch: 099 | loss: 0.74746 - acc: 0.7278 | val_loss: 2.72394 - val_acc: 0.3395 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10700  | total loss: 0.70560 | time: 24.839s
| Adam | epoch: 100 | loss: 0.70560 - acc: 0.7590 | val_loss: 2.68169 - val_acc: 0.3263 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

