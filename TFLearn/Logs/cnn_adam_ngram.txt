Training Step: 107  | total loss: 1.62393 | time: 5.583s
| Adam | epoch: 001 | loss: 1.62393 - acc: 0.3580 | val_loss: 1.56069 - val_acc: 0.3789 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 214  | total loss: 1.55942 | time: 4.672s
| Adam | epoch: 002 | loss: 1.55942 - acc: 0.4084 | val_loss: 1.48700 - val_acc: 0.4579 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 321  | total loss: 1.51754 | time: 4.635s
| Adam | epoch: 003 | loss: 1.51754 - acc: 0.4407 | val_loss: 1.44588 - val_acc: 0.4684 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 428  | total loss: 1.50313 | time: 4.659s
| Adam | epoch: 004 | loss: 1.50313 - acc: 0.4538 | val_loss: 1.42722 - val_acc: 0.4868 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 535  | total loss: 1.52012 | time: 4.666s
| Adam | epoch: 005 | loss: 1.52012 - acc: 0.4160 | val_loss: 1.41520 - val_acc: 0.4895 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 642  | total loss: 1.47917 | time: 4.645s
| Adam | epoch: 006 | loss: 1.47917 - acc: 0.4380 | val_loss: 1.38122 - val_acc: 0.4816 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 749  | total loss: 1.45873 | time: 4.671s
| Adam | epoch: 007 | loss: 1.45873 - acc: 0.4279 | val_loss: 1.38101 - val_acc: 0.4974 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 856  | total loss: 1.44828 | time: 4.670s
| Adam | epoch: 008 | loss: 1.44828 - acc: 0.4332 | val_loss: 1.36635 - val_acc: 0.5053 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 963  | total loss: 1.46078 | time: 4.703s
| Adam | epoch: 009 | loss: 1.46078 - acc: 0.4606 | val_loss: 1.36240 - val_acc: 0.4868 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1070  | total loss: 1.37087 | time: 4.898s
| Adam | epoch: 010 | loss: 1.37087 - acc: 0.4970 | val_loss: 1.36862 - val_acc: 0.4895 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1177  | total loss: 1.37261 | time: 4.743s
| Adam | epoch: 011 | loss: 1.37261 - acc: 0.4767 | val_loss: 1.35884 - val_acc: 0.5263 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1284  | total loss: 1.34662 | time: 4.732s
| Adam | epoch: 012 | loss: 1.34662 - acc: 0.4961 | val_loss: 1.34894 - val_acc: 0.5105 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1391  | total loss: 1.36563 | time: 4.670s
| Adam | epoch: 013 | loss: 1.36563 - acc: 0.4930 | val_loss: 1.34147 - val_acc: 0.5184 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1498  | total loss: 1.34016 | time: 4.648s
| Adam | epoch: 014 | loss: 1.34016 - acc: 0.4919 | val_loss: 1.33949 - val_acc: 0.5263 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1605  | total loss: 1.34742 | time: 4.651s
| Adam | epoch: 015 | loss: 1.34742 - acc: 0.4821 | val_loss: 1.32562 - val_acc: 0.5263 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1712  | total loss: 1.33835 | time: 4.660s
| Adam | epoch: 016 | loss: 1.33835 - acc: 0.4951 | val_loss: 1.35020 - val_acc: 0.5105 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1819  | total loss: 1.34592 | time: 4.652s
| Adam | epoch: 017 | loss: 1.34592 - acc: 0.4960 | val_loss: 1.33987 - val_acc: 0.5053 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1926  | total loss: 1.32779 | time: 4.796s
| Adam | epoch: 018 | loss: 1.32779 - acc: 0.5005 | val_loss: 1.33747 - val_acc: 0.5105 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2033  | total loss: 1.23370 | time: 4.744s
| Adam | epoch: 019 | loss: 1.23370 - acc: 0.5445 | val_loss: 1.31212 - val_acc: 0.5289 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2140  | total loss: 1.30085 | time: 4.722s
| Adam | epoch: 020 | loss: 1.30085 - acc: 0.5324 | val_loss: 1.34113 - val_acc: 0.5026 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2247  | total loss: 1.22427 | time: 4.649s
| Adam | epoch: 021 | loss: 1.22427 - acc: 0.5326 | val_loss: 1.34515 - val_acc: 0.5263 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2354  | total loss: 1.27025 | time: 4.650s
| Adam | epoch: 022 | loss: 1.27025 - acc: 0.5382 | val_loss: 1.33679 - val_acc: 0.5053 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2461  | total loss: 1.24688 | time: 4.657s
| Adam | epoch: 023 | loss: 1.24688 - acc: 0.5427 | val_loss: 1.35160 - val_acc: 0.4921 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2568  | total loss: 1.19014 | time: 4.644s
| Adam | epoch: 024 | loss: 1.19014 - acc: 0.5614 | val_loss: 1.33476 - val_acc: 0.5000 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2675  | total loss: 1.18861 | time: 4.658s
| Adam | epoch: 025 | loss: 1.18861 - acc: 0.5539 | val_loss: 1.35405 - val_acc: 0.5079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2782  | total loss: 1.18917 | time: 4.650s
| Adam | epoch: 026 | loss: 1.18917 - acc: 0.5652 | val_loss: 1.35755 - val_acc: 0.5132 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2889  | total loss: 1.23529 | time: 4.647s
| Adam | epoch: 027 | loss: 1.23529 - acc: 0.5630 | val_loss: 1.35107 - val_acc: 0.5158 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2996  | total loss: 1.20200 | time: 4.644s
| Adam | epoch: 028 | loss: 1.20200 - acc: 0.5488 | val_loss: 1.35289 - val_acc: 0.5211 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3103  | total loss: 1.14865 | time: 4.639s
| Adam | epoch: 029 | loss: 1.14865 - acc: 0.5949 | val_loss: 1.35823 - val_acc: 0.5105 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3210  | total loss: 1.21073 | time: 4.875s
| Adam | epoch: 030 | loss: 1.21073 - acc: 0.5661 | val_loss: 1.36805 - val_acc: 0.5000 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3317  | total loss: 1.20250 | time: 4.771s
| Adam | epoch: 031 | loss: 1.20250 - acc: 0.5816 | val_loss: 1.36758 - val_acc: 0.4816 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3424  | total loss: 1.09150 | time: 4.805s
| Adam | epoch: 032 | loss: 1.09150 - acc: 0.6111 | val_loss: 1.35316 - val_acc: 0.5000 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3531  | total loss: 1.18302 | time: 4.660s
| Adam | epoch: 033 | loss: 1.18302 - acc: 0.5560 | val_loss: 1.36758 - val_acc: 0.4921 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3638  | total loss: 1.11327 | time: 4.650s
| Adam | epoch: 034 | loss: 1.11327 - acc: 0.5796 | val_loss: 1.38155 - val_acc: 0.4947 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3745  | total loss: 1.06558 | time: 4.651s
| Adam | epoch: 035 | loss: 1.06558 - acc: 0.5907 | val_loss: 1.39857 - val_acc: 0.5105 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3852  | total loss: 1.07175 | time: 4.587s
| Adam | epoch: 036 | loss: 1.07175 - acc: 0.5903 | val_loss: 1.39170 - val_acc: 0.4947 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3959  | total loss: 1.08494 | time: 4.613s
| Adam | epoch: 037 | loss: 1.08494 - acc: 0.5823 | val_loss: 1.39614 - val_acc: 0.4816 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4066  | total loss: 1.09248 | time: 4.602s
| Adam | epoch: 038 | loss: 1.09248 - acc: 0.6111 | val_loss: 1.38836 - val_acc: 0.5053 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4173  | total loss: 1.05161 | time: 4.607s
| Adam | epoch: 039 | loss: 1.05161 - acc: 0.6027 | val_loss: 1.39803 - val_acc: 0.4816 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4280  | total loss: 1.10568 | time: 4.600s
| Adam | epoch: 040 | loss: 1.10568 - acc: 0.6090 | val_loss: 1.40122 - val_acc: 0.4763 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4387  | total loss: 1.08192 | time: 4.719s
| Adam | epoch: 041 | loss: 1.08192 - acc: 0.6118 | val_loss: 1.42459 - val_acc: 0.4658 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4494  | total loss: 1.07404 | time: 4.745s
| Adam | epoch: 042 | loss: 1.07404 - acc: 0.6091 | val_loss: 1.41889 - val_acc: 0.4895 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4601  | total loss: 1.02152 | time: 4.682s
| Adam | epoch: 043 | loss: 1.02152 - acc: 0.6216 | val_loss: 1.41237 - val_acc: 0.5000 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4708  | total loss: 1.03087 | time: 4.614s
| Adam | epoch: 044 | loss: 1.03087 - acc: 0.6185 | val_loss: 1.41210 - val_acc: 0.4763 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4815  | total loss: 1.01147 | time: 4.599s
| Adam | epoch: 045 | loss: 1.01147 - acc: 0.6371 | val_loss: 1.45988 - val_acc: 0.4500 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4922  | total loss: 0.97726 | time: 4.603s
| Adam | epoch: 046 | loss: 0.97726 - acc: 0.6582 | val_loss: 1.42855 - val_acc: 0.4895 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5029  | total loss: 1.05340 | time: 4.596s
| Adam | epoch: 047 | loss: 1.05340 - acc: 0.5986 | val_loss: 1.44012 - val_acc: 0.4868 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5136  | total loss: 0.95573 | time: 4.607s
| Adam | epoch: 048 | loss: 0.95573 - acc: 0.6513 | val_loss: 1.45700 - val_acc: 0.4711 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5243  | total loss: 0.96125 | time: 4.594s
| Adam | epoch: 049 | loss: 0.96125 - acc: 0.6412 | val_loss: 1.47465 - val_acc: 0.4658 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5350  | total loss: 0.95434 | time: 4.597s
| Adam | epoch: 050 | loss: 0.95434 - acc: 0.6469 | val_loss: 1.44059 - val_acc: 0.4947 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5457  | total loss: 0.99003 | time: 4.603s
| Adam | epoch: 051 | loss: 0.99003 - acc: 0.6398 | val_loss: 1.45782 - val_acc: 0.4789 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5564  | total loss: 0.94165 | time: 5.042s
| Adam | epoch: 052 | loss: 0.94165 - acc: 0.6526 | val_loss: 1.46006 - val_acc: 0.4763 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5671  | total loss: 0.92037 | time: 4.730s
| Adam | epoch: 053 | loss: 0.92037 - acc: 0.6636 | val_loss: 1.47772 - val_acc: 0.4789 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5778  | total loss: 0.97698 | time: 4.584s
| Adam | epoch: 054 | loss: 0.97698 - acc: 0.6616 | val_loss: 1.49772 - val_acc: 0.4763 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5885  | total loss: 0.93076 | time: 4.589s
| Adam | epoch: 055 | loss: 0.93076 - acc: 0.6477 | val_loss: 1.46655 - val_acc: 0.4974 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5992  | total loss: 0.92183 | time: 4.620s
| Adam | epoch: 056 | loss: 0.92183 - acc: 0.6508 | val_loss: 1.48696 - val_acc: 0.4789 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6099  | total loss: 0.92420 | time: 4.620s
| Adam | epoch: 057 | loss: 0.92420 - acc: 0.6685 | val_loss: 1.49190 - val_acc: 0.4895 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6206  | total loss: 0.91698 | time: 4.591s
| Adam | epoch: 058 | loss: 0.91698 - acc: 0.6637 | val_loss: 1.51232 - val_acc: 0.4816 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6313  | total loss: 0.83306 | time: 4.603s
| Adam | epoch: 059 | loss: 0.83306 - acc: 0.7015 | val_loss: 1.55039 - val_acc: 0.4711 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6420  | total loss: 0.87786 | time: 4.601s
| Adam | epoch: 060 | loss: 0.87786 - acc: 0.6933 | val_loss: 1.54748 - val_acc: 0.4368 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6527  | total loss: 0.86773 | time: 4.588s
| Adam | epoch: 061 | loss: 0.86773 - acc: 0.6790 | val_loss: 1.52023 - val_acc: 0.4658 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6634  | total loss: 0.87497 | time: 4.608s
| Adam | epoch: 062 | loss: 0.87497 - acc: 0.6694 | val_loss: 1.56582 - val_acc: 0.4526 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6741  | total loss: 0.83851 | time: 4.603s
| Adam | epoch: 063 | loss: 0.83851 - acc: 0.6950 | val_loss: 1.55324 - val_acc: 0.4553 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6848  | total loss: 0.89483 | time: 4.581s
| Adam | epoch: 064 | loss: 0.89483 - acc: 0.6579 | val_loss: 1.54648 - val_acc: 0.4684 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6955  | total loss: 0.88127 | time: 4.596s
| Adam | epoch: 065 | loss: 0.88127 - acc: 0.6802 | val_loss: 1.53552 - val_acc: 0.4605 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7062  | total loss: 0.86386 | time: 4.573s
| Adam | epoch: 066 | loss: 0.86386 - acc: 0.6889 | val_loss: 1.55735 - val_acc: 0.4474 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7169  | total loss: 0.87389 | time: 4.603s
| Adam | epoch: 067 | loss: 0.87389 - acc: 0.6877 | val_loss: 1.55181 - val_acc: 0.4526 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7276  | total loss: 0.91227 | time: 4.600s
| Adam | epoch: 068 | loss: 0.91227 - acc: 0.6611 | val_loss: 1.53729 - val_acc: 0.4553 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7383  | total loss: 0.84498 | time: 4.622s
| Adam | epoch: 069 | loss: 0.84498 - acc: 0.6876 | val_loss: 1.56368 - val_acc: 0.4789 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7490  | total loss: 0.86544 | time: 4.593s
| Adam | epoch: 070 | loss: 0.86544 - acc: 0.6985 | val_loss: 1.57136 - val_acc: 0.4632 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7597  | total loss: 0.82177 | time: 4.587s
| Adam | epoch: 071 | loss: 0.82177 - acc: 0.7059 | val_loss: 1.54284 - val_acc: 0.4816 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7704  | total loss: 0.82809 | time: 4.585s
| Adam | epoch: 072 | loss: 0.82809 - acc: 0.7010 | val_loss: 1.57552 - val_acc: 0.4658 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7811  | total loss: 0.79308 | time: 4.593s
| Adam | epoch: 073 | loss: 0.79308 - acc: 0.7251 | val_loss: 1.67372 - val_acc: 0.4342 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7918  | total loss: 0.76655 | time: 4.586s
| Adam | epoch: 074 | loss: 0.76655 - acc: 0.7263 | val_loss: 1.60253 - val_acc: 0.4737 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8025  | total loss: 0.82037 | time: 4.591s
| Adam | epoch: 075 | loss: 0.82037 - acc: 0.6995 | val_loss: 1.59337 - val_acc: 0.4684 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8132  | total loss: 0.72938 | time: 4.592s
| Adam | epoch: 076 | loss: 0.72938 - acc: 0.7478 | val_loss: 1.62245 - val_acc: 0.4474 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8239  | total loss: 0.81702 | time: 4.612s
| Adam | epoch: 077 | loss: 0.81702 - acc: 0.6930 | val_loss: 1.59072 - val_acc: 0.4447 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8346  | total loss: 0.82009 | time: 4.599s
| Adam | epoch: 078 | loss: 0.82009 - acc: 0.6908 | val_loss: 1.61826 - val_acc: 0.4447 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8453  | total loss: 0.80987 | time: 4.594s
| Adam | epoch: 079 | loss: 0.80987 - acc: 0.6972 | val_loss: 1.64687 - val_acc: 0.4526 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8560  | total loss: 0.78625 | time: 4.587s
| Adam | epoch: 080 | loss: 0.78625 - acc: 0.7283 | val_loss: 1.60128 - val_acc: 0.4579 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8667  | total loss: 0.82343 | time: 4.589s
| Adam | epoch: 081 | loss: 0.82343 - acc: 0.7074 | val_loss: 1.64005 - val_acc: 0.4553 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8774  | total loss: 0.80873 | time: 4.598s
| Adam | epoch: 082 | loss: 0.80873 - acc: 0.7275 | val_loss: 1.63314 - val_acc: 0.4395 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8881  | total loss: 0.76340 | time: 4.577s
| Adam | epoch: 083 | loss: 0.76340 - acc: 0.7269 | val_loss: 1.65461 - val_acc: 0.4579 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8988  | total loss: 0.76848 | time: 4.583s
| Adam | epoch: 084 | loss: 0.76848 - acc: 0.7155 | val_loss: 1.67893 - val_acc: 0.4474 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9095  | total loss: 0.79831 | time: 4.593s
| Adam | epoch: 085 | loss: 0.79831 - acc: 0.6944 | val_loss: 1.64957 - val_acc: 0.4447 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9202  | total loss: 0.77410 | time: 4.577s
| Adam | epoch: 086 | loss: 0.77410 - acc: 0.7030 | val_loss: 1.69377 - val_acc: 0.4500 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9309  | total loss: 0.69483 | time: 4.590s
| Adam | epoch: 087 | loss: 0.69483 - acc: 0.7447 | val_loss: 1.69194 - val_acc: 0.4342 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9416  | total loss: 0.72525 | time: 4.585s
| Adam | epoch: 088 | loss: 0.72525 - acc: 0.7360 | val_loss: 1.68838 - val_acc: 0.4526 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9523  | total loss: 0.71936 | time: 4.606s
| Adam | epoch: 089 | loss: 0.71936 - acc: 0.7527 | val_loss: 1.70931 - val_acc: 0.4605 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9630  | total loss: 0.75831 | time: 4.585s
| Adam | epoch: 090 | loss: 0.75831 - acc: 0.7219 | val_loss: 1.72366 - val_acc: 0.4500 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9737  | total loss: 0.74848 | time: 4.616s
| Adam | epoch: 091 | loss: 0.74848 - acc: 0.7196 | val_loss: 1.75591 - val_acc: 0.4316 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9844  | total loss: 0.77304 | time: 4.605s
| Adam | epoch: 092 | loss: 0.77304 - acc: 0.7248 | val_loss: 1.71978 - val_acc: 0.4526 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9951  | total loss: 0.72795 | time: 4.597s
| Adam | epoch: 093 | loss: 0.72795 - acc: 0.7371 | val_loss: 1.73873 - val_acc: 0.4263 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10058  | total loss: 0.68416 | time: 4.610s
| Adam | epoch: 094 | loss: 0.68416 - acc: 0.7465 | val_loss: 1.72860 - val_acc: 0.4658 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10165  | total loss: 0.74292 | time: 4.598s
| Adam | epoch: 095 | loss: 0.74292 - acc: 0.7314 | val_loss: 1.66290 - val_acc: 0.4658 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10272  | total loss: 0.67597 | time: 4.605s
| Adam | epoch: 096 | loss: 0.67597 - acc: 0.7660 | val_loss: 1.69194 - val_acc: 0.4658 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10379  | total loss: 0.70488 | time: 4.711s
| Adam | epoch: 097 | loss: 0.70488 - acc: 0.7278 | val_loss: 1.70527 - val_acc: 0.4447 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10486  | total loss: 0.72473 | time: 4.639s
| Adam | epoch: 098 | loss: 0.72473 - acc: 0.7302 | val_loss: 1.66475 - val_acc: 0.4500 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10593  | total loss: 0.71550 | time: 4.646s
| Adam | epoch: 099 | loss: 0.71550 - acc: 0.7209 | val_loss: 1.71946 - val_acc: 0.4368 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10700  | total loss: 0.67441 | time: 4.634s
| Adam | epoch: 100 | loss: 0.67441 - acc: 0.7545 | val_loss: 1.75131 - val_acc: 0.4395 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

