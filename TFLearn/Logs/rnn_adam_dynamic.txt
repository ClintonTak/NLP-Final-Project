Training Step: 107  | total loss: [1m[32m1.56878[0m[0m | time: 147.828s
| Adam | epoch: 001 | loss: 1.56878 - acc: 0.3637 | val_loss: 1.61427 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 214  | total loss: [1m[32m1.62361[0m[0m | time: 36.544s
| Adam | epoch: 002 | loss: 1.62361 - acc: 0.3377 | val_loss: 1.61338 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 321  | total loss: [1m[32m1.62706[0m[0m | time: 36.071s
| Adam | epoch: 003 | loss: 1.62706 - acc: 0.3480 | val_loss: 1.62471 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 428  | total loss: [1m[32m1.61838[0m[0m | time: 36.245s
| Adam | epoch: 004 | loss: 1.61838 - acc: 0.3462 | val_loss: 1.61891 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 535  | total loss: [1m[32m1.62097[0m[0m | time: 36.086s
| Adam | epoch: 005 | loss: 1.62097 - acc: 0.3463 | val_loss: 1.61951 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 642  | total loss: [1m[32m1.54848[0m[0m | time: 36.429s
| Adam | epoch: 006 | loss: 1.54848 - acc: 0.3930 | val_loss: 1.61944 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 749  | total loss: [1m[32m1.60837[0m[0m | time: 36.510s
| Adam | epoch: 007 | loss: 1.60837 - acc: 0.3363 | val_loss: 1.61238 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 856  | total loss: [1m[32m1.61944[0m[0m | time: 36.286s
| Adam | epoch: 008 | loss: 1.61944 - acc: 0.3356 | val_loss: 1.61122 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 963  | total loss: [1m[32m1.57000[0m[0m | time: 36.332s
| Adam | epoch: 009 | loss: 1.57000 - acc: 0.3800 | val_loss: 1.62725 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1070  | total loss: [1m[32m1.61063[0m[0m | time: 37.139s
| Adam | epoch: 010 | loss: 1.61063 - acc: 0.3521 | val_loss: 1.61451 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1177  | total loss: [1m[32m1.59855[0m[0m | time: 36.911s
| Adam | epoch: 011 | loss: 1.59855 - acc: 0.3265 | val_loss: 1.61282 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1284  | total loss: [1m[32m1.59059[0m[0m | time: 36.725s
| Adam | epoch: 012 | loss: 1.59059 - acc: 0.3484 | val_loss: 1.61088 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1391  | total loss: [1m[32m1.58881[0m[0m | time: 36.211s
| Adam | epoch: 013 | loss: 1.58881 - acc: 0.3468 | val_loss: 1.61154 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1498  | total loss: [1m[32m1.59451[0m[0m | time: 36.267s
| Adam | epoch: 014 | loss: 1.59451 - acc: 0.3455 | val_loss: 1.61490 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1605  | total loss: [1m[32m1.59972[0m[0m | time: 36.041s
| Adam | epoch: 015 | loss: 1.59972 - acc: 0.3695 | val_loss: 1.62920 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1712  | total loss: [1m[32m1.57632[0m[0m | time: 36.574s
| Adam | epoch: 016 | loss: 1.57632 - acc: 0.3547 | val_loss: 1.61096 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1819  | total loss: [1m[32m1.60188[0m[0m | time: 36.177s
| Adam | epoch: 017 | loss: 1.60188 - acc: 0.3436 | val_loss: 1.61615 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 1926  | total loss: [1m[32m1.61221[0m[0m | time: 36.148s
| Adam | epoch: 018 | loss: 1.61221 - acc: 0.3268 | val_loss: 1.60622 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2033  | total loss: [1m[32m1.65684[0m[0m | time: 36.084s
| Adam | epoch: 019 | loss: 1.65684 - acc: 0.3064 | val_loss: 1.61108 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2140  | total loss: [1m[32m1.64536[0m[0m | time: 36.043s
| Adam | epoch: 020 | loss: 1.64536 - acc: 0.3227 | val_loss: 1.62033 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2247  | total loss: [1m[32m1.59627[0m[0m | time: 35.992s
| Adam | epoch: 021 | loss: 1.59627 - acc: 0.3643 | val_loss: 1.61524 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2354  | total loss: [1m[32m1.56687[0m[0m | time: 36.429s
| Adam | epoch: 022 | loss: 1.56687 - acc: 0.3576 | val_loss: 1.61357 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2461  | total loss: [1m[32m1.60139[0m[0m | time: 36.654s
| Adam | epoch: 023 | loss: 1.60139 - acc: 0.3543 | val_loss: 1.61977 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2568  | total loss: [1m[32m1.57409[0m[0m | time: 36.441s
| Adam | epoch: 024 | loss: 1.57409 - acc: 0.3621 | val_loss: 1.61342 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2675  | total loss: [1m[32m1.64100[0m[0m | time: 36.382s
| Adam | epoch: 025 | loss: 1.64100 - acc: 0.3334 | val_loss: 1.61007 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2782  | total loss: [1m[32m1.58205[0m[0m | time: 36.245s
| Adam | epoch: 026 | loss: 1.58205 - acc: 0.3531 | val_loss: 1.61318 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2889  | total loss: [1m[32m1.56795[0m[0m | time: 36.002s
| Adam | epoch: 027 | loss: 1.56795 - acc: 0.3777 | val_loss: 1.61344 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 2996  | total loss: [1m[32m1.58530[0m[0m | time: 36.025s
| Adam | epoch: 028 | loss: 1.58530 - acc: 0.3587 | val_loss: 1.61220 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3103  | total loss: [1m[32m1.61206[0m[0m | time: 36.029s
| Adam | epoch: 029 | loss: 1.61206 - acc: 0.3287 | val_loss: 1.61174 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3210  | total loss: [1m[32m1.58758[0m[0m | time: 36.512s
| Adam | epoch: 030 | loss: 1.58758 - acc: 0.3586 | val_loss: 1.61714 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3317  | total loss: [1m[32m1.61665[0m[0m | time: 36.056s
| Adam | epoch: 031 | loss: 1.61665 - acc: 0.3421 | val_loss: 1.60919 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3424  | total loss: [1m[32m1.62562[0m[0m | time: 36.107s
| Adam | epoch: 032 | loss: 1.62562 - acc: 0.3462 | val_loss: 1.61367 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3531  | total loss: [1m[32m1.60806[0m[0m | time: 37.379s
| Adam | epoch: 033 | loss: 1.60806 - acc: 0.3590 | val_loss: 1.61823 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3638  | total loss: [1m[32m1.62204[0m[0m | time: 36.961s
| Adam | epoch: 034 | loss: 1.62204 - acc: 0.3503 | val_loss: 1.61444 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3745  | total loss: [1m[32m1.56520[0m[0m | time: 36.954s
| Adam | epoch: 035 | loss: 1.56520 - acc: 0.3525 | val_loss: 1.60574 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3852  | total loss: [1m[32m1.57308[0m[0m | time: 36.945s
| Adam | epoch: 036 | loss: 1.57308 - acc: 0.3618 | val_loss: 1.60941 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 3959  | total loss: [1m[32m1.57021[0m[0m | time: 36.972s
| Adam | epoch: 037 | loss: 1.57021 - acc: 0.3677 | val_loss: 1.61302 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4066  | total loss: [1m[32m1.60527[0m[0m | time: 36.925s
| Adam | epoch: 038 | loss: 1.60527 - acc: 0.3326 | val_loss: 1.60960 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4173  | total loss: [1m[32m1.61552[0m[0m | time: 37.042s
| Adam | epoch: 039 | loss: 1.61552 - acc: 0.3398 | val_loss: 1.60235 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4280  | total loss: [1m[32m1.63245[0m[0m | time: 36.807s
| Adam | epoch: 040 | loss: 1.63245 - acc: 0.3339 | val_loss: 1.59724 - val_acc: 0.3711 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4387  | total loss: [1m[32m1.57881[0m[0m | time: 37.003s
| Adam | epoch: 041 | loss: 1.57881 - acc: 0.3406 | val_loss: 1.59109 - val_acc: 0.3579 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4494  | total loss: [1m[32m1.57904[0m[0m | time: 36.786s
| Adam | epoch: 042 | loss: 1.57904 - acc: 0.3503 | val_loss: 1.60793 - val_acc: 0.3079 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4601  | total loss: [1m[32m1.57393[0m[0m | time: 36.931s
| Adam | epoch: 043 | loss: 1.57393 - acc: 0.3686 | val_loss: 1.59278 - val_acc: 0.3605 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4708  | total loss: [1m[32m1.55874[0m[0m | time: 36.985s
| Adam | epoch: 044 | loss: 1.55874 - acc: 0.3822 | val_loss: 1.58534 - val_acc: 0.3632 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4815  | total loss: [1m[32m1.60763[0m[0m | time: 36.984s
| Adam | epoch: 045 | loss: 1.60763 - acc: 0.3497 | val_loss: 1.57212 - val_acc: 0.3789 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 4922  | total loss: [1m[32m1.58044[0m[0m | time: 37.008s
| Adam | epoch: 046 | loss: 1.58044 - acc: 0.3492 | val_loss: 1.58145 - val_acc: 0.3553 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5029  | total loss: [1m[32m1.60333[0m[0m | time: 36.815s
| Adam | epoch: 047 | loss: 1.60333 - acc: 0.3577 | val_loss: 1.57648 - val_acc: 0.3658 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5136  | total loss: [1m[32m1.60331[0m[0m | time: 36.876s
| Adam | epoch: 048 | loss: 1.60331 - acc: 0.3519 | val_loss: 1.57990 - val_acc: 0.3526 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5243  | total loss: [1m[32m1.59160[0m[0m | time: 37.062s
| Adam | epoch: 049 | loss: 1.59160 - acc: 0.3776 | val_loss: 1.57383 - val_acc: 0.3763 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5350  | total loss: [1m[32m1.57126[0m[0m | time: 37.122s
| Adam | epoch: 050 | loss: 1.57126 - acc: 0.3803 | val_loss: 1.58798 - val_acc: 0.3474 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5457  | total loss: [1m[32m1.58455[0m[0m | time: 36.980s
| Adam | epoch: 051 | loss: 1.58455 - acc: 0.3672 | val_loss: 1.58992 - val_acc: 0.3474 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5564  | total loss: [1m[32m1.60794[0m[0m | time: 37.020s
| Adam | epoch: 052 | loss: 1.60794 - acc: 0.3542 | val_loss: 1.58376 - val_acc: 0.3553 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5671  | total loss: [1m[32m1.55635[0m[0m | time: 36.933s
| Adam | epoch: 053 | loss: 1.55635 - acc: 0.3705 | val_loss: 1.57497 - val_acc: 0.3579 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5778  | total loss: [1m[32m1.57679[0m[0m | time: 37.331s
| Adam | epoch: 054 | loss: 1.57679 - acc: 0.3607 | val_loss: 1.58165 - val_acc: 0.3553 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5885  | total loss: [1m[32m1.55791[0m[0m | time: 36.923s
| Adam | epoch: 055 | loss: 1.55791 - acc: 0.3917 | val_loss: 1.58616 - val_acc: 0.3632 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 5992  | total loss: [1m[32m1.54809[0m[0m | time: 36.926s
| Adam | epoch: 056 | loss: 1.54809 - acc: 0.3957 | val_loss: 1.57389 - val_acc: 0.3789 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6099  | total loss: [1m[32m1.58764[0m[0m | time: 36.908s
| Adam | epoch: 057 | loss: 1.58764 - acc: 0.3658 | val_loss: 1.57628 - val_acc: 0.3658 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6206  | total loss: [1m[32m1.58917[0m[0m | time: 36.813s
| Adam | epoch: 058 | loss: 1.58917 - acc: 0.3818 | val_loss: 1.58902 - val_acc: 0.3579 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6313  | total loss: [1m[32m1.56872[0m[0m | time: 36.937s
| Adam | epoch: 059 | loss: 1.56872 - acc: 0.4011 | val_loss: 1.58297 - val_acc: 0.3605 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6420  | total loss: [1m[32m1.59165[0m[0m | time: 36.792s
| Adam | epoch: 060 | loss: 1.59165 - acc: 0.3702 | val_loss: 1.58053 - val_acc: 0.3658 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6527  | total loss: [1m[32m1.54597[0m[0m | time: 36.809s
| Adam | epoch: 061 | loss: 1.54597 - acc: 0.4195 | val_loss: 1.57713 - val_acc: 0.3711 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6634  | total loss: [1m[32m1.55669[0m[0m | time: 36.870s
| Adam | epoch: 062 | loss: 1.55669 - acc: 0.3771 | val_loss: 1.57410 - val_acc: 0.3632 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6741  | total loss: [1m[32m1.57231[0m[0m | time: 36.840s
| Adam | epoch: 063 | loss: 1.57231 - acc: 0.3785 | val_loss: 1.58130 - val_acc: 0.3658 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6848  | total loss: [1m[32m1.53396[0m[0m | time: 36.831s
| Adam | epoch: 064 | loss: 1.53396 - acc: 0.3990 | val_loss: 1.58058 - val_acc: 0.3526 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 6955  | total loss: [1m[32m1.58576[0m[0m | time: 36.789s
| Adam | epoch: 065 | loss: 1.58576 - acc: 0.3777 | val_loss: 1.58906 - val_acc: 0.3553 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7062  | total loss: [1m[32m1.52417[0m[0m | time: 36.795s
| Adam | epoch: 066 | loss: 1.52417 - acc: 0.3909 | val_loss: 1.57920 - val_acc: 0.3605 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7169  | total loss: [1m[32m1.57786[0m[0m | time: 36.862s
| Adam | epoch: 067 | loss: 1.57786 - acc: 0.3975 | val_loss: 1.58247 - val_acc: 0.3684 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7276  | total loss: [1m[32m1.57933[0m[0m | time: 36.867s
| Adam | epoch: 068 | loss: 1.57933 - acc: 0.3608 | val_loss: 1.57665 - val_acc: 0.3842 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7383  | total loss: [1m[32m1.57638[0m[0m | time: 36.802s
| Adam | epoch: 069 | loss: 1.57638 - acc: 0.3827 | val_loss: 1.58237 - val_acc: 0.3632 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7490  | total loss: [1m[32m1.57974[0m[0m | time: 36.795s
| Adam | epoch: 070 | loss: 1.57974 - acc: 0.3703 | val_loss: 1.57850 - val_acc: 0.3632 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7597  | total loss: [1m[32m1.56431[0m[0m | time: 36.810s
| Adam | epoch: 071 | loss: 1.56431 - acc: 0.3917 | val_loss: 1.58696 - val_acc: 0.3447 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7704  | total loss: [1m[32m1.57591[0m[0m | time: 36.834s
| Adam | epoch: 072 | loss: 1.57591 - acc: 0.3834 | val_loss: 1.57675 - val_acc: 0.3711 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7811  | total loss: [1m[32m1.58265[0m[0m | time: 36.799s
| Adam | epoch: 073 | loss: 1.58265 - acc: 0.3835 | val_loss: 1.58440 - val_acc: 0.3816 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 7918  | total loss: [1m[32m1.56611[0m[0m | time: 36.777s
| Adam | epoch: 074 | loss: 1.56611 - acc: 0.3677 | val_loss: 1.57564 - val_acc: 0.3895 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8025  | total loss: [1m[32m1.58432[0m[0m | time: 36.917s
| Adam | epoch: 075 | loss: 1.58432 - acc: 0.3715 | val_loss: 1.58608 - val_acc: 0.3526 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8132  | total loss: [1m[32m1.55344[0m[0m | time: 37.069s
| Adam | epoch: 076 | loss: 1.55344 - acc: 0.3880 | val_loss: 1.58179 - val_acc: 0.3737 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8239  | total loss: [1m[32m1.55726[0m[0m | time: 36.565s
| Adam | epoch: 077 | loss: 1.55726 - acc: 0.3827 | val_loss: 1.58012 - val_acc: 0.3895 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8346  | total loss: [1m[32m1.52001[0m[0m | time: 38.697s
| Adam | epoch: 078 | loss: 1.52001 - acc: 0.4025 | val_loss: 1.58763 - val_acc: 0.3553 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8453  | total loss: [1m[32m1.62489[0m[0m | time: 36.455s
| Adam | epoch: 079 | loss: 1.62489 - acc: 0.3752 | val_loss: 1.56907 - val_acc: 0.3737 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8560  | total loss: [1m[32m1.52917[0m[0m | time: 39.098s
| Adam | epoch: 080 | loss: 1.52917 - acc: 0.3934 | val_loss: 1.58542 - val_acc: 0.3500 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8667  | total loss: [1m[32m1.58982[0m[0m | time: 36.534s
| Adam | epoch: 081 | loss: 1.58982 - acc: 0.3828 | val_loss: 1.58341 - val_acc: 0.3579 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8774  | total loss: [1m[32m1.54369[0m[0m | time: 36.477s
| Adam | epoch: 082 | loss: 1.54369 - acc: 0.4128 | val_loss: 1.57946 - val_acc: 0.3579 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8881  | total loss: [1m[32m1.54923[0m[0m | time: 38.645s
| Adam | epoch: 083 | loss: 1.54923 - acc: 0.3890 | val_loss: 1.57925 - val_acc: 0.3789 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 8988  | total loss: [1m[32m1.55767[0m[0m | time: 39.341s
| Adam | epoch: 084 | loss: 1.55767 - acc: 0.3829 | val_loss: 1.58599 - val_acc: 0.3553 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9095  | total loss: [1m[32m1.55827[0m[0m | time: 38.768s
| Adam | epoch: 085 | loss: 1.55827 - acc: 0.4017 | val_loss: 1.57517 - val_acc: 0.3842 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9202  | total loss: [1m[32m1.56109[0m[0m | time: 38.879s
| Adam | epoch: 086 | loss: 1.56109 - acc: 0.3681 | val_loss: 1.57989 - val_acc: 0.3737 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9309  | total loss: [1m[32m1.59727[0m[0m | time: 40.045s
| Adam | epoch: 087 | loss: 1.59727 - acc: 0.3691 | val_loss: 1.58777 - val_acc: 0.3526 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9416  | total loss: [1m[32m1.56514[0m[0m | time: 37.545s
| Adam | epoch: 088 | loss: 1.56514 - acc: 0.3757 | val_loss: 1.57544 - val_acc: 0.3789 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9523  | total loss: [1m[32m1.57313[0m[0m | time: 37.445s
| Adam | epoch: 089 | loss: 1.57313 - acc: 0.4029 | val_loss: 1.55534 - val_acc: 0.3684 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9630  | total loss: [1m[32m1.57588[0m[0m | time: 37.356s
| Adam | epoch: 090 | loss: 1.57588 - acc: 0.3829 | val_loss: 1.59110 - val_acc: 0.3579 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9737  | total loss: [1m[32m1.57491[0m[0m | time: 39.756s
| Adam | epoch: 091 | loss: 1.57491 - acc: 0.3734 | val_loss: 1.56711 - val_acc: 0.3921 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9844  | total loss: [1m[32m1.55744[0m[0m | time: 38.352s
| Adam | epoch: 092 | loss: 1.55744 - acc: 0.3757 | val_loss: 1.57250 - val_acc: 0.3947 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 9951  | total loss: [1m[32m1.56683[0m[0m | time: 38.933s
| Adam | epoch: 093 | loss: 1.56683 - acc: 0.3840 | val_loss: 1.56076 - val_acc: 0.3974 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10058  | total loss: [1m[32m1.54966[0m[0m | time: 38.500s
| Adam | epoch: 094 | loss: 1.54966 - acc: 0.4181 | val_loss: 1.54561 - val_acc: 0.3974 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10165  | total loss: [1m[32m1.49687[0m[0m | time: 39.352s
| Adam | epoch: 095 | loss: 1.49687 - acc: 0.4542 | val_loss: 1.53841 - val_acc: 0.3947 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10272  | total loss: [1m[32m1.54455[0m[0m | time: 39.671s
| Adam | epoch: 096 | loss: 1.54455 - acc: 0.4257 | val_loss: 1.53161 - val_acc: 0.3921 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10379  | total loss: [1m[32m1.52728[0m[0m | time: 37.319s
| Adam | epoch: 097 | loss: 1.52728 - acc: 0.4282 | val_loss: 1.52449 - val_acc: 0.3947 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10486  | total loss: [1m[32m1.55043[0m[0m | time: 40.074s
| Adam | epoch: 098 | loss: 1.55043 - acc: 0.3951 | val_loss: 1.53813 - val_acc: 0.3921 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10593  | total loss: [1m[32m1.48612[0m[0m | time: 39.189s
| Adam | epoch: 099 | loss: 1.48612 - acc: 0.4702 | val_loss: 1.52556 - val_acc: 0.4053 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

Training Step: 10700  | total loss: [1m[32m1.53467[0m[0m | time: 39.257s
| Adam | epoch: 100 | loss: 1.53467 - acc: 0.4095 | val_loss: 1.54690 - val_acc: 0.3895 -- iter: 3421/3421 

 -------------------------------------------------------------------------------- 

