Training Step: 108  | total loss: 1.56903 | time: 9.877s
| Adam | epoch: 001 | loss: 1.56903 - acc: 0.3520 | val_loss: 1.57438 - val_acc: 0.3701 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 216  | total loss: 1.53121 | time: 9.020s
| Adam | epoch: 002 | loss: 1.53121 - acc: 0.4031 | val_loss: 1.48644 - val_acc: 0.4724 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 324  | total loss: 1.35243 | time: 8.989s
| Adam | epoch: 003 | loss: 1.35243 - acc: 0.4903 | val_loss: 1.40444 - val_acc: 0.5092 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 432  | total loss: 1.23191 | time: 9.117s
| Adam | epoch: 004 | loss: 1.23191 - acc: 0.5668 | val_loss: 1.34872 - val_acc: 0.5276 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 540  | total loss: 1.02358 | time: 9.008s
| Adam | epoch: 005 | loss: 1.02358 - acc: 0.6593 | val_loss: 1.32068 - val_acc: 0.5433 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 648  | total loss: 0.80860 | time: 9.008s
| Adam | epoch: 006 | loss: 0.80860 - acc: 0.7122 | val_loss: 1.31406 - val_acc: 0.5354 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 756  | total loss: 0.69513 | time: 9.028s
| Adam | epoch: 007 | loss: 0.69513 - acc: 0.7534 | val_loss: 1.32750 - val_acc: 0.5276 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 864  | total loss: 0.59182 | time: 9.017s
| Adam | epoch: 008 | loss: 0.59182 - acc: 0.7819 | val_loss: 1.34927 - val_acc: 0.5223 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 972  | total loss: 0.48380 | time: 9.031s
| Adam | epoch: 009 | loss: 0.48380 - acc: 0.8298 | val_loss: 1.41204 - val_acc: 0.5039 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1080  | total loss: 0.36756 | time: 9.008s
| Adam | epoch: 010 | loss: 0.36756 - acc: 0.8844 | val_loss: 1.46609 - val_acc: 0.5039 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1188  | total loss: 0.31345 | time: 9.135s
| Adam | epoch: 011 | loss: 0.31345 - acc: 0.9024 | val_loss: 1.55986 - val_acc: 0.4882 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1296  | total loss: 0.24418 | time: 9.107s
| Adam | epoch: 012 | loss: 0.24418 - acc: 0.9400 | val_loss: 1.58236 - val_acc: 0.4934 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1404  | total loss: 0.19153 | time: 9.238s
| Adam | epoch: 013 | loss: 0.19153 - acc: 0.9623 | val_loss: 1.62169 - val_acc: 0.5039 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1512  | total loss: 0.14837 | time: 9.100s
| Adam | epoch: 014 | loss: 0.14837 - acc: 0.9687 | val_loss: 1.69455 - val_acc: 0.4829 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1620  | total loss: 0.12939 | time: 9.132s
| Adam | epoch: 015 | loss: 0.12939 - acc: 0.9744 | val_loss: 1.75400 - val_acc: 0.4934 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1728  | total loss: 0.11504 | time: 9.033s
| Adam | epoch: 016 | loss: 0.11504 - acc: 0.9803 | val_loss: 1.79490 - val_acc: 0.4829 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1836  | total loss: 0.10729 | time: 9.056s
| Adam | epoch: 017 | loss: 0.10729 - acc: 0.9822 | val_loss: 1.82376 - val_acc: 0.4777 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1944  | total loss: 0.08866 | time: 9.005s
| Adam | epoch: 018 | loss: 0.08866 - acc: 0.9901 | val_loss: 1.85533 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2052  | total loss: 0.06822 | time: 9.007s
| Adam | epoch: 019 | loss: 0.06822 - acc: 0.9878 | val_loss: 1.87338 - val_acc: 0.4803 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2160  | total loss: 0.05920 | time: 9.036s
| Adam | epoch: 020 | loss: 0.05920 - acc: 0.9968 | val_loss: 1.89239 - val_acc: 0.4882 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2268  | total loss: 0.07415 | time: 9.034s
| Adam | epoch: 021 | loss: 0.07415 - acc: 0.9922 | val_loss: 1.94789 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2376  | total loss: 0.06489 | time: 9.017s
| Adam | epoch: 022 | loss: 0.06489 - acc: 0.9937 | val_loss: 1.96669 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2484  | total loss: 0.05430 | time: 9.029s
| Adam | epoch: 023 | loss: 0.05430 - acc: 0.9922 | val_loss: 2.02181 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2592  | total loss: 0.05278 | time: 9.022s
| Adam | epoch: 024 | loss: 0.05278 - acc: 0.9958 | val_loss: 1.96437 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2700  | total loss: 0.05551 | time: 9.023s
| Adam | epoch: 025 | loss: 0.05551 - acc: 0.9938 | val_loss: 1.97304 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2808  | total loss: 0.04497 | time: 9.015s
| Adam | epoch: 026 | loss: 0.04497 - acc: 0.9922 | val_loss: 1.97402 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2916  | total loss: 0.05471 | time: 9.069s
| Adam | epoch: 027 | loss: 0.05471 - acc: 0.9929 | val_loss: 1.96969 - val_acc: 0.4751 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3024  | total loss: 0.04623 | time: 9.034s
| Adam | epoch: 028 | loss: 0.04623 - acc: 0.9931 | val_loss: 1.99514 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3132  | total loss: 0.03981 | time: 9.039s
| Adam | epoch: 029 | loss: 0.03981 - acc: 0.9976 | val_loss: 2.03312 - val_acc: 0.4724 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3240  | total loss: 0.03758 | time: 9.021s
| Adam | epoch: 030 | loss: 0.03758 - acc: 0.9988 | val_loss: 2.05734 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3348  | total loss: 0.04757 | time: 9.027s
| Adam | epoch: 031 | loss: 0.04757 - acc: 0.9896 | val_loss: 2.10127 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3456  | total loss: 0.03815 | time: 9.038s
| Adam | epoch: 032 | loss: 0.03815 - acc: 0.9974 | val_loss: 2.13311 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3564  | total loss: 0.03481 | time: 9.046s
| Adam | epoch: 033 | loss: 0.03481 - acc: 0.9989 | val_loss: 2.17362 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3672  | total loss: 0.03331 | time: 9.013s
| Adam | epoch: 034 | loss: 0.03331 - acc: 0.9969 | val_loss: 2.13912 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3780  | total loss: 0.04018 | time: 9.007s
| Adam | epoch: 035 | loss: 0.04018 - acc: 0.9925 | val_loss: 2.12612 - val_acc: 0.4488 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3888  | total loss: 0.03806 | time: 9.362s
| Adam | epoch: 036 | loss: 0.03806 - acc: 0.9943 | val_loss: 2.18300 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3996  | total loss: 0.03654 | time: 9.148s
| Adam | epoch: 037 | loss: 0.03654 - acc: 0.9971 | val_loss: 2.17678 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4104  | total loss: 0.02574 | time: 9.037s
| Adam | epoch: 038 | loss: 0.02574 - acc: 0.9958 | val_loss: 2.20083 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4212  | total loss: 0.02264 | time: 9.226s
| Adam | epoch: 039 | loss: 0.02264 - acc: 0.9991 | val_loss: 2.15102 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4320  | total loss: 0.02397 | time: 10.277s
| Adam | epoch: 040 | loss: 0.02397 - acc: 0.9993 | val_loss: 2.21396 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4428  | total loss: 0.02534 | time: 10.042s
| Adam | epoch: 041 | loss: 0.02534 - acc: 0.9994 | val_loss: 2.21293 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4536  | total loss: 0.01811 | time: 9.656s
| Adam | epoch: 042 | loss: 0.01811 - acc: 0.9988 | val_loss: 2.23366 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4644  | total loss: 0.01932 | time: 10.535s
| Adam | epoch: 043 | loss: 0.01932 - acc: 0.9994 | val_loss: 2.23148 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4752  | total loss: 0.01883 | time: 10.036s
| Adam | epoch: 044 | loss: 0.01883 - acc: 0.9983 | val_loss: 2.27535 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4860  | total loss: 0.02094 | time: 9.506s
| Adam | epoch: 045 | loss: 0.02094 - acc: 0.9987 | val_loss: 2.28979 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4968  | total loss: 0.02131 | time: 9.445s
| Adam | epoch: 046 | loss: 0.02131 - acc: 0.9994 | val_loss: 2.28779 - val_acc: 0.4751 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5076  | total loss: 0.01721 | time: 9.777s
| Adam | epoch: 047 | loss: 0.01721 - acc: 0.9999 | val_loss: 2.32865 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5184  | total loss: 0.01936 | time: 9.942s
| Adam | epoch: 048 | loss: 0.01936 - acc: 0.9990 | val_loss: 2.26260 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5292  | total loss: 0.01947 | time: 9.599s
| Adam | epoch: 049 | loss: 0.01947 - acc: 0.9973 | val_loss: 2.32437 - val_acc: 0.4488 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5400  | total loss: 0.02168 | time: 9.518s
| Adam | epoch: 050 | loss: 0.02168 - acc: 0.9966 | val_loss: 2.44310 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5508  | total loss: 0.01344 | time: 9.385s
| Adam | epoch: 051 | loss: 0.01344 - acc: 1.0000 | val_loss: 2.40484 - val_acc: 0.4488 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5616  | total loss: 0.01329 | time: 10.097s
| Adam | epoch: 052 | loss: 0.01329 - acc: 0.9989 | val_loss: 2.45142 - val_acc: 0.4409 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5724  | total loss: 0.01853 | time: 9.875s
| Adam | epoch: 053 | loss: 0.01853 - acc: 0.9934 | val_loss: 2.42984 - val_acc: 0.4357 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5832  | total loss: 0.01473 | time: 9.651s
| Adam | epoch: 054 | loss: 0.01473 - acc: 0.9983 | val_loss: 2.49598 - val_acc: 0.4357 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5940  | total loss: 0.02215 | time: 9.226s
| Adam | epoch: 055 | loss: 0.02215 - acc: 0.9975 | val_loss: 2.45813 - val_acc: 0.4488 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6048  | total loss: 0.01271 | time: 9.875s
| Adam | epoch: 056 | loss: 0.01271 - acc: 0.9987 | val_loss: 2.47656 - val_acc: 0.4436 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6156  | total loss: 0.02140 | time: 10.149s
| Adam | epoch: 057 | loss: 0.02140 - acc: 0.9948 | val_loss: 2.45809 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6264  | total loss: 0.01915 | time: 10.386s
| Adam | epoch: 058 | loss: 0.01915 - acc: 0.9947 | val_loss: 2.49863 - val_acc: 0.4462 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6372  | total loss: 0.02036 | time: 9.473s
| Adam | epoch: 059 | loss: 0.02036 - acc: 0.9930 | val_loss: 2.43054 - val_acc: 0.4436 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6480  | total loss: 0.01967 | time: 9.365s
| Adam | epoch: 060 | loss: 0.01967 - acc: 0.9917 | val_loss: 2.51938 - val_acc: 0.4488 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6588  | total loss: 0.01711 | time: 9.813s
| Adam | epoch: 061 | loss: 0.01711 - acc: 0.9994 | val_loss: 2.49778 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6696  | total loss: 0.01235 | time: 9.134s
| Adam | epoch: 062 | loss: 0.01235 - acc: 0.9977 | val_loss: 2.51069 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6804  | total loss: 0.01465 | time: 9.040s
| Adam | epoch: 063 | loss: 0.01465 - acc: 0.9996 | val_loss: 2.52746 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6912  | total loss: 0.01472 | time: 9.159s
| Adam | epoch: 064 | loss: 0.01472 - acc: 0.9981 | val_loss: 2.56687 - val_acc: 0.4724 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7020  | total loss: 0.01256 | time: 9.133s
| Adam | epoch: 065 | loss: 0.01256 - acc: 0.9999 | val_loss: 2.65674 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7128  | total loss: 0.01528 | time: 8.997s
| Adam | epoch: 066 | loss: 0.01528 - acc: 0.9980 | val_loss: 2.56630 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7236  | total loss: 0.01221 | time: 8.987s
| Adam | epoch: 067 | loss: 0.01221 - acc: 0.9996 | val_loss: 2.66319 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7344  | total loss: 0.00882 | time: 9.006s
| Adam | epoch: 068 | loss: 0.00882 - acc: 0.9992 | val_loss: 2.58700 - val_acc: 0.4409 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7452  | total loss: 0.01247 | time: 8.985s
| Adam | epoch: 069 | loss: 0.01247 - acc: 0.9987 | val_loss: 2.63874 - val_acc: 0.4488 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7560  | total loss: 0.01215 | time: 8.980s
| Adam | epoch: 070 | loss: 0.01215 - acc: 0.9960 | val_loss: 2.64805 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7668  | total loss: 0.01100 | time: 9.022s
| Adam | epoch: 071 | loss: 0.01100 - acc: 0.9993 | val_loss: 2.65946 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7776  | total loss: 0.01517 | time: 9.009s
| Adam | epoch: 072 | loss: 0.01517 - acc: 0.9953 | val_loss: 2.62034 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7884  | total loss: 0.01176 | time: 8.994s
| Adam | epoch: 073 | loss: 0.01176 - acc: 0.9976 | val_loss: 2.77151 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7992  | total loss: 0.01015 | time: 8.997s
| Adam | epoch: 074 | loss: 0.01015 - acc: 0.9996 | val_loss: 2.70924 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8100  | total loss: 0.01199 | time: 8.973s
| Adam | epoch: 075 | loss: 0.01199 - acc: 0.9973 | val_loss: 2.74001 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8208  | total loss: 0.00754 | time: 9.006s
| Adam | epoch: 076 | loss: 0.00754 - acc: 1.0000 | val_loss: 2.76735 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8316  | total loss: 0.01545 | time: 8.974s
| Adam | epoch: 077 | loss: 0.01545 - acc: 0.9962 | val_loss: 2.68941 - val_acc: 0.4436 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8424  | total loss: 0.01727 | time: 8.991s
| Adam | epoch: 078 | loss: 0.01727 - acc: 0.9968 | val_loss: 2.73224 - val_acc: 0.4436 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8532  | total loss: 0.00511 | time: 8.996s
| Adam | epoch: 079 | loss: 0.00511 - acc: 0.9995 | val_loss: 2.78425 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8640  | total loss: 0.00869 | time: 9.354s
| Adam | epoch: 080 | loss: 0.00869 - acc: 0.9996 | val_loss: 2.72894 - val_acc: 0.4488 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8748  | total loss: 0.00839 | time: 9.268s
| Adam | epoch: 081 | loss: 0.00839 - acc: 0.9994 | val_loss: 2.73036 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8856  | total loss: 0.00989 | time: 8.999s
| Adam | epoch: 082 | loss: 0.00989 - acc: 0.9976 | val_loss: 2.74365 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8964  | total loss: 0.00992 | time: 8.985s
| Adam | epoch: 083 | loss: 0.00992 - acc: 0.9987 | val_loss: 2.74844 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9072  | total loss: 0.00879 | time: 8.984s
| Adam | epoch: 084 | loss: 0.00879 - acc: 0.9983 | val_loss: 2.80185 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9180  | total loss: 0.00747 | time: 8.984s
| Adam | epoch: 085 | loss: 0.00747 - acc: 0.9987 | val_loss: 2.82141 - val_acc: 0.4462 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9288  | total loss: 0.00817 | time: 8.988s
| Adam | epoch: 086 | loss: 0.00817 - acc: 0.9980 | val_loss: 2.84924 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9396  | total loss: 0.00566 | time: 8.988s
| Adam | epoch: 087 | loss: 0.00566 - acc: 0.9998 | val_loss: 2.70186 - val_acc: 0.4724 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9504  | total loss: 0.00812 | time: 8.988s
| Adam | epoch: 088 | loss: 0.00812 - acc: 0.9985 | val_loss: 2.68956 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9612  | total loss: 0.00761 | time: 9.028s
| Adam | epoch: 089 | loss: 0.00761 - acc: 0.9979 | val_loss: 2.70929 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9720  | total loss: 0.00752 | time: 8.984s
| Adam | epoch: 090 | loss: 0.00752 - acc: 1.0000 | val_loss: 2.84238 - val_acc: 0.4724 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9828  | total loss: 0.00511 | time: 8.975s
| Adam | epoch: 091 | loss: 0.00511 - acc: 1.0000 | val_loss: 2.80027 - val_acc: 0.4829 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9936  | total loss: 0.00565 | time: 8.982s
| Adam | epoch: 092 | loss: 0.00565 - acc: 1.0000 | val_loss: 2.88844 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10044  | total loss: 0.00949 | time: 8.982s
| Adam | epoch: 093 | loss: 0.00949 - acc: 0.9978 | val_loss: 2.87271 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10152  | total loss: 0.00916 | time: 8.990s
| Adam | epoch: 094 | loss: 0.00916 - acc: 0.9985 | val_loss: 2.91492 - val_acc: 0.4488 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10260  | total loss: 0.00687 | time: 8.976s
| Adam | epoch: 095 | loss: 0.00687 - acc: 0.9993 | val_loss: 2.97752 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10368  | total loss: 0.00554 | time: 8.999s
| Adam | epoch: 096 | loss: 0.00554 - acc: 0.9995 | val_loss: 3.00310 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10476  | total loss: 0.01366 | time: 8.973s
| Adam | epoch: 097 | loss: 0.01366 - acc: 0.9953 | val_loss: 2.94949 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10584  | total loss: 0.00474 | time: 8.982s
| Adam | epoch: 098 | loss: 0.00474 - acc: 1.0000 | val_loss: 2.95842 - val_acc: 0.4462 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10692  | total loss: 0.01139 | time: 8.990s
| Adam | epoch: 099 | loss: 0.01139 - acc: 0.9961 | val_loss: 3.16788 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10800  | total loss: 0.00799 | time: 9.002s
| Adam | epoch: 100 | loss: 0.00799 - acc: 0.9981 | val_loss: 3.09519 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

