Training Step: 108  | total loss: 1.59214 | time: 4.856s
| Adam | epoch: 001 | loss: 1.59214 - acc: 0.3730 | val_loss: 1.60421 - val_acc: 0.3202 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 216  | total loss: 1.47308 | time: 3.921s
| Adam | epoch: 002 | loss: 1.47308 - acc: 0.4408 | val_loss: 1.53444 - val_acc: 0.4331 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 324  | total loss: 1.38042 | time: 3.947s
| Adam | epoch: 003 | loss: 1.38042 - acc: 0.4839 | val_loss: 1.43566 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 432  | total loss: 1.29772 | time: 3.904s
| Adam | epoch: 004 | loss: 1.29772 - acc: 0.5131 | val_loss: 1.34952 - val_acc: 0.4882 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 540  | total loss: 1.24301 | time: 3.921s
| Adam | epoch: 005 | loss: 1.24301 - acc: 0.5340 | val_loss: 1.27142 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 648  | total loss: 1.10793 | time: 3.924s
| Adam | epoch: 006 | loss: 1.10793 - acc: 0.5898 | val_loss: 1.22231 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 756  | total loss: 1.06816 | time: 3.911s
| Adam | epoch: 007 | loss: 1.06816 - acc: 0.6448 | val_loss: 1.16761 - val_acc: 0.6063 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 864  | total loss: 1.02753 | time: 3.916s
| Adam | epoch: 008 | loss: 1.02753 - acc: 0.6323 | val_loss: 1.13295 - val_acc: 0.5906 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 972  | total loss: 0.99324 | time: 3.934s
| Adam | epoch: 009 | loss: 0.99324 - acc: 0.6272 | val_loss: 1.10546 - val_acc: 0.6299 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1080  | total loss: 0.93301 | time: 3.939s
| Adam | epoch: 010 | loss: 0.93301 - acc: 0.6592 | val_loss: 1.13655 - val_acc: 0.5932 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1188  | total loss: 0.83405 | time: 3.906s
| Adam | epoch: 011 | loss: 0.83405 - acc: 0.7147 | val_loss: 1.07328 - val_acc: 0.6063 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1296  | total loss: 0.82710 | time: 3.925s
| Adam | epoch: 012 | loss: 0.82710 - acc: 0.7325 | val_loss: 1.08243 - val_acc: 0.6037 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1404  | total loss: 0.81349 | time: 3.923s
| Adam | epoch: 013 | loss: 0.81349 - acc: 0.7268 | val_loss: 1.06185 - val_acc: 0.6142 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1512  | total loss: 0.78803 | time: 4.034s
| Adam | epoch: 014 | loss: 0.78803 - acc: 0.7328 | val_loss: 1.06656 - val_acc: 0.6299 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1620  | total loss: 0.66951 | time: 3.965s
| Adam | epoch: 015 | loss: 0.66951 - acc: 0.7742 | val_loss: 1.07833 - val_acc: 0.6273 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1728  | total loss: 0.67520 | time: 3.951s
| Adam | epoch: 016 | loss: 0.67520 - acc: 0.8048 | val_loss: 1.05058 - val_acc: 0.6378 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1836  | total loss: 0.57282 | time: 3.923s
| Adam | epoch: 017 | loss: 0.57282 - acc: 0.8299 | val_loss: 1.10411 - val_acc: 0.6168 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1944  | total loss: 0.52934 | time: 3.902s
| Adam | epoch: 018 | loss: 0.52934 - acc: 0.8271 | val_loss: 1.06534 - val_acc: 0.6325 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2052  | total loss: 0.56375 | time: 3.911s
| Adam | epoch: 019 | loss: 0.56375 - acc: 0.7938 | val_loss: 1.13240 - val_acc: 0.6168 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2160  | total loss: 0.49673 | time: 3.943s
| Adam | epoch: 020 | loss: 0.49673 - acc: 0.8342 | val_loss: 1.04476 - val_acc: 0.6483 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2268  | total loss: 0.45934 | time: 3.951s
| Adam | epoch: 021 | loss: 0.45934 - acc: 0.8703 | val_loss: 1.06560 - val_acc: 0.6378 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2376  | total loss: 0.42181 | time: 3.922s
| Adam | epoch: 022 | loss: 0.42181 - acc: 0.8797 | val_loss: 1.06287 - val_acc: 0.6325 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2484  | total loss: 0.43930 | time: 3.911s
| Adam | epoch: 023 | loss: 0.43930 - acc: 0.8620 | val_loss: 1.08283 - val_acc: 0.6352 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2592  | total loss: 0.41905 | time: 3.905s
| Adam | epoch: 024 | loss: 0.41905 - acc: 0.8591 | val_loss: 1.12836 - val_acc: 0.6220 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2700  | total loss: 0.37109 | time: 3.926s
| Adam | epoch: 025 | loss: 0.37109 - acc: 0.8979 | val_loss: 1.08700 - val_acc: 0.6352 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2808  | total loss: 0.55960 | time: 3.916s
| Adam | epoch: 026 | loss: 0.55960 - acc: 0.8427 | val_loss: 1.09458 - val_acc: 0.6404 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2916  | total loss: 0.35480 | time: 3.921s
| Adam | epoch: 027 | loss: 0.35480 - acc: 0.8852 | val_loss: 1.10884 - val_acc: 0.6509 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3024  | total loss: 0.30072 | time: 3.927s
| Adam | epoch: 028 | loss: 0.30072 - acc: 0.9196 | val_loss: 1.09198 - val_acc: 0.6588 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3132  | total loss: 0.34391 | time: 3.930s
| Adam | epoch: 029 | loss: 0.34391 - acc: 0.8910 | val_loss: 1.09599 - val_acc: 0.6535 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3240  | total loss: 0.31960 | time: 3.898s
| Adam | epoch: 030 | loss: 0.31960 - acc: 0.8934 | val_loss: 1.15841 - val_acc: 0.6430 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3348  | total loss: 0.26741 | time: 3.933s
| Adam | epoch: 031 | loss: 0.26741 - acc: 0.9318 | val_loss: 1.12769 - val_acc: 0.6404 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3456  | total loss: 0.28076 | time: 3.907s
| Adam | epoch: 032 | loss: 0.28076 - acc: 0.9282 | val_loss: 1.11002 - val_acc: 0.6640 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3564  | total loss: 0.27405 | time: 3.944s
| Adam | epoch: 033 | loss: 0.27405 - acc: 0.9318 | val_loss: 1.15087 - val_acc: 0.6509 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3672  | total loss: 0.26289 | time: 3.917s
| Adam | epoch: 034 | loss: 0.26289 - acc: 0.9259 | val_loss: 1.17538 - val_acc: 0.6430 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3780  | total loss: 0.24667 | time: 3.898s
| Adam | epoch: 035 | loss: 0.24667 - acc: 0.9359 | val_loss: 1.20149 - val_acc: 0.6299 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3888  | total loss: 0.21193 | time: 3.912s
| Adam | epoch: 036 | loss: 0.21193 - acc: 0.9579 | val_loss: 1.16543 - val_acc: 0.6535 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3996  | total loss: 0.21589 | time: 3.913s
| Adam | epoch: 037 | loss: 0.21589 - acc: 0.9453 | val_loss: 1.19623 - val_acc: 0.6562 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4104  | total loss: 0.20036 | time: 3.914s
| Adam | epoch: 038 | loss: 0.20036 - acc: 0.9514 | val_loss: 1.18357 - val_acc: 0.6509 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4212  | total loss: 0.19765 | time: 3.909s
| Adam | epoch: 039 | loss: 0.19765 - acc: 0.9552 | val_loss: 1.20834 - val_acc: 0.6378 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4320  | total loss: 0.21297 | time: 3.931s
| Adam | epoch: 040 | loss: 0.21297 - acc: 0.9427 | val_loss: 1.23195 - val_acc: 0.6325 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4428  | total loss: 0.19014 | time: 3.932s
| Adam | epoch: 041 | loss: 0.19014 - acc: 0.9621 | val_loss: 1.22595 - val_acc: 0.6483 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4536  | total loss: 0.19720 | time: 3.911s
| Adam | epoch: 042 | loss: 0.19720 - acc: 0.9448 | val_loss: 1.31462 - val_acc: 0.6037 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4644  | total loss: 0.17771 | time: 3.926s
| Adam | epoch: 043 | loss: 0.17771 - acc: 0.9465 | val_loss: 1.26992 - val_acc: 0.6457 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4752  | total loss: 0.17611 | time: 3.926s
| Adam | epoch: 044 | loss: 0.17611 - acc: 0.9602 | val_loss: 1.25853 - val_acc: 0.6404 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4860  | total loss: 0.15573 | time: 3.909s
| Adam | epoch: 045 | loss: 0.15573 - acc: 0.9533 | val_loss: 1.27014 - val_acc: 0.6352 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4968  | total loss: 0.14605 | time: 3.936s
| Adam | epoch: 046 | loss: 0.14605 - acc: 0.9676 | val_loss: 1.29229 - val_acc: 0.6325 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5076  | total loss: 0.14120 | time: 3.917s
| Adam | epoch: 047 | loss: 0.14120 - acc: 0.9717 | val_loss: 1.24273 - val_acc: 0.6562 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5184  | total loss: 0.12623 | time: 3.898s
| Adam | epoch: 048 | loss: 0.12623 - acc: 0.9675 | val_loss: 1.28166 - val_acc: 0.6220 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5292  | total loss: 0.13321 | time: 3.940s
| Adam | epoch: 049 | loss: 0.13321 - acc: 0.9662 | val_loss: 1.37262 - val_acc: 0.6142 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5400  | total loss: 0.11890 | time: 3.929s
| Adam | epoch: 050 | loss: 0.11890 - acc: 0.9765 | val_loss: 1.32018 - val_acc: 0.6352 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5508  | total loss: 0.11219 | time: 3.934s
| Adam | epoch: 051 | loss: 0.11219 - acc: 0.9783 | val_loss: 1.36407 - val_acc: 0.6325 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5616  | total loss: 0.12504 | time: 3.923s
| Adam | epoch: 052 | loss: 0.12504 - acc: 0.9721 | val_loss: 1.33435 - val_acc: 0.6509 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5724  | total loss: 0.12273 | time: 3.929s
| Adam | epoch: 053 | loss: 0.12273 - acc: 0.9662 | val_loss: 1.30370 - val_acc: 0.6457 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5832  | total loss: 0.10443 | time: 3.909s
| Adam | epoch: 054 | loss: 0.10443 - acc: 0.9808 | val_loss: 1.35578 - val_acc: 0.6247 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5940  | total loss: 0.13867 | time: 3.913s
| Adam | epoch: 055 | loss: 0.13867 - acc: 0.9656 | val_loss: 1.41474 - val_acc: 0.6115 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6048  | total loss: 0.14638 | time: 3.919s
| Adam | epoch: 056 | loss: 0.14638 - acc: 0.9591 | val_loss: 1.32517 - val_acc: 0.6378 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6156  | total loss: 0.10648 | time: 3.929s
| Adam | epoch: 057 | loss: 0.10648 - acc: 0.9782 | val_loss: 1.42116 - val_acc: 0.6037 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6264  | total loss: 0.08590 | time: 3.935s
| Adam | epoch: 058 | loss: 0.08590 - acc: 0.9842 | val_loss: 1.33970 - val_acc: 0.6404 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6372  | total loss: 0.11256 | time: 3.926s
| Adam | epoch: 059 | loss: 0.11256 - acc: 0.9706 | val_loss: 1.39351 - val_acc: 0.6115 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6480  | total loss: 0.09246 | time: 3.928s
| Adam | epoch: 060 | loss: 0.09246 - acc: 0.9841 | val_loss: 1.37004 - val_acc: 0.6535 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6588  | total loss: 0.10235 | time: 3.927s
| Adam | epoch: 061 | loss: 0.10235 - acc: 0.9761 | val_loss: 1.49244 - val_acc: 0.6194 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6696  | total loss: 0.11230 | time: 3.903s
| Adam | epoch: 062 | loss: 0.11230 - acc: 0.9657 | val_loss: 1.43606 - val_acc: 0.6168 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6804  | total loss: 0.10362 | time: 3.913s
| Adam | epoch: 063 | loss: 0.10362 - acc: 0.9712 | val_loss: 1.45833 - val_acc: 0.6168 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6912  | total loss: 0.09926 | time: 3.944s
| Adam | epoch: 064 | loss: 0.09926 - acc: 0.9699 | val_loss: 1.39846 - val_acc: 0.6247 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7020  | total loss: 0.10987 | time: 3.910s
| Adam | epoch: 065 | loss: 0.10987 - acc: 0.9713 | val_loss: 1.41938 - val_acc: 0.6220 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7128  | total loss: 0.07940 | time: 3.918s
| Adam | epoch: 066 | loss: 0.07940 - acc: 0.9853 | val_loss: 1.44832 - val_acc: 0.6247 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7236  | total loss: 0.08856 | time: 3.933s
| Adam | epoch: 067 | loss: 0.08856 - acc: 0.9761 | val_loss: 1.45583 - val_acc: 0.6430 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7344  | total loss: 0.10966 | time: 3.913s
| Adam | epoch: 068 | loss: 0.10966 - acc: 0.9738 | val_loss: 1.42079 - val_acc: 0.6273 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7452  | total loss: 0.09337 | time: 3.913s
| Adam | epoch: 069 | loss: 0.09337 - acc: 0.9800 | val_loss: 1.49303 - val_acc: 0.6273 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7560  | total loss: 0.06758 | time: 3.932s
| Adam | epoch: 070 | loss: 0.06758 - acc: 0.9871 | val_loss: 1.49424 - val_acc: 0.6220 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7668  | total loss: 0.08687 | time: 3.944s
| Adam | epoch: 071 | loss: 0.08687 - acc: 0.9770 | val_loss: 1.48152 - val_acc: 0.6273 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7776  | total loss: 0.07537 | time: 3.925s
| Adam | epoch: 072 | loss: 0.07537 - acc: 0.9824 | val_loss: 1.62251 - val_acc: 0.5932 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7884  | total loss: 0.08684 | time: 3.912s
| Adam | epoch: 073 | loss: 0.08684 - acc: 0.9805 | val_loss: 1.54577 - val_acc: 0.6037 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7992  | total loss: 0.07072 | time: 3.926s
| Adam | epoch: 074 | loss: 0.07072 - acc: 0.9859 | val_loss: 1.54788 - val_acc: 0.6168 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8100  | total loss: 0.08611 | time: 3.923s
| Adam | epoch: 075 | loss: 0.08611 - acc: 0.9775 | val_loss: 1.53451 - val_acc: 0.6352 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8208  | total loss: 0.10568 | time: 3.911s
| Adam | epoch: 076 | loss: 0.10568 - acc: 0.9615 | val_loss: 1.51837 - val_acc: 0.6247 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8316  | total loss: 0.07832 | time: 3.966s
| Adam | epoch: 077 | loss: 0.07832 - acc: 0.9848 | val_loss: 1.58831 - val_acc: 0.6142 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8424  | total loss: 0.05574 | time: 3.941s
| Adam | epoch: 078 | loss: 0.05574 - acc: 0.9926 | val_loss: 1.60134 - val_acc: 0.6273 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8532  | total loss: 0.06258 | time: 3.920s
| Adam | epoch: 079 | loss: 0.06258 - acc: 0.9843 | val_loss: 1.58177 - val_acc: 0.6273 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8640  | total loss: 0.06935 | time: 3.927s
| Adam | epoch: 080 | loss: 0.06935 - acc: 0.9816 | val_loss: 1.55007 - val_acc: 0.6247 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8748  | total loss: 0.08942 | time: 3.948s
| Adam | epoch: 081 | loss: 0.08942 - acc: 0.9802 | val_loss: 1.50337 - val_acc: 0.6325 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8856  | total loss: 0.08895 | time: 3.934s
| Adam | epoch: 082 | loss: 0.08895 - acc: 0.9777 | val_loss: 1.46396 - val_acc: 0.6273 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8964  | total loss: 0.08013 | time: 3.906s
| Adam | epoch: 083 | loss: 0.08013 - acc: 0.9716 | val_loss: 1.64999 - val_acc: 0.6115 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9072  | total loss: 0.06799 | time: 3.949s
| Adam | epoch: 084 | loss: 0.06799 - acc: 0.9859 | val_loss: 1.59931 - val_acc: 0.6352 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9180  | total loss: 0.09006 | time: 3.932s
| Adam | epoch: 085 | loss: 0.09006 - acc: 0.9766 | val_loss: 1.58419 - val_acc: 0.6457 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9288  | total loss: 0.07181 | time: 3.915s
| Adam | epoch: 086 | loss: 0.07181 - acc: 0.9808 | val_loss: 1.61837 - val_acc: 0.6220 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9396  | total loss: 0.06893 | time: 3.921s
| Adam | epoch: 087 | loss: 0.06893 - acc: 0.9834 | val_loss: 1.63744 - val_acc: 0.6325 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9504  | total loss: 0.07438 | time: 3.918s
| Adam | epoch: 088 | loss: 0.07438 - acc: 0.9798 | val_loss: 1.62473 - val_acc: 0.6299 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9612  | total loss: 0.08984 | time: 3.936s
| Adam | epoch: 089 | loss: 0.08984 - acc: 0.9760 | val_loss: 1.60652 - val_acc: 0.6325 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9720  | total loss: 0.06745 | time: 3.928s
| Adam | epoch: 090 | loss: 0.06745 - acc: 0.9799 | val_loss: 1.61104 - val_acc: 0.6404 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9828  | total loss: 0.04641 | time: 3.909s
| Adam | epoch: 091 | loss: 0.04641 - acc: 0.9934 | val_loss: 1.63405 - val_acc: 0.6194 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9936  | total loss: 0.05979 | time: 3.916s
| Adam | epoch: 092 | loss: 0.05979 - acc: 0.9826 | val_loss: 1.54529 - val_acc: 0.6247 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10044  | total loss: 0.06845 | time: 3.953s
| Adam | epoch: 093 | loss: 0.06845 - acc: 0.9816 | val_loss: 1.59312 - val_acc: 0.6352 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10152  | total loss: 0.05809 | time: 3.919s
| Adam | epoch: 094 | loss: 0.05809 - acc: 0.9866 | val_loss: 1.69056 - val_acc: 0.6325 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10260  | total loss: 0.05370 | time: 3.926s
| Adam | epoch: 095 | loss: 0.05370 - acc: 0.9890 | val_loss: 1.58507 - val_acc: 0.6299 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10368  | total loss: 0.05342 | time: 3.912s
| Adam | epoch: 096 | loss: 0.05342 - acc: 0.9908 | val_loss: 1.62711 - val_acc: 0.6010 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10476  | total loss: 0.04688 | time: 3.921s
| Adam | epoch: 097 | loss: 0.04688 - acc: 0.9895 | val_loss: 1.68638 - val_acc: 0.6194 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10584  | total loss: 0.09221 | time: 3.919s
| Adam | epoch: 098 | loss: 0.09221 - acc: 0.9774 | val_loss: 1.68331 - val_acc: 0.6010 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10692  | total loss: 0.08132 | time: 3.925s
| Adam | epoch: 099 | loss: 0.08132 - acc: 0.9711 | val_loss: 1.69432 - val_acc: 0.6220 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10800  | total loss: 0.04962 | time: 3.929s
| Adam | epoch: 100 | loss: 0.04962 - acc: 0.9903 | val_loss: 1.65935 - val_acc: 0.6168 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

