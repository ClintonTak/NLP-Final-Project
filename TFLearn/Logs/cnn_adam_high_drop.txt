Training Step: 108  | total loss: 1.62904 | time: 4.842s
| Adam | epoch: 001 | loss: 1.62904 - acc: 0.3124 | val_loss: 1.59320 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 216  | total loss: 1.52828 | time: 3.941s
| Adam | epoch: 002 | loss: 1.52828 - acc: 0.4156 | val_loss: 1.57074 - val_acc: 0.3990 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 324  | total loss: 1.53635 | time: 3.942s
| Adam | epoch: 003 | loss: 1.53635 - acc: 0.3813 | val_loss: 1.53611 - val_acc: 0.4304 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 432  | total loss: 1.50023 | time: 3.930s
| Adam | epoch: 004 | loss: 1.50023 - acc: 0.4221 | val_loss: 1.46992 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 540  | total loss: 1.47868 | time: 3.925s
| Adam | epoch: 005 | loss: 1.47868 - acc: 0.4436 | val_loss: 1.41596 - val_acc: 0.4829 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 648  | total loss: 1.42707 | time: 3.914s
| Adam | epoch: 006 | loss: 1.42707 - acc: 0.4659 | val_loss: 1.37838 - val_acc: 0.4961 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 756  | total loss: 1.44048 | time: 3.911s
| Adam | epoch: 007 | loss: 1.44048 - acc: 0.4745 | val_loss: 1.34261 - val_acc: 0.5092 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 864  | total loss: 1.33148 | time: 3.917s
| Adam | epoch: 008 | loss: 1.33148 - acc: 0.5187 | val_loss: 1.31572 - val_acc: 0.5249 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 972  | total loss: 1.27657 | time: 3.921s
| Adam | epoch: 009 | loss: 1.27657 - acc: 0.5477 | val_loss: 1.30100 - val_acc: 0.5039 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1080  | total loss: 1.30720 | time: 3.938s
| Adam | epoch: 010 | loss: 1.30720 - acc: 0.5098 | val_loss: 1.29738 - val_acc: 0.5171 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1188  | total loss: 1.23674 | time: 3.924s
| Adam | epoch: 011 | loss: 1.23674 - acc: 0.5488 | val_loss: 1.27092 - val_acc: 0.5171 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1296  | total loss: 1.27337 | time: 3.931s
| Adam | epoch: 012 | loss: 1.27337 - acc: 0.5413 | val_loss: 1.25295 - val_acc: 0.5354 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1404  | total loss: 1.18947 | time: 3.926s
| Adam | epoch: 013 | loss: 1.18947 - acc: 0.5796 | val_loss: 1.25343 - val_acc: 0.5538 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1512  | total loss: 1.26832 | time: 3.927s
| Adam | epoch: 014 | loss: 1.26832 - acc: 0.5361 | val_loss: 1.23858 - val_acc: 0.5486 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1620  | total loss: 1.20766 | time: 3.926s
| Adam | epoch: 015 | loss: 1.20766 - acc: 0.5599 | val_loss: 1.23519 - val_acc: 0.5538 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1728  | total loss: 1.18210 | time: 3.909s
| Adam | epoch: 016 | loss: 1.18210 - acc: 0.5623 | val_loss: 1.22666 - val_acc: 0.5459 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1836  | total loss: 1.14786 | time: 3.928s
| Adam | epoch: 017 | loss: 1.14786 - acc: 0.5972 | val_loss: 1.22926 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1944  | total loss: 1.14589 | time: 3.919s
| Adam | epoch: 018 | loss: 1.14589 - acc: 0.5879 | val_loss: 1.23162 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2052  | total loss: 1.11043 | time: 3.921s
| Adam | epoch: 019 | loss: 1.11043 - acc: 0.6088 | val_loss: 1.20711 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2160  | total loss: 1.13086 | time: 3.919s
| Adam | epoch: 020 | loss: 1.13086 - acc: 0.5882 | val_loss: 1.22732 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2268  | total loss: 1.07866 | time: 3.922s
| Adam | epoch: 021 | loss: 1.07866 - acc: 0.6029 | val_loss: 1.20970 - val_acc: 0.5407 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2376  | total loss: 1.12657 | time: 3.922s
| Adam | epoch: 022 | loss: 1.12657 - acc: 0.5784 | val_loss: 1.22055 - val_acc: 0.5433 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2484  | total loss: 1.18691 | time: 3.923s
| Adam | epoch: 023 | loss: 1.18691 - acc: 0.6068 | val_loss: 1.21636 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2592  | total loss: 0.97416 | time: 3.918s
| Adam | epoch: 024 | loss: 0.97416 - acc: 0.6482 | val_loss: 1.19389 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2700  | total loss: 1.05600 | time: 3.921s
| Adam | epoch: 025 | loss: 1.05600 - acc: 0.6107 | val_loss: 1.19518 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2808  | total loss: 0.98703 | time: 3.905s
| Adam | epoch: 026 | loss: 0.98703 - acc: 0.6566 | val_loss: 1.18377 - val_acc: 0.5906 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2916  | total loss: 1.05810 | time: 3.911s
| Adam | epoch: 027 | loss: 1.05810 - acc: 0.6041 | val_loss: 1.21048 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3024  | total loss: 1.15494 | time: 3.940s
| Adam | epoch: 028 | loss: 1.15494 - acc: 0.6114 | val_loss: 1.21934 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3132  | total loss: 0.96171 | time: 3.929s
| Adam | epoch: 029 | loss: 0.96171 - acc: 0.6677 | val_loss: 1.21245 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3240  | total loss: 0.95980 | time: 3.912s
| Adam | epoch: 030 | loss: 0.95980 - acc: 0.6647 | val_loss: 1.21571 - val_acc: 0.5774 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3348  | total loss: 1.03868 | time: 3.986s
| Adam | epoch: 031 | loss: 1.03868 - acc: 0.6377 | val_loss: 1.21353 - val_acc: 0.5249 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3456  | total loss: 0.97949 | time: 3.925s
| Adam | epoch: 032 | loss: 0.97949 - acc: 0.6607 | val_loss: 1.22372 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3564  | total loss: 0.96081 | time: 3.936s
| Adam | epoch: 033 | loss: 0.96081 - acc: 0.6550 | val_loss: 1.20906 - val_acc: 0.5433 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3672  | total loss: 1.00238 | time: 3.933s
| Adam | epoch: 034 | loss: 1.00238 - acc: 0.6465 | val_loss: 1.22364 - val_acc: 0.5538 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3780  | total loss: 0.92089 | time: 3.980s
| Adam | epoch: 035 | loss: 0.92089 - acc: 0.6860 | val_loss: 1.20681 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3888  | total loss: 0.97022 | time: 3.927s
| Adam | epoch: 036 | loss: 0.97022 - acc: 0.6505 | val_loss: 1.21060 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3996  | total loss: 0.94618 | time: 3.940s
| Adam | epoch: 037 | loss: 0.94618 - acc: 0.6538 | val_loss: 1.21661 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4104  | total loss: 0.86318 | time: 3.922s
| Adam | epoch: 038 | loss: 0.86318 - acc: 0.7017 | val_loss: 1.21754 - val_acc: 0.5486 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4212  | total loss: 0.90121 | time: 3.917s
| Adam | epoch: 039 | loss: 0.90121 - acc: 0.6909 | val_loss: 1.21314 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4320  | total loss: 0.89618 | time: 3.925s
| Adam | epoch: 040 | loss: 0.89618 - acc: 0.6831 | val_loss: 1.24895 - val_acc: 0.5354 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4428  | total loss: 0.89938 | time: 3.906s
| Adam | epoch: 041 | loss: 0.89938 - acc: 0.7006 | val_loss: 1.24405 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4536  | total loss: 0.94039 | time: 3.922s
| Adam | epoch: 042 | loss: 0.94039 - acc: 0.6730 | val_loss: 1.23570 - val_acc: 0.5486 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4644  | total loss: 0.85774 | time: 3.919s
| Adam | epoch: 043 | loss: 0.85774 - acc: 0.6976 | val_loss: 1.22959 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4752  | total loss: 0.91923 | time: 3.923s
| Adam | epoch: 044 | loss: 0.91923 - acc: 0.7000 | val_loss: 1.23272 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4860  | total loss: 0.91946 | time: 3.939s
| Adam | epoch: 045 | loss: 0.91946 - acc: 0.6803 | val_loss: 1.23295 - val_acc: 0.5538 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4968  | total loss: 0.85175 | time: 3.926s
| Adam | epoch: 046 | loss: 0.85175 - acc: 0.6976 | val_loss: 1.22741 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5076  | total loss: 0.85985 | time: 3.926s
| Adam | epoch: 047 | loss: 0.85985 - acc: 0.7166 | val_loss: 1.23991 - val_acc: 0.5433 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5184  | total loss: 0.87227 | time: 3.937s
| Adam | epoch: 048 | loss: 0.87227 - acc: 0.6770 | val_loss: 1.26840 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5292  | total loss: 0.86045 | time: 3.942s
| Adam | epoch: 049 | loss: 0.86045 - acc: 0.6926 | val_loss: 1.23371 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5400  | total loss: 0.82414 | time: 3.921s
| Adam | epoch: 050 | loss: 0.82414 - acc: 0.7276 | val_loss: 1.24177 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5508  | total loss: 0.81542 | time: 3.915s
| Adam | epoch: 051 | loss: 0.81542 - acc: 0.7006 | val_loss: 1.24881 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5616  | total loss: 0.73424 | time: 3.929s
| Adam | epoch: 052 | loss: 0.73424 - acc: 0.7381 | val_loss: 1.26634 - val_acc: 0.5564 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5724  | total loss: 0.85191 | time: 3.946s
| Adam | epoch: 053 | loss: 0.85191 - acc: 0.6825 | val_loss: 1.27009 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5832  | total loss: 0.75821 | time: 3.924s
| Adam | epoch: 054 | loss: 0.75821 - acc: 0.7394 | val_loss: 1.26730 - val_acc: 0.5459 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5940  | total loss: 0.81993 | time: 3.891s
| Adam | epoch: 055 | loss: 0.81993 - acc: 0.6946 | val_loss: 1.26842 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6048  | total loss: 0.80795 | time: 3.915s
| Adam | epoch: 056 | loss: 0.80795 - acc: 0.7089 | val_loss: 1.24087 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6156  | total loss: 0.78675 | time: 3.912s
| Adam | epoch: 057 | loss: 0.78675 - acc: 0.7121 | val_loss: 1.28015 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6264  | total loss: 0.87139 | time: 3.915s
| Adam | epoch: 058 | loss: 0.87139 - acc: 0.6870 | val_loss: 1.28678 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6372  | total loss: 0.79080 | time: 3.904s
| Adam | epoch: 059 | loss: 0.79080 - acc: 0.7291 | val_loss: 1.30988 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6480  | total loss: 0.70917 | time: 4.026s
| Adam | epoch: 060 | loss: 0.70917 - acc: 0.7439 | val_loss: 1.28389 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6588  | total loss: 0.75465 | time: 3.930s
| Adam | epoch: 061 | loss: 0.75465 - acc: 0.7404 | val_loss: 1.26005 - val_acc: 0.5538 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6696  | total loss: 0.75108 | time: 3.924s
| Adam | epoch: 062 | loss: 0.75108 - acc: 0.7301 | val_loss: 1.30950 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6804  | total loss: 0.78185 | time: 3.917s
| Adam | epoch: 063 | loss: 0.78185 - acc: 0.6981 | val_loss: 1.29251 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6912  | total loss: 0.78886 | time: 3.918s
| Adam | epoch: 064 | loss: 0.78886 - acc: 0.7268 | val_loss: 1.30553 - val_acc: 0.5486 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7020  | total loss: 0.74445 | time: 3.888s
| Adam | epoch: 065 | loss: 0.74445 - acc: 0.7302 | val_loss: 1.31294 - val_acc: 0.5564 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7128  | total loss: 0.79237 | time: 3.933s
| Adam | epoch: 066 | loss: 0.79237 - acc: 0.7255 | val_loss: 1.31991 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7236  | total loss: 0.73601 | time: 3.904s
| Adam | epoch: 067 | loss: 0.73601 - acc: 0.7572 | val_loss: 1.31216 - val_acc: 0.5459 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7344  | total loss: 0.79964 | time: 3.966s
| Adam | epoch: 068 | loss: 0.79964 - acc: 0.6911 | val_loss: 1.31101 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7452  | total loss: 0.76333 | time: 3.908s
| Adam | epoch: 069 | loss: 0.76333 - acc: 0.7200 | val_loss: 1.29778 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7560  | total loss: 0.73291 | time: 3.914s
| Adam | epoch: 070 | loss: 0.73291 - acc: 0.7404 | val_loss: 1.28983 - val_acc: 0.5564 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7668  | total loss: 0.69205 | time: 3.906s
| Adam | epoch: 071 | loss: 0.69205 - acc: 0.7685 | val_loss: 1.32174 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7776  | total loss: 0.74101 | time: 3.905s
| Adam | epoch: 072 | loss: 0.74101 - acc: 0.7178 | val_loss: 1.32357 - val_acc: 0.5459 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7884  | total loss: 0.70878 | time: 3.911s
| Adam | epoch: 073 | loss: 0.70878 - acc: 0.7630 | val_loss: 1.30475 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7992  | total loss: 0.72591 | time: 3.948s
| Adam | epoch: 074 | loss: 0.72591 - acc: 0.7376 | val_loss: 1.32199 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8100  | total loss: 0.74510 | time: 3.942s
| Adam | epoch: 075 | loss: 0.74510 - acc: 0.7373 | val_loss: 1.34805 - val_acc: 0.5433 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8208  | total loss: 0.64921 | time: 3.948s
| Adam | epoch: 076 | loss: 0.64921 - acc: 0.7611 | val_loss: 1.33423 - val_acc: 0.5433 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8316  | total loss: 0.68677 | time: 3.916s
| Adam | epoch: 077 | loss: 0.68677 - acc: 0.7765 | val_loss: 1.32863 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8424  | total loss: 0.67172 | time: 3.930s
| Adam | epoch: 078 | loss: 0.67172 - acc: 0.7504 | val_loss: 1.34601 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8532  | total loss: 0.71904 | time: 3.943s
| Adam | epoch: 079 | loss: 0.71904 - acc: 0.7417 | val_loss: 1.36860 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8640  | total loss: 0.70448 | time: 3.919s
| Adam | epoch: 080 | loss: 0.70448 - acc: 0.7457 | val_loss: 1.34184 - val_acc: 0.5538 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8748  | total loss: 0.75065 | time: 3.922s
| Adam | epoch: 081 | loss: 0.75065 - acc: 0.7390 | val_loss: 1.34034 - val_acc: 0.5538 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8856  | total loss: 0.73180 | time: 3.903s
| Adam | epoch: 082 | loss: 0.73180 - acc: 0.7442 | val_loss: 1.35276 - val_acc: 0.5564 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8964  | total loss: 0.69686 | time: 3.913s
| Adam | epoch: 083 | loss: 0.69686 - acc: 0.7607 | val_loss: 1.31337 - val_acc: 0.5538 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9072  | total loss: 0.66130 | time: 3.917s
| Adam | epoch: 084 | loss: 0.66130 - acc: 0.7687 | val_loss: 1.34770 - val_acc: 0.5459 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9180  | total loss: 0.69549 | time: 3.919s
| Adam | epoch: 085 | loss: 0.69549 - acc: 0.7456 | val_loss: 1.42319 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9288  | total loss: 0.67786 | time: 3.942s
| Adam | epoch: 086 | loss: 0.67786 - acc: 0.7535 | val_loss: 1.37060 - val_acc: 0.5407 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9396  | total loss: 0.65110 | time: 3.925s
| Adam | epoch: 087 | loss: 0.65110 - acc: 0.7709 | val_loss: 1.35520 - val_acc: 0.5538 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9504  | total loss: 0.58201 | time: 3.925s
| Adam | epoch: 088 | loss: 0.58201 - acc: 0.7859 | val_loss: 1.35858 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9612  | total loss: 0.64822 | time: 3.934s
| Adam | epoch: 089 | loss: 0.64822 - acc: 0.7669 | val_loss: 1.37118 - val_acc: 0.5407 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9720  | total loss: 0.58193 | time: 3.937s
| Adam | epoch: 090 | loss: 0.58193 - acc: 0.8059 | val_loss: 1.37438 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9828  | total loss: 0.60289 | time: 3.932s
| Adam | epoch: 091 | loss: 0.60289 - acc: 0.7724 | val_loss: 1.38945 - val_acc: 0.5354 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9936  | total loss: 0.68169 | time: 3.929s
| Adam | epoch: 092 | loss: 0.68169 - acc: 0.7301 | val_loss: 1.36448 - val_acc: 0.5538 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10044  | total loss: 0.61944 | time: 3.883s
| Adam | epoch: 093 | loss: 0.61944 - acc: 0.7789 | val_loss: 1.36869 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10152  | total loss: 0.63581 | time: 3.939s
| Adam | epoch: 094 | loss: 0.63581 - acc: 0.7622 | val_loss: 1.37055 - val_acc: 0.5538 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10260  | total loss: 0.58607 | time: 3.924s
| Adam | epoch: 095 | loss: 0.58607 - acc: 0.7897 | val_loss: 1.37240 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10368  | total loss: 0.56497 | time: 3.924s
| Adam | epoch: 096 | loss: 0.56497 - acc: 0.8055 | val_loss: 1.43202 - val_acc: 0.5564 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10476  | total loss: 0.56508 | time: 3.903s
| Adam | epoch: 097 | loss: 0.56508 - acc: 0.7935 | val_loss: 1.42670 - val_acc: 0.5538 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10584  | total loss: 0.63275 | time: 3.896s
| Adam | epoch: 098 | loss: 0.63275 - acc: 0.7654 | val_loss: 1.42110 - val_acc: 0.5459 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10692  | total loss: 0.61765 | time: 3.917s
| Adam | epoch: 099 | loss: 0.61765 - acc: 0.7782 | val_loss: 1.40632 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10800  | total loss: 0.59606 | time: 3.926s
| Adam | epoch: 100 | loss: 0.59606 - acc: 0.7785 | val_loss: 1.41724 - val_acc: 0.5564 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

