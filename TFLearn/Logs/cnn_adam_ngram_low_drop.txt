Training Step: 108  | total loss: 1.54604 | time: 9.859s
| Adam | epoch: 001 | loss: 1.54604 - acc: 0.3863 | val_loss: 1.55431 - val_acc: 0.3570 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 216  | total loss: 1.38224 | time: 8.988s
| Adam | epoch: 002 | loss: 1.38224 - acc: 0.4995 | val_loss: 1.38950 - val_acc: 0.5039 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 324  | total loss: 1.15887 | time: 9.035s
| Adam | epoch: 003 | loss: 1.15887 - acc: 0.6165 | val_loss: 1.29069 - val_acc: 0.5407 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 432  | total loss: 0.77329 | time: 9.069s
| Adam | epoch: 004 | loss: 0.77329 - acc: 0.7321 | val_loss: 1.22494 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 540  | total loss: 0.41166 | time: 9.134s
| Adam | epoch: 005 | loss: 0.41166 - acc: 0.8838 | val_loss: 1.29901 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 648  | total loss: 0.24676 | time: 9.139s
| Adam | epoch: 006 | loss: 0.24676 - acc: 0.9389 | val_loss: 1.40208 - val_acc: 0.5433 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 756  | total loss: 0.13394 | time: 9.007s
| Adam | epoch: 007 | loss: 0.13394 - acc: 0.9760 | val_loss: 1.49958 - val_acc: 0.5092 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 864  | total loss: 0.07049 | time: 9.000s
| Adam | epoch: 008 | loss: 0.07049 - acc: 0.9915 | val_loss: 1.55820 - val_acc: 0.5197 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 972  | total loss: 0.05342 | time: 8.973s
| Adam | epoch: 009 | loss: 0.05342 - acc: 0.9988 | val_loss: 1.57156 - val_acc: 0.5223 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1080  | total loss: 0.03784 | time: 8.986s
| Adam | epoch: 010 | loss: 0.03784 - acc: 0.9986 | val_loss: 1.56714 - val_acc: 0.5223 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1188  | total loss: 0.02812 | time: 8.977s
| Adam | epoch: 011 | loss: 0.02812 - acc: 0.9994 | val_loss: 1.57554 - val_acc: 0.5302 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1296  | total loss: 0.03471 | time: 8.950s
| Adam | epoch: 012 | loss: 0.03471 - acc: 0.9987 | val_loss: 1.58084 - val_acc: 0.5197 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1404  | total loss: 0.02286 | time: 8.968s
| Adam | epoch: 013 | loss: 0.02286 - acc: 1.0000 | val_loss: 1.55580 - val_acc: 0.5276 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1512  | total loss: 0.02137 | time: 9.005s
| Adam | epoch: 014 | loss: 0.02137 - acc: 1.0000 | val_loss: 1.57489 - val_acc: 0.5354 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1620  | total loss: 0.01643 | time: 8.987s
| Adam | epoch: 015 | loss: 0.01643 - acc: 1.0000 | val_loss: 1.57003 - val_acc: 0.5276 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1728  | total loss: 0.01555 | time: 8.961s
| Adam | epoch: 016 | loss: 0.01555 - acc: 0.9998 | val_loss: 1.59284 - val_acc: 0.5197 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1836  | total loss: 0.01328 | time: 8.980s
| Adam | epoch: 017 | loss: 0.01328 - acc: 1.0000 | val_loss: 1.60663 - val_acc: 0.4961 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1944  | total loss: 0.01393 | time: 8.976s
| Adam | epoch: 018 | loss: 0.01393 - acc: 1.0000 | val_loss: 1.61367 - val_acc: 0.5118 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2052  | total loss: 0.01139 | time: 8.968s
| Adam | epoch: 019 | loss: 0.01139 - acc: 1.0000 | val_loss: 1.61803 - val_acc: 0.5171 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2160  | total loss: 0.01215 | time: 8.985s
| Adam | epoch: 020 | loss: 0.01215 - acc: 0.9992 | val_loss: 1.63640 - val_acc: 0.5171 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2268  | total loss: 0.01032 | time: 9.159s
| Adam | epoch: 021 | loss: 0.01032 - acc: 1.0000 | val_loss: 1.63792 - val_acc: 0.5249 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2376  | total loss: 0.01100 | time: 8.998s
| Adam | epoch: 022 | loss: 0.01100 - acc: 1.0000 | val_loss: 1.64041 - val_acc: 0.5223 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2484  | total loss: 0.00954 | time: 9.040s
| Adam | epoch: 023 | loss: 0.00954 - acc: 1.0000 | val_loss: 1.65122 - val_acc: 0.5197 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2592  | total loss: 0.00798 | time: 8.965s
| Adam | epoch: 024 | loss: 0.00798 - acc: 1.0000 | val_loss: 1.67085 - val_acc: 0.5118 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2700  | total loss: 0.00812 | time: 9.088s
| Adam | epoch: 025 | loss: 0.00812 - acc: 1.0000 | val_loss: 1.68318 - val_acc: 0.5223 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2808  | total loss: 0.00900 | time: 9.259s
| Adam | epoch: 026 | loss: 0.00900 - acc: 1.0000 | val_loss: 1.68636 - val_acc: 0.5171 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2916  | total loss: 0.00677 | time: 9.040s
| Adam | epoch: 027 | loss: 0.00677 - acc: 1.0000 | val_loss: 1.68522 - val_acc: 0.5013 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3024  | total loss: 0.00622 | time: 8.946s
| Adam | epoch: 028 | loss: 0.00622 - acc: 1.0000 | val_loss: 1.69630 - val_acc: 0.5171 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3132  | total loss: 0.00669 | time: 11.768s
| Adam | epoch: 029 | loss: 0.00669 - acc: 1.0000 | val_loss: 1.68918 - val_acc: 0.5249 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3240  | total loss: 0.00581 | time: 9.728s
| Adam | epoch: 030 | loss: 0.00581 - acc: 1.0000 | val_loss: 1.71554 - val_acc: 0.5223 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3348  | total loss: 0.00495 | time: 9.643s
| Adam | epoch: 031 | loss: 0.00495 - acc: 1.0000 | val_loss: 1.70634 - val_acc: 0.5249 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3456  | total loss: 0.00627 | time: 9.067s
| Adam | epoch: 032 | loss: 0.00627 - acc: 1.0000 | val_loss: 1.72381 - val_acc: 0.5039 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3564  | total loss: 0.00534 | time: 9.284s
| Adam | epoch: 033 | loss: 0.00534 - acc: 1.0000 | val_loss: 1.75084 - val_acc: 0.5118 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3672  | total loss: 0.00618 | time: 9.085s
| Adam | epoch: 034 | loss: 0.00618 - acc: 1.0000 | val_loss: 1.75352 - val_acc: 0.5092 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3780  | total loss: 0.02539 | time: 9.168s
| Adam | epoch: 035 | loss: 0.02539 - acc: 0.9926 | val_loss: 1.96420 - val_acc: 0.4829 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3888  | total loss: 0.00467 | time: 9.067s
| Adam | epoch: 036 | loss: 0.00467 - acc: 1.0000 | val_loss: 1.87471 - val_acc: 0.5013 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3996  | total loss: 0.00421 | time: 9.240s
| Adam | epoch: 037 | loss: 0.00421 - acc: 1.0000 | val_loss: 1.81789 - val_acc: 0.4987 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4104  | total loss: 0.00375 | time: 9.328s
| Adam | epoch: 038 | loss: 0.00375 - acc: 1.0000 | val_loss: 1.80957 - val_acc: 0.4987 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4212  | total loss: 0.00366 | time: 9.267s
| Adam | epoch: 039 | loss: 0.00366 - acc: 1.0000 | val_loss: 1.80477 - val_acc: 0.5039 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4320  | total loss: 0.00366 | time: 9.070s
| Adam | epoch: 040 | loss: 0.00366 - acc: 1.0000 | val_loss: 1.82636 - val_acc: 0.5118 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4428  | total loss: 0.00385 | time: 9.059s
| Adam | epoch: 041 | loss: 0.00385 - acc: 1.0000 | val_loss: 1.80091 - val_acc: 0.5066 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4536  | total loss: 0.00316 | time: 9.031s
| Adam | epoch: 042 | loss: 0.00316 - acc: 1.0000 | val_loss: 1.81283 - val_acc: 0.4987 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4644  | total loss: 0.00324 | time: 9.009s
| Adam | epoch: 043 | loss: 0.00324 - acc: 1.0000 | val_loss: 1.80727 - val_acc: 0.4908 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4752  | total loss: 0.00328 | time: 9.048s
| Adam | epoch: 044 | loss: 0.00328 - acc: 1.0000 | val_loss: 1.83804 - val_acc: 0.4882 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4860  | total loss: 0.02193 | time: 9.289s
| Adam | epoch: 045 | loss: 0.02193 - acc: 0.9955 | val_loss: 2.13869 - val_acc: 0.4777 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4968  | total loss: 0.00277 | time: 9.092s
| Adam | epoch: 046 | loss: 0.00277 - acc: 1.0000 | val_loss: 1.98007 - val_acc: 0.5171 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5076  | total loss: 0.00249 | time: 9.161s
| Adam | epoch: 047 | loss: 0.00249 - acc: 1.0000 | val_loss: 1.92478 - val_acc: 0.5066 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5184  | total loss: 0.00260 | time: 9.127s
| Adam | epoch: 048 | loss: 0.00260 - acc: 1.0000 | val_loss: 1.89783 - val_acc: 0.5092 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5292  | total loss: 0.00307 | time: 9.184s
| Adam | epoch: 049 | loss: 0.00307 - acc: 1.0000 | val_loss: 1.88663 - val_acc: 0.5013 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5400  | total loss: 0.01159 | time: 9.189s
| Adam | epoch: 050 | loss: 0.01159 - acc: 0.9962 | val_loss: 2.01337 - val_acc: 0.5171 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5508  | total loss: 0.00838 | time: 9.121s
| Adam | epoch: 051 | loss: 0.00838 - acc: 0.9971 | val_loss: 2.10600 - val_acc: 0.4934 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5616  | total loss: 0.00230 | time: 9.174s
| Adam | epoch: 052 | loss: 0.00230 - acc: 1.0000 | val_loss: 2.01478 - val_acc: 0.5092 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5724  | total loss: 0.00207 | time: 9.279s
| Adam | epoch: 053 | loss: 0.00207 - acc: 1.0000 | val_loss: 1.97899 - val_acc: 0.5092 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5832  | total loss: 0.00284 | time: 9.121s
| Adam | epoch: 054 | loss: 0.00284 - acc: 1.0000 | val_loss: 1.94016 - val_acc: 0.5092 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5940  | total loss: 0.00271 | time: 9.090s
| Adam | epoch: 055 | loss: 0.00271 - acc: 1.0000 | val_loss: 1.93535 - val_acc: 0.5039 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6048  | total loss: 0.00234 | time: 9.104s
| Adam | epoch: 056 | loss: 0.00234 - acc: 1.0000 | val_loss: 1.92642 - val_acc: 0.5039 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6156  | total loss: 0.00201 | time: 9.096s
| Adam | epoch: 057 | loss: 0.00201 - acc: 1.0000 | val_loss: 1.91891 - val_acc: 0.4987 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6264  | total loss: 0.00225 | time: 9.181s
| Adam | epoch: 058 | loss: 0.00225 - acc: 1.0000 | val_loss: 1.92373 - val_acc: 0.5013 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6372  | total loss: 0.00197 | time: 9.376s
| Adam | epoch: 059 | loss: 0.00197 - acc: 1.0000 | val_loss: 1.91713 - val_acc: 0.4987 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6480  | total loss: 0.00197 | time: 9.198s
| Adam | epoch: 060 | loss: 0.00197 - acc: 1.0000 | val_loss: 1.89661 - val_acc: 0.5013 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6588  | total loss: 0.00190 | time: 9.150s
| Adam | epoch: 061 | loss: 0.00190 - acc: 1.0000 | val_loss: 1.90901 - val_acc: 0.5039 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6696  | total loss: 0.00158 | time: 9.640s
| Adam | epoch: 062 | loss: 0.00158 - acc: 1.0000 | val_loss: 1.90491 - val_acc: 0.5066 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6804  | total loss: 0.00183 | time: 9.152s
| Adam | epoch: 063 | loss: 0.00183 - acc: 1.0000 | val_loss: 1.89989 - val_acc: 0.4987 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6912  | total loss: 0.00164 | time: 9.335s
| Adam | epoch: 064 | loss: 0.00164 - acc: 1.0000 | val_loss: 1.91646 - val_acc: 0.5013 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7020  | total loss: 0.00187 | time: 9.215s
| Adam | epoch: 065 | loss: 0.00187 - acc: 1.0000 | val_loss: 1.91246 - val_acc: 0.4934 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7128  | total loss: 0.00171 | time: 9.430s
| Adam | epoch: 066 | loss: 0.00171 - acc: 1.0000 | val_loss: 1.90984 - val_acc: 0.4934 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7236  | total loss: 0.00162 | time: 9.035s
| Adam | epoch: 067 | loss: 0.00162 - acc: 1.0000 | val_loss: 1.92640 - val_acc: 0.4882 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7344  | total loss: 0.00864 | time: 9.074s
| Adam | epoch: 068 | loss: 0.00864 - acc: 0.9959 | val_loss: 2.42349 - val_acc: 0.4829 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7452  | total loss: 0.00085 | time: 9.086s
| Adam | epoch: 069 | loss: 0.00085 - acc: 1.0000 | val_loss: 2.23593 - val_acc: 0.4961 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7560  | total loss: 0.00141 | time: 9.137s
| Adam | epoch: 070 | loss: 0.00141 - acc: 1.0000 | val_loss: 2.12115 - val_acc: 0.4803 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7668  | total loss: 0.00580 | time: 9.098s
| Adam | epoch: 071 | loss: 0.00580 - acc: 0.9997 | val_loss: 2.27968 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7776  | total loss: 0.00190 | time: 9.427s
| Adam | epoch: 072 | loss: 0.00190 - acc: 1.0000 | val_loss: 2.18391 - val_acc: 0.4724 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7884  | total loss: 0.00234 | time: 9.079s
| Adam | epoch: 073 | loss: 0.00234 - acc: 1.0000 | val_loss: 2.13582 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7992  | total loss: 0.00165 | time: 9.054s
| Adam | epoch: 074 | loss: 0.00165 - acc: 1.0000 | val_loss: 2.09168 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8100  | total loss: 0.00173 | time: 9.097s
| Adam | epoch: 075 | loss: 0.00173 - acc: 1.0000 | val_loss: 2.06118 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8208  | total loss: 0.00143 | time: 8.978s
| Adam | epoch: 076 | loss: 0.00143 - acc: 1.0000 | val_loss: 2.03492 - val_acc: 0.4724 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8316  | total loss: 0.00144 | time: 9.017s
| Adam | epoch: 077 | loss: 0.00144 - acc: 1.0000 | val_loss: 2.03049 - val_acc: 0.4724 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8424  | total loss: 0.00142 | time: 9.157s
| Adam | epoch: 078 | loss: 0.00142 - acc: 1.0000 | val_loss: 2.02468 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8532  | total loss: 0.00135 | time: 9.101s
| Adam | epoch: 079 | loss: 0.00135 - acc: 1.0000 | val_loss: 2.05723 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8640  | total loss: 0.00110 | time: 8.999s
| Adam | epoch: 080 | loss: 0.00110 - acc: 1.0000 | val_loss: 2.02756 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8748  | total loss: 0.00097 | time: 8.992s
| Adam | epoch: 081 | loss: 0.00097 - acc: 1.0000 | val_loss: 2.02640 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8856  | total loss: 0.00099 | time: 9.019s
| Adam | epoch: 082 | loss: 0.00099 - acc: 1.0000 | val_loss: 2.05483 - val_acc: 0.4567 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8964  | total loss: 0.00111 | time: 9.001s
| Adam | epoch: 083 | loss: 0.00111 - acc: 1.0000 | val_loss: 2.03905 - val_acc: 0.4751 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9072  | total loss: 0.00093 | time: 8.980s
| Adam | epoch: 084 | loss: 0.00093 - acc: 1.0000 | val_loss: 2.02400 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9180  | total loss: 0.00110 | time: 9.385s
| Adam | epoch: 085 | loss: 0.00110 - acc: 1.0000 | val_loss: 2.04535 - val_acc: 0.4514 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9288  | total loss: 0.00114 | time: 9.122s
| Adam | epoch: 086 | loss: 0.00114 - acc: 1.0000 | val_loss: 2.03455 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9396  | total loss: 0.00097 | time: 8.978s
| Adam | epoch: 087 | loss: 0.00097 - acc: 1.0000 | val_loss: 2.01831 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9504  | total loss: 0.00088 | time: 8.978s
| Adam | epoch: 088 | loss: 0.00088 - acc: 1.0000 | val_loss: 2.03482 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9612  | total loss: 0.01092 | time: 9.291s
| Adam | epoch: 089 | loss: 0.01092 - acc: 0.9959 | val_loss: 3.01920 - val_acc: 0.4226 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9720  | total loss: 0.00105 | time: 9.026s
| Adam | epoch: 090 | loss: 0.00105 - acc: 1.0000 | val_loss: 2.74945 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9828  | total loss: 0.00054 | time: 8.978s
| Adam | epoch: 091 | loss: 0.00054 - acc: 1.0000 | val_loss: 2.47128 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9936  | total loss: 0.00076 | time: 8.998s
| Adam | epoch: 092 | loss: 0.00076 - acc: 1.0000 | val_loss: 2.32630 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10044  | total loss: 0.00090 | time: 8.996s
| Adam | epoch: 093 | loss: 0.00090 - acc: 1.0000 | val_loss: 2.23435 - val_acc: 0.4462 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10152  | total loss: 0.00077 | time: 9.040s
| Adam | epoch: 094 | loss: 0.00077 - acc: 1.0000 | val_loss: 2.22134 - val_acc: 0.4462 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10260  | total loss: 0.00097 | time: 9.026s
| Adam | epoch: 095 | loss: 0.00097 - acc: 1.0000 | val_loss: 2.17986 - val_acc: 0.4462 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10368  | total loss: 0.00086 | time: 9.007s
| Adam | epoch: 096 | loss: 0.00086 - acc: 1.0000 | val_loss: 2.15748 - val_acc: 0.4409 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10476  | total loss: 0.01811 | time: 8.997s
| Adam | epoch: 097 | loss: 0.01811 - acc: 0.9982 | val_loss: 2.66629 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10584  | total loss: 0.00063 | time: 9.004s
| Adam | epoch: 098 | loss: 0.00063 - acc: 1.0000 | val_loss: 2.58685 - val_acc: 0.4593 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10692  | total loss: 0.00059 | time: 9.019s
| Adam | epoch: 099 | loss: 0.00059 - acc: 1.0000 | val_loss: 2.41476 - val_acc: 0.4619 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10800  | total loss: 0.00060 | time: 9.008s
| Adam | epoch: 100 | loss: 0.00060 - acc: 1.0000 | val_loss: 2.31021 - val_acc: 0.4672 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

