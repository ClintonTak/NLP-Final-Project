Training Step: 35  | total loss: 1.65515 | time: 5.045s
| Adam | epoch: 001 | loss: 1.65515 - acc: 0.3295 | val_loss: 1.61358 - val_acc: 0.3228 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 70  | total loss: 1.60331 | time: 4.137s
| Adam | epoch: 002 | loss: 1.60331 - acc: 0.3443 | val_loss: 1.60188 - val_acc: 0.3228 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 105  | total loss: 1.60595 | time: 4.044s
| Adam | epoch: 003 | loss: 1.60595 - acc: 0.3446 | val_loss: 1.59588 - val_acc: 0.3228 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 140  | total loss: 1.60678 | time: 4.148s
| Adam | epoch: 004 | loss: 1.60678 - acc: 0.3363 | val_loss: 1.59192 - val_acc: 0.3228 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 175  | total loss: 1.59832 | time: 4.124s
| Adam | epoch: 005 | loss: 1.59832 - acc: 0.3455 | val_loss: 1.58398 - val_acc: 0.3228 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 210  | total loss: 1.57738 | time: 4.111s
| Adam | epoch: 006 | loss: 1.57738 - acc: 0.3697 | val_loss: 1.57359 - val_acc: 0.3333 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 245  | total loss: 1.56592 | time: 4.031s
| Adam | epoch: 007 | loss: 1.56592 - acc: 0.3703 | val_loss: 1.55608 - val_acc: 0.3307 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 280  | total loss: 1.54084 | time: 4.114s
| Adam | epoch: 008 | loss: 1.54084 - acc: 0.3881 | val_loss: 1.52860 - val_acc: 0.4173 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 315  | total loss: 1.50385 | time: 4.057s
| Adam | epoch: 009 | loss: 1.50385 - acc: 0.4140 | val_loss: 1.50451 - val_acc: 0.4042 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 350  | total loss: 1.48783 | time: 4.027s
| Adam | epoch: 010 | loss: 1.48783 - acc: 0.4143 | val_loss: 1.45268 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 385  | total loss: 1.45277 | time: 4.085s
| Adam | epoch: 011 | loss: 1.45277 - acc: 0.4376 | val_loss: 1.41813 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 420  | total loss: 1.39931 | time: 4.166s
| Adam | epoch: 012 | loss: 1.39931 - acc: 0.4751 | val_loss: 1.39590 - val_acc: 0.4751 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 455  | total loss: 1.36962 | time: 4.037s
| Adam | epoch: 013 | loss: 1.36962 - acc: 0.4794 | val_loss: 1.36664 - val_acc: 0.5013 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 490  | total loss: 1.34979 | time: 4.049s
| Adam | epoch: 014 | loss: 1.34979 - acc: 0.4988 | val_loss: 1.34323 - val_acc: 0.4987 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 525  | total loss: 1.33530 | time: 4.012s
| Adam | epoch: 015 | loss: 1.33530 - acc: 0.5081 | val_loss: 1.32275 - val_acc: 0.5092 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 560  | total loss: 1.26275 | time: 4.000s
| Adam | epoch: 016 | loss: 1.26275 - acc: 0.5555 | val_loss: 1.30847 - val_acc: 0.5302 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 595  | total loss: 1.27649 | time: 4.315s
| Adam | epoch: 017 | loss: 1.27649 - acc: 0.5243 | val_loss: 1.29005 - val_acc: 0.5433 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 630  | total loss: 1.27865 | time: 4.282s
| Adam | epoch: 018 | loss: 1.27865 - acc: 0.5354 | val_loss: 1.27613 - val_acc: 0.5433 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 665  | total loss: 1.21498 | time: 4.122s
| Adam | epoch: 019 | loss: 1.21498 - acc: 0.5711 | val_loss: 1.26472 - val_acc: 0.5486 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 700  | total loss: 1.21796 | time: 4.054s
| Adam | epoch: 020 | loss: 1.21796 - acc: 0.5543 | val_loss: 1.24429 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 735  | total loss: 1.23105 | time: 4.127s
| Adam | epoch: 021 | loss: 1.23105 - acc: 0.5565 | val_loss: 1.24623 - val_acc: 0.5538 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 770  | total loss: 1.21012 | time: 4.058s
| Adam | epoch: 022 | loss: 1.21012 - acc: 0.5654 | val_loss: 1.21706 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 805  | total loss: 1.13431 | time: 4.092s
| Adam | epoch: 023 | loss: 1.13431 - acc: 0.5965 | val_loss: 1.22246 - val_acc: 0.5774 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 840  | total loss: 1.16862 | time: 3.989s
| Adam | epoch: 024 | loss: 1.16862 - acc: 0.5844 | val_loss: 1.22089 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 875  | total loss: 1.22556 | time: 3.997s
| Adam | epoch: 025 | loss: 1.22556 - acc: 0.5499 | val_loss: 1.21707 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 910  | total loss: 1.10951 | time: 4.000s
| Adam | epoch: 026 | loss: 1.10951 - acc: 0.6132 | val_loss: 1.20885 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 945  | total loss: 1.19954 | time: 3.994s
| Adam | epoch: 027 | loss: 1.19954 - acc: 0.5643 | val_loss: 1.20344 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 980  | total loss: 1.10962 | time: 3.993s
| Adam | epoch: 028 | loss: 1.10962 - acc: 0.6023 | val_loss: 1.18977 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1015  | total loss: 1.20644 | time: 3.998s
| Adam | epoch: 029 | loss: 1.20644 - acc: 0.5782 | val_loss: 1.21219 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1050  | total loss: 1.11174 | time: 4.008s
| Adam | epoch: 030 | loss: 1.11174 - acc: 0.6010 | val_loss: 1.18268 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1085  | total loss: 1.03204 | time: 3.998s
| Adam | epoch: 031 | loss: 1.03204 - acc: 0.6380 | val_loss: 1.17803 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1120  | total loss: 1.10765 | time: 4.002s
| Adam | epoch: 032 | loss: 1.10765 - acc: 0.5994 | val_loss: 1.19246 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1155  | total loss: 1.09090 | time: 4.003s
| Adam | epoch: 033 | loss: 1.09090 - acc: 0.6271 | val_loss: 1.20495 - val_acc: 0.5564 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1190  | total loss: 1.08508 | time: 3.996s
| Adam | epoch: 034 | loss: 1.08508 - acc: 0.6123 | val_loss: 1.19018 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1225  | total loss: 1.05382 | time: 3.986s
| Adam | epoch: 035 | loss: 1.05382 - acc: 0.6221 | val_loss: 1.17777 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1260  | total loss: 1.04310 | time: 3.990s
| Adam | epoch: 036 | loss: 1.04310 - acc: 0.6271 | val_loss: 1.16932 - val_acc: 0.5879 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1295  | total loss: 1.00639 | time: 4.060s
| Adam | epoch: 037 | loss: 1.00639 - acc: 0.6417 | val_loss: 1.17126 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1330  | total loss: 1.02340 | time: 4.055s
| Adam | epoch: 038 | loss: 1.02340 - acc: 0.6417 | val_loss: 1.17294 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1365  | total loss: 0.99365 | time: 3.982s
| Adam | epoch: 039 | loss: 0.99365 - acc: 0.6572 | val_loss: 1.17376 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1400  | total loss: 0.99705 | time: 3.990s
| Adam | epoch: 040 | loss: 0.99705 - acc: 0.6383 | val_loss: 1.15580 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1435  | total loss: 1.01953 | time: 3.978s
| Adam | epoch: 041 | loss: 1.01953 - acc: 0.6468 | val_loss: 1.16204 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1470  | total loss: 1.00339 | time: 4.007s
| Adam | epoch: 042 | loss: 1.00339 - acc: 0.6390 | val_loss: 1.17573 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1505  | total loss: 1.00389 | time: 4.099s
| Adam | epoch: 043 | loss: 1.00389 - acc: 0.6456 | val_loss: 1.16950 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1540  | total loss: 0.93236 | time: 4.111s
| Adam | epoch: 044 | loss: 0.93236 - acc: 0.6681 | val_loss: 1.17473 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1575  | total loss: 0.96199 | time: 4.001s
| Adam | epoch: 045 | loss: 0.96199 - acc: 0.6536 | val_loss: 1.19254 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1610  | total loss: 0.96261 | time: 3.991s
| Adam | epoch: 046 | loss: 0.96261 - acc: 0.6630 | val_loss: 1.17425 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1645  | total loss: 0.93705 | time: 3.957s
| Adam | epoch: 047 | loss: 0.93705 - acc: 0.6785 | val_loss: 1.16681 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1680  | total loss: 0.92379 | time: 3.999s
| Adam | epoch: 048 | loss: 0.92379 - acc: 0.6717 | val_loss: 1.17084 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1715  | total loss: 0.95023 | time: 3.992s
| Adam | epoch: 049 | loss: 0.95023 - acc: 0.6727 | val_loss: 1.16858 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1750  | total loss: 0.97139 | time: 3.999s
| Adam | epoch: 050 | loss: 0.97139 - acc: 0.6615 | val_loss: 1.14901 - val_acc: 0.5879 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1785  | total loss: 0.91580 | time: 3.956s
| Adam | epoch: 051 | loss: 0.91580 - acc: 0.6780 | val_loss: 1.15537 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1820  | total loss: 0.96514 | time: 4.007s
| Adam | epoch: 052 | loss: 0.96514 - acc: 0.6647 | val_loss: 1.17177 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1855  | total loss: 0.92489 | time: 3.987s
| Adam | epoch: 053 | loss: 0.92489 - acc: 0.6784 | val_loss: 1.16182 - val_acc: 0.5827 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1890  | total loss: 0.91725 | time: 3.998s
| Adam | epoch: 054 | loss: 0.91725 - acc: 0.6857 | val_loss: 1.15534 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1925  | total loss: 0.88513 | time: 3.992s
| Adam | epoch: 055 | loss: 0.88513 - acc: 0.6754 | val_loss: 1.15462 - val_acc: 0.5932 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1960  | total loss: 0.97371 | time: 3.987s
| Adam | epoch: 056 | loss: 0.97371 - acc: 0.6712 | val_loss: 1.16648 - val_acc: 0.5774 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1995  | total loss: 0.92150 | time: 3.999s
| Adam | epoch: 057 | loss: 0.92150 - acc: 0.6848 | val_loss: 1.18508 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2030  | total loss: 0.85118 | time: 4.008s
| Adam | epoch: 058 | loss: 0.85118 - acc: 0.7039 | val_loss: 1.18554 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2065  | total loss: 0.94980 | time: 3.992s
| Adam | epoch: 059 | loss: 0.94980 - acc: 0.6738 | val_loss: 1.18568 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2100  | total loss: 0.86339 | time: 4.003s
| Adam | epoch: 060 | loss: 0.86339 - acc: 0.6927 | val_loss: 1.17731 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2135  | total loss: 0.96314 | time: 3.994s
| Adam | epoch: 061 | loss: 0.96314 - acc: 0.6668 | val_loss: 1.19361 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2170  | total loss: 0.84216 | time: 4.009s
| Adam | epoch: 062 | loss: 0.84216 - acc: 0.7105 | val_loss: 1.16906 - val_acc: 0.5906 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2205  | total loss: 0.84283 | time: 4.103s
| Adam | epoch: 063 | loss: 0.84283 - acc: 0.7075 | val_loss: 1.18362 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2240  | total loss: 1.01038 | time: 4.028s
| Adam | epoch: 064 | loss: 1.01038 - acc: 0.6742 | val_loss: 1.17907 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2275  | total loss: 0.83873 | time: 4.018s
| Adam | epoch: 065 | loss: 0.83873 - acc: 0.7094 | val_loss: 1.17686 - val_acc: 0.5853 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2310  | total loss: 1.07286 | time: 4.011s
| Adam | epoch: 066 | loss: 1.07286 - acc: 0.6395 | val_loss: 1.19366 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2345  | total loss: 1.06712 | time: 4.024s
| Adam | epoch: 067 | loss: 1.06712 - acc: 0.6579 | val_loss: 1.17422 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2380  | total loss: 0.83141 | time: 4.013s
| Adam | epoch: 068 | loss: 0.83141 - acc: 0.7069 | val_loss: 1.18601 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2415  | total loss: 0.80245 | time: 4.109s
| Adam | epoch: 069 | loss: 0.80245 - acc: 0.7188 | val_loss: 1.17986 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2450  | total loss: 0.81160 | time: 4.021s
| Adam | epoch: 070 | loss: 0.81160 - acc: 0.7223 | val_loss: 1.18378 - val_acc: 0.5827 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2485  | total loss: 0.81900 | time: 4.040s
| Adam | epoch: 071 | loss: 0.81900 - acc: 0.7129 | val_loss: 1.19436 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2520  | total loss: 0.78867 | time: 4.096s
| Adam | epoch: 072 | loss: 0.78867 - acc: 0.7347 | val_loss: 1.18756 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2555  | total loss: 0.79363 | time: 4.100s
| Adam | epoch: 073 | loss: 0.79363 - acc: 0.7246 | val_loss: 1.19307 - val_acc: 0.5879 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2590  | total loss: 0.82028 | time: 4.125s
| Adam | epoch: 074 | loss: 0.82028 - acc: 0.7063 | val_loss: 1.16946 - val_acc: 0.5879 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2625  | total loss: 0.77200 | time: 4.037s
| Adam | epoch: 075 | loss: 0.77200 - acc: 0.7166 | val_loss: 1.20740 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2660  | total loss: 0.78210 | time: 4.050s
| Adam | epoch: 076 | loss: 0.78210 - acc: 0.7244 | val_loss: 1.19182 - val_acc: 0.5879 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2695  | total loss: 0.80578 | time: 4.076s
| Adam | epoch: 077 | loss: 0.80578 - acc: 0.7200 | val_loss: 1.18919 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2730  | total loss: 0.78635 | time: 3.995s
| Adam | epoch: 078 | loss: 0.78635 - acc: 0.7184 | val_loss: 1.22890 - val_acc: 0.5774 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2765  | total loss: 0.80087 | time: 4.007s
| Adam | epoch: 079 | loss: 0.80087 - acc: 0.7211 | val_loss: 1.20541 - val_acc: 0.5879 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2800  | total loss: 0.81133 | time: 4.087s
| Adam | epoch: 080 | loss: 0.81133 - acc: 0.7133 | val_loss: 1.20869 - val_acc: 0.5879 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2835  | total loss: 0.84113 | time: 4.114s
| Adam | epoch: 081 | loss: 0.84113 - acc: 0.7192 | val_loss: 1.21021 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2870  | total loss: 0.75145 | time: 4.072s
| Adam | epoch: 082 | loss: 0.75145 - acc: 0.7368 | val_loss: 1.20287 - val_acc: 0.5827 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2905  | total loss: 0.79913 | time: 4.119s
| Adam | epoch: 083 | loss: 0.79913 - acc: 0.7321 | val_loss: 1.20514 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2940  | total loss: 0.78862 | time: 4.349s
| Adam | epoch: 084 | loss: 0.78862 - acc: 0.7305 | val_loss: 1.22007 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2975  | total loss: 0.75373 | time: 4.116s
| Adam | epoch: 085 | loss: 0.75373 - acc: 0.7321 | val_loss: 1.21702 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3010  | total loss: 0.80174 | time: 4.106s
| Adam | epoch: 086 | loss: 0.80174 - acc: 0.7350 | val_loss: 1.21049 - val_acc: 0.5879 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3045  | total loss: 0.78113 | time: 4.043s
| Adam | epoch: 087 | loss: 0.78113 - acc: 0.7470 | val_loss: 1.21206 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3080  | total loss: 0.80380 | time: 4.045s
| Adam | epoch: 088 | loss: 0.80380 - acc: 0.7285 | val_loss: 1.22881 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3115  | total loss: 0.72345 | time: 4.048s
| Adam | epoch: 089 | loss: 0.72345 - acc: 0.7475 | val_loss: 1.22049 - val_acc: 0.5958 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3150  | total loss: 0.72348 | time: 4.011s
| Adam | epoch: 090 | loss: 0.72348 - acc: 0.7353 | val_loss: 1.23434 - val_acc: 0.5774 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3185  | total loss: 0.80351 | time: 4.019s
| Adam | epoch: 091 | loss: 0.80351 - acc: 0.7384 | val_loss: 1.23757 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3220  | total loss: 0.75601 | time: 4.018s
| Adam | epoch: 092 | loss: 0.75601 - acc: 0.7324 | val_loss: 1.22980 - val_acc: 0.5774 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3255  | total loss: 0.67617 | time: 4.015s
| Adam | epoch: 093 | loss: 0.67617 - acc: 0.7716 | val_loss: 1.23162 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3290  | total loss: 0.69059 | time: 4.307s
| Adam | epoch: 094 | loss: 0.69059 - acc: 0.7688 | val_loss: 1.24186 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3325  | total loss: 0.74293 | time: 4.098s
| Adam | epoch: 095 | loss: 0.74293 - acc: 0.7413 | val_loss: 1.25227 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3360  | total loss: 0.72544 | time: 4.036s
| Adam | epoch: 096 | loss: 0.72544 - acc: 0.7410 | val_loss: 1.25336 - val_acc: 0.5827 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3395  | total loss: 0.68875 | time: 4.006s
| Adam | epoch: 097 | loss: 0.68875 - acc: 0.7705 | val_loss: 1.21105 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3430  | total loss: 0.90306 | time: 4.011s
| Adam | epoch: 098 | loss: 0.90306 - acc: 0.7149 | val_loss: 1.24527 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3465  | total loss: 0.82328 | time: 4.013s
| Adam | epoch: 099 | loss: 0.82328 - acc: 0.7316 | val_loss: 1.25265 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3500  | total loss: 0.67982 | time: 4.000s
| Adam | epoch: 100 | loss: 0.67982 - acc: 0.7614 | val_loss: 1.23657 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

