Training Step: 58  | total loss: 1.65162 | time: 5.127s
| Adam | epoch: 001 | loss: 1.65162 - acc: 0.3182 | val_loss: 1.63261 - val_acc: 0.3176 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 116  | total loss: 1.58371 | time: 4.181s
| Adam | epoch: 002 | loss: 1.58371 - acc: 0.3509 | val_loss: 1.61911 - val_acc: 0.3176 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 174  | total loss: 1.58450 | time: 4.070s
| Adam | epoch: 003 | loss: 1.58450 - acc: 0.3770 | val_loss: 1.60560 - val_acc: 0.3727 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 232  | total loss: 1.54991 | time: 4.176s
| Adam | epoch: 004 | loss: 1.54991 - acc: 0.4048 | val_loss: 1.57501 - val_acc: 0.3937 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 290  | total loss: 1.53772 | time: 4.137s
| Adam | epoch: 005 | loss: 1.53772 - acc: 0.3925 | val_loss: 1.53735 - val_acc: 0.4409 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 348  | total loss: 1.50880 | time: 4.087s
| Adam | epoch: 006 | loss: 1.50880 - acc: 0.4194 | val_loss: 1.49343 - val_acc: 0.4646 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 406  | total loss: 1.42016 | time: 4.052s
| Adam | epoch: 007 | loss: 1.42016 - acc: 0.4731 | val_loss: 1.44292 - val_acc: 0.4541 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 464  | total loss: 1.34710 | time: 4.088s
| Adam | epoch: 008 | loss: 1.34710 - acc: 0.4692 | val_loss: 1.41078 - val_acc: 0.4751 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 522  | total loss: 1.29721 | time: 4.041s
| Adam | epoch: 009 | loss: 1.29721 - acc: 0.5160 | val_loss: 1.37224 - val_acc: 0.5066 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 580  | total loss: 1.27711 | time: 4.064s
| Adam | epoch: 010 | loss: 1.27711 - acc: 0.5399 | val_loss: 1.34071 - val_acc: 0.5249 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 638  | total loss: 1.27259 | time: 4.066s
| Adam | epoch: 011 | loss: 1.27259 - acc: 0.5205 | val_loss: 1.31763 - val_acc: 0.5276 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 696  | total loss: 1.24451 | time: 4.070s
| Adam | epoch: 012 | loss: 1.24451 - acc: 0.5319 | val_loss: 1.31074 - val_acc: 0.5249 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 754  | total loss: 1.18314 | time: 4.082s
| Adam | epoch: 013 | loss: 1.18314 - acc: 0.5642 | val_loss: 1.27819 - val_acc: 0.5302 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 812  | total loss: 1.18874 | time: 4.125s
| Adam | epoch: 014 | loss: 1.18874 - acc: 0.5613 | val_loss: 1.28038 - val_acc: 0.5354 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 870  | total loss: 1.16917 | time: 4.048s
| Adam | epoch: 015 | loss: 1.16917 - acc: 0.5752 | val_loss: 1.26771 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 928  | total loss: 1.15354 | time: 4.073s
| Adam | epoch: 016 | loss: 1.15354 - acc: 0.6000 | val_loss: 1.24751 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 986  | total loss: 1.13004 | time: 4.076s
| Adam | epoch: 017 | loss: 1.13004 - acc: 0.5984 | val_loss: 1.24940 - val_acc: 0.5459 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1044  | total loss: 1.07245 | time: 4.073s
| Adam | epoch: 018 | loss: 1.07245 - acc: 0.6145 | val_loss: 1.22780 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1102  | total loss: 1.02993 | time: 4.063s
| Adam | epoch: 019 | loss: 1.02993 - acc: 0.6349 | val_loss: 1.20791 - val_acc: 0.5827 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1160  | total loss: 1.07956 | time: 4.067s
| Adam | epoch: 020 | loss: 1.07956 - acc: 0.6181 | val_loss: 1.20846 - val_acc: 0.5853 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1218  | total loss: 1.05075 | time: 4.072s
| Adam | epoch: 021 | loss: 1.05075 - acc: 0.6192 | val_loss: 1.21169 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1276  | total loss: 1.05679 | time: 4.033s
| Adam | epoch: 022 | loss: 1.05679 - acc: 0.6143 | val_loss: 1.20831 - val_acc: 0.5774 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1334  | total loss: 0.98648 | time: 4.021s
| Adam | epoch: 023 | loss: 0.98648 - acc: 0.6618 | val_loss: 1.20810 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1392  | total loss: 1.05095 | time: 4.018s
| Adam | epoch: 024 | loss: 1.05095 - acc: 0.6332 | val_loss: 1.17998 - val_acc: 0.5827 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1450  | total loss: 1.00699 | time: 4.068s
| Adam | epoch: 025 | loss: 1.00699 - acc: 0.6458 | val_loss: 1.19149 - val_acc: 0.5827 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1508  | total loss: 0.99611 | time: 4.077s
| Adam | epoch: 026 | loss: 0.99611 - acc: 0.6350 | val_loss: 1.16824 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1566  | total loss: 0.94402 | time: 4.072s
| Adam | epoch: 027 | loss: 0.94402 - acc: 0.6667 | val_loss: 1.17121 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1624  | total loss: 0.94533 | time: 4.094s
| Adam | epoch: 028 | loss: 0.94533 - acc: 0.6651 | val_loss: 1.18009 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1682  | total loss: 0.89360 | time: 4.072s
| Adam | epoch: 029 | loss: 0.89360 - acc: 0.6927 | val_loss: 1.17088 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1740  | total loss: 0.90652 | time: 4.073s
| Adam | epoch: 030 | loss: 0.90652 - acc: 0.6773 | val_loss: 1.18171 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1798  | total loss: 0.86981 | time: 4.060s
| Adam | epoch: 031 | loss: 0.86981 - acc: 0.6847 | val_loss: 1.16689 - val_acc: 0.5879 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1856  | total loss: 0.87963 | time: 4.076s
| Adam | epoch: 032 | loss: 0.87963 - acc: 0.6882 | val_loss: 1.17157 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1914  | total loss: 0.86146 | time: 4.062s
| Adam | epoch: 033 | loss: 0.86146 - acc: 0.6936 | val_loss: 1.18067 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1972  | total loss: 0.87681 | time: 4.057s
| Adam | epoch: 034 | loss: 0.87681 - acc: 0.6912 | val_loss: 1.17143 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2030  | total loss: 0.83395 | time: 4.058s
| Adam | epoch: 035 | loss: 0.83395 - acc: 0.7014 | val_loss: 1.16248 - val_acc: 0.5853 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2088  | total loss: 0.84623 | time: 4.070s
| Adam | epoch: 036 | loss: 0.84623 - acc: 0.7015 | val_loss: 1.17935 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2146  | total loss: 0.84140 | time: 4.051s
| Adam | epoch: 037 | loss: 0.84140 - acc: 0.7068 | val_loss: 1.19533 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2204  | total loss: 0.81385 | time: 4.066s
| Adam | epoch: 038 | loss: 0.81385 - acc: 0.7253 | val_loss: 1.21317 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2262  | total loss: 0.82583 | time: 4.077s
| Adam | epoch: 039 | loss: 0.82583 - acc: 0.7197 | val_loss: 1.21210 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2320  | total loss: 0.81219 | time: 4.071s
| Adam | epoch: 040 | loss: 0.81219 - acc: 0.7130 | val_loss: 1.17406 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2378  | total loss: 0.77767 | time: 4.068s
| Adam | epoch: 041 | loss: 0.77767 - acc: 0.7235 | val_loss: 1.20264 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2436  | total loss: 0.81228 | time: 4.074s
| Adam | epoch: 042 | loss: 0.81228 - acc: 0.7194 | val_loss: 1.19223 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2494  | total loss: 0.75168 | time: 4.058s
| Adam | epoch: 043 | loss: 0.75168 - acc: 0.7440 | val_loss: 1.19780 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2552  | total loss: 0.81413 | time: 4.069s
| Adam | epoch: 044 | loss: 0.81413 - acc: 0.7023 | val_loss: 1.24133 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2610  | total loss: 0.74685 | time: 4.059s
| Adam | epoch: 045 | loss: 0.74685 - acc: 0.7394 | val_loss: 1.21135 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2668  | total loss: 0.79280 | time: 4.078s
| Adam | epoch: 046 | loss: 0.79280 - acc: 0.7089 | val_loss: 1.22593 - val_acc: 0.5827 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2726  | total loss: 0.73220 | time: 4.051s
| Adam | epoch: 047 | loss: 0.73220 - acc: 0.7381 | val_loss: 1.19000 - val_acc: 0.5827 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2784  | total loss: 0.73321 | time: 4.077s
| Adam | epoch: 048 | loss: 0.73321 - acc: 0.7568 | val_loss: 1.22397 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2842  | total loss: 0.71308 | time: 4.083s
| Adam | epoch: 049 | loss: 0.71308 - acc: 0.7651 | val_loss: 1.21414 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2900  | total loss: 0.71881 | time: 4.064s
| Adam | epoch: 050 | loss: 0.71881 - acc: 0.7421 | val_loss: 1.21533 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2958  | total loss: 0.71147 | time: 4.065s
| Adam | epoch: 051 | loss: 0.71147 - acc: 0.7539 | val_loss: 1.21069 - val_acc: 0.5906 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3016  | total loss: 0.67796 | time: 4.077s
| Adam | epoch: 052 | loss: 0.67796 - acc: 0.7605 | val_loss: 1.21879 - val_acc: 0.5774 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3074  | total loss: 0.65266 | time: 4.066s
| Adam | epoch: 053 | loss: 0.65266 - acc: 0.7675 | val_loss: 1.22123 - val_acc: 0.5879 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3132  | total loss: 0.67250 | time: 4.076s
| Adam | epoch: 054 | loss: 0.67250 - acc: 0.7550 | val_loss: 1.25752 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3190  | total loss: 0.68801 | time: 4.071s
| Adam | epoch: 055 | loss: 0.68801 - acc: 0.7530 | val_loss: 1.24917 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3248  | total loss: 0.64916 | time: 4.080s
| Adam | epoch: 056 | loss: 0.64916 - acc: 0.7962 | val_loss: 1.29203 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3306  | total loss: 0.63403 | time: 4.064s
| Adam | epoch: 057 | loss: 0.63403 - acc: 0.7795 | val_loss: 1.27598 - val_acc: 0.5774 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3364  | total loss: 0.68176 | time: 4.066s
| Adam | epoch: 058 | loss: 0.68176 - acc: 0.7610 | val_loss: 1.26580 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3422  | total loss: 0.65154 | time: 4.074s
| Adam | epoch: 059 | loss: 0.65154 - acc: 0.7683 | val_loss: 1.29193 - val_acc: 0.5774 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3480  | total loss: 0.64840 | time: 4.109s
| Adam | epoch: 060 | loss: 0.64840 - acc: 0.7599 | val_loss: 1.25239 - val_acc: 0.5932 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3538  | total loss: 0.60876 | time: 4.111s
| Adam | epoch: 061 | loss: 0.60876 - acc: 0.7934 | val_loss: 1.29040 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3596  | total loss: 0.58584 | time: 4.066s
| Adam | epoch: 062 | loss: 0.58584 - acc: 0.7785 | val_loss: 1.32149 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3654  | total loss: 0.62548 | time: 4.059s
| Adam | epoch: 063 | loss: 0.62548 - acc: 0.7880 | val_loss: 1.31388 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3712  | total loss: 0.60048 | time: 4.064s
| Adam | epoch: 064 | loss: 0.60048 - acc: 0.7889 | val_loss: 1.31454 - val_acc: 0.5774 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3770  | total loss: 0.59882 | time: 4.065s
| Adam | epoch: 065 | loss: 0.59882 - acc: 0.7925 | val_loss: 1.34451 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3828  | total loss: 0.60747 | time: 4.057s
| Adam | epoch: 066 | loss: 0.60747 - acc: 0.7939 | val_loss: 1.33553 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3886  | total loss: 0.63311 | time: 4.054s
| Adam | epoch: 067 | loss: 0.63311 - acc: 0.7721 | val_loss: 1.33898 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3944  | total loss: 0.56380 | time: 4.049s
| Adam | epoch: 068 | loss: 0.56380 - acc: 0.8271 | val_loss: 1.32640 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4002  | total loss: 0.57871 | time: 4.073s
| Adam | epoch: 069 | loss: 0.57871 - acc: 0.7950 | val_loss: 1.34423 - val_acc: 0.5564 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4060  | total loss: 0.57481 | time: 4.087s
| Adam | epoch: 070 | loss: 0.57481 - acc: 0.8158 | val_loss: 1.33082 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4118  | total loss: 0.55176 | time: 4.080s
| Adam | epoch: 071 | loss: 0.55176 - acc: 0.8067 | val_loss: 1.32931 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4176  | total loss: 0.54692 | time: 4.066s
| Adam | epoch: 072 | loss: 0.54692 - acc: 0.8069 | val_loss: 1.34917 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4234  | total loss: 0.60246 | time: 4.126s
| Adam | epoch: 073 | loss: 0.60246 - acc: 0.7953 | val_loss: 1.34009 - val_acc: 0.5853 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4292  | total loss: 0.53347 | time: 4.163s
| Adam | epoch: 074 | loss: 0.53347 - acc: 0.8162 | val_loss: 1.37696 - val_acc: 0.5564 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4350  | total loss: 0.55682 | time: 4.060s
| Adam | epoch: 075 | loss: 0.55682 - acc: 0.7996 | val_loss: 1.35680 - val_acc: 0.5774 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4408  | total loss: 0.55452 | time: 4.056s
| Adam | epoch: 076 | loss: 0.55452 - acc: 0.8110 | val_loss: 1.37598 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4466  | total loss: 0.51048 | time: 4.085s
| Adam | epoch: 077 | loss: 0.51048 - acc: 0.8307 | val_loss: 1.42972 - val_acc: 0.5459 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4524  | total loss: 0.52846 | time: 4.078s
| Adam | epoch: 078 | loss: 0.52846 - acc: 0.8091 | val_loss: 1.41958 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4582  | total loss: 0.50097 | time: 4.060s
| Adam | epoch: 079 | loss: 0.50097 - acc: 0.8283 | val_loss: 1.41856 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4640  | total loss: 0.57111 | time: 4.080s
| Adam | epoch: 080 | loss: 0.57111 - acc: 0.7978 | val_loss: 1.40935 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4698  | total loss: 0.55423 | time: 4.083s
| Adam | epoch: 081 | loss: 0.55423 - acc: 0.8109 | val_loss: 1.39737 - val_acc: 0.5748 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4756  | total loss: 0.56369 | time: 4.079s
| Adam | epoch: 082 | loss: 0.56369 - acc: 0.8122 | val_loss: 1.38175 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4814  | total loss: 0.49659 | time: 4.086s
| Adam | epoch: 083 | loss: 0.49659 - acc: 0.8321 | val_loss: 1.40514 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4872  | total loss: 0.52405 | time: 4.070s
| Adam | epoch: 084 | loss: 0.52405 - acc: 0.8212 | val_loss: 1.41615 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4930  | total loss: 0.48796 | time: 4.061s
| Adam | epoch: 085 | loss: 0.48796 - acc: 0.8300 | val_loss: 1.43744 - val_acc: 0.5879 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4988  | total loss: 0.51122 | time: 4.082s
| Adam | epoch: 086 | loss: 0.51122 - acc: 0.8254 | val_loss: 1.42567 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5046  | total loss: 0.53287 | time: 4.072s
| Adam | epoch: 087 | loss: 0.53287 - acc: 0.8069 | val_loss: 1.43324 - val_acc: 0.5564 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5104  | total loss: 0.50478 | time: 4.070s
| Adam | epoch: 088 | loss: 0.50478 - acc: 0.8269 | val_loss: 1.46007 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5162  | total loss: 0.55373 | time: 4.061s
| Adam | epoch: 089 | loss: 0.55373 - acc: 0.8126 | val_loss: 1.48094 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5220  | total loss: 0.50797 | time: 4.044s
| Adam | epoch: 090 | loss: 0.50797 - acc: 0.8154 | val_loss: 1.44642 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5278  | total loss: 0.50506 | time: 4.079s
| Adam | epoch: 091 | loss: 0.50506 - acc: 0.8241 | val_loss: 1.44937 - val_acc: 0.5801 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5336  | total loss: 0.51446 | time: 4.076s
| Adam | epoch: 092 | loss: 0.51446 - acc: 0.8216 | val_loss: 1.48811 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5394  | total loss: 0.48909 | time: 4.075s
| Adam | epoch: 093 | loss: 0.48909 - acc: 0.8369 | val_loss: 1.45545 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5452  | total loss: 0.49112 | time: 4.067s
| Adam | epoch: 094 | loss: 0.49112 - acc: 0.8319 | val_loss: 1.51585 - val_acc: 0.5722 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5510  | total loss: 0.49233 | time: 4.066s
| Adam | epoch: 095 | loss: 0.49233 - acc: 0.8202 | val_loss: 1.50658 - val_acc: 0.5617 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5568  | total loss: 0.46642 | time: 4.070s
| Adam | epoch: 096 | loss: 0.46642 - acc: 0.8325 | val_loss: 1.47351 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5626  | total loss: 0.51599 | time: 4.073s
| Adam | epoch: 097 | loss: 0.51599 - acc: 0.8294 | val_loss: 1.52832 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5684  | total loss: 0.46546 | time: 4.071s
| Adam | epoch: 098 | loss: 0.46546 - acc: 0.8343 | val_loss: 1.55402 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5742  | total loss: 0.45609 | time: 4.062s
| Adam | epoch: 099 | loss: 0.45609 - acc: 0.8325 | val_loss: 1.55897 - val_acc: 0.5512 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5800  | total loss: 0.44473 | time: 4.060s
| Adam | epoch: 100 | loss: 0.44473 - acc: 0.8503 | val_loss: 1.48079 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

