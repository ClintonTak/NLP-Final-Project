Training Step: 105  | total loss: 1.58843 | time: 8.172s
| Adam | epoch: 001 | loss: 1.58843 - acc: 0.3740 | val_loss: 1.57379 - val_acc: 0.3666 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 210  | total loss: 1.58900 | time: 7.227s
| Adam | epoch: 002 | loss: 1.58900 - acc: 0.3468 | val_loss: 1.55284 - val_acc: 0.3827 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 315  | total loss: 1.53375 | time: 6.917s
| Adam | epoch: 003 | loss: 1.53375 - acc: 0.4081 | val_loss: 1.51773 - val_acc: 0.4070 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 420  | total loss: 1.52841 | time: 6.952s
| Adam | epoch: 004 | loss: 1.52841 - acc: 0.4238 | val_loss: 1.48330 - val_acc: 0.4286 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 525  | total loss: 1.50180 | time: 6.929s
| Adam | epoch: 005 | loss: 1.50180 - acc: 0.4052 | val_loss: 1.44790 - val_acc: 0.4528 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 630  | total loss: 1.44986 | time: 7.019s
| Adam | epoch: 006 | loss: 1.44986 - acc: 0.4566 | val_loss: 1.39766 - val_acc: 0.4771 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 735  | total loss: 1.39842 | time: 6.988s
| Adam | epoch: 007 | loss: 1.39842 - acc: 0.4908 | val_loss: 1.35957 - val_acc: 0.4852 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 840  | total loss: 1.41597 | time: 6.998s
| Adam | epoch: 008 | loss: 1.41597 - acc: 0.4846 | val_loss: 1.34160 - val_acc: 0.5067 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 945  | total loss: 1.36186 | time: 7.009s
| Adam | epoch: 009 | loss: 1.36186 - acc: 0.5001 | val_loss: 1.30840 - val_acc: 0.4987 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1050  | total loss: 1.34149 | time: 6.979s
| Adam | epoch: 010 | loss: 1.34149 - acc: 0.5130 | val_loss: 1.29343 - val_acc: 0.5148 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1155  | total loss: 1.31075 | time: 6.926s
| Adam | epoch: 011 | loss: 1.31075 - acc: 0.5360 | val_loss: 1.28352 - val_acc: 0.5526 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1260  | total loss: 1.32522 | time: 6.876s
| Adam | epoch: 012 | loss: 1.32522 - acc: 0.5053 | val_loss: 1.26235 - val_acc: 0.5418 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1365  | total loss: 1.31302 | time: 6.906s
| Adam | epoch: 013 | loss: 1.31302 - acc: 0.5300 | val_loss: 1.27473 - val_acc: 0.5229 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1470  | total loss: 1.19338 | time: 6.921s
| Adam | epoch: 014 | loss: 1.19338 - acc: 0.5718 | val_loss: 1.23776 - val_acc: 0.5580 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1575  | total loss: 1.23965 | time: 6.932s
| Adam | epoch: 015 | loss: 1.23965 - acc: 0.5512 | val_loss: 1.23420 - val_acc: 0.5606 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1680  | total loss: 1.23466 | time: 6.913s
| Adam | epoch: 016 | loss: 1.23466 - acc: 0.5647 | val_loss: 1.21624 - val_acc: 0.5714 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1785  | total loss: 1.21385 | time: 6.942s
| Adam | epoch: 017 | loss: 1.21385 - acc: 0.5629 | val_loss: 1.22029 - val_acc: 0.5499 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1890  | total loss: 1.21903 | time: 6.924s
| Adam | epoch: 018 | loss: 1.21903 - acc: 0.5701 | val_loss: 1.21656 - val_acc: 0.5553 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1995  | total loss: 1.23044 | time: 6.926s
| Adam | epoch: 019 | loss: 1.23044 - acc: 0.5595 | val_loss: 1.20015 - val_acc: 0.5687 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2100  | total loss: 1.18628 | time: 6.922s
| Adam | epoch: 020 | loss: 1.18628 - acc: 0.5707 | val_loss: 1.20842 - val_acc: 0.5687 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2205  | total loss: 1.18129 | time: 6.924s
| Adam | epoch: 021 | loss: 1.18129 - acc: 0.5674 | val_loss: 1.18717 - val_acc: 0.5768 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2310  | total loss: 1.13797 | time: 6.912s
| Adam | epoch: 022 | loss: 1.13797 - acc: 0.6068 | val_loss: 1.18441 - val_acc: 0.5822 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2415  | total loss: 1.16824 | time: 7.194s
| Adam | epoch: 023 | loss: 1.16824 - acc: 0.5894 | val_loss: 1.17562 - val_acc: 0.5768 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2520  | total loss: 1.08422 | time: 6.964s
| Adam | epoch: 024 | loss: 1.08422 - acc: 0.6068 | val_loss: 1.17986 - val_acc: 0.5714 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2625  | total loss: 1.13913 | time: 6.953s
| Adam | epoch: 025 | loss: 1.13913 - acc: 0.5798 | val_loss: 1.18951 - val_acc: 0.5822 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2730  | total loss: 1.05185 | time: 6.979s
| Adam | epoch: 026 | loss: 1.05185 - acc: 0.6119 | val_loss: 1.18946 - val_acc: 0.5526 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2835  | total loss: 1.10856 | time: 6.976s
| Adam | epoch: 027 | loss: 1.10856 - acc: 0.5733 | val_loss: 1.17005 - val_acc: 0.5849 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2940  | total loss: 1.09818 | time: 6.958s
| Adam | epoch: 028 | loss: 1.09818 - acc: 0.6079 | val_loss: 1.19703 - val_acc: 0.5741 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3045  | total loss: 1.08980 | time: 6.931s
| Adam | epoch: 029 | loss: 1.08980 - acc: 0.5980 | val_loss: 1.18381 - val_acc: 0.5957 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3150  | total loss: 1.13191 | time: 6.909s
| Adam | epoch: 030 | loss: 1.13191 - acc: 0.5958 | val_loss: 1.19160 - val_acc: 0.5849 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3255  | total loss: 1.03954 | time: 6.920s
| Adam | epoch: 031 | loss: 1.03954 - acc: 0.6231 | val_loss: 1.17976 - val_acc: 0.5876 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3360  | total loss: 1.05202 | time: 6.936s
| Adam | epoch: 032 | loss: 1.05202 - acc: 0.6204 | val_loss: 1.19901 - val_acc: 0.5930 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3465  | total loss: 1.07393 | time: 6.905s
| Adam | epoch: 033 | loss: 1.07393 - acc: 0.6115 | val_loss: 1.19441 - val_acc: 0.5876 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3570  | total loss: 1.07080 | time: 6.889s
| Adam | epoch: 034 | loss: 1.07080 - acc: 0.6054 | val_loss: 1.19144 - val_acc: 0.5768 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3675  | total loss: 1.06777 | time: 6.941s
| Adam | epoch: 035 | loss: 1.06777 - acc: 0.6332 | val_loss: 1.20903 - val_acc: 0.5687 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3780  | total loss: 1.01584 | time: 6.917s
| Adam | epoch: 036 | loss: 1.01584 - acc: 0.6362 | val_loss: 1.19791 - val_acc: 0.5687 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3885  | total loss: 1.04584 | time: 6.899s
| Adam | epoch: 037 | loss: 1.04584 - acc: 0.5982 | val_loss: 1.22755 - val_acc: 0.5768 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3990  | total loss: 1.05252 | time: 6.939s
| Adam | epoch: 038 | loss: 1.05252 - acc: 0.6265 | val_loss: 1.22391 - val_acc: 0.5714 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4095  | total loss: 0.96938 | time: 6.919s
| Adam | epoch: 039 | loss: 0.96938 - acc: 0.6326 | val_loss: 1.21845 - val_acc: 0.5795 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4200  | total loss: 1.04883 | time: 6.919s
| Adam | epoch: 040 | loss: 1.04883 - acc: 0.6357 | val_loss: 1.22210 - val_acc: 0.5903 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4305  | total loss: 1.10177 | time: 6.899s
| Adam | epoch: 041 | loss: 1.10177 - acc: 0.6037 | val_loss: 1.23668 - val_acc: 0.5849 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4410  | total loss: 1.02991 | time: 6.928s
| Adam | epoch: 042 | loss: 1.02991 - acc: 0.6416 | val_loss: 1.25571 - val_acc: 0.5741 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4515  | total loss: 1.05586 | time: 6.917s
| Adam | epoch: 043 | loss: 1.05586 - acc: 0.6072 | val_loss: 1.24849 - val_acc: 0.5795 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4620  | total loss: 0.93309 | time: 6.923s
| Adam | epoch: 044 | loss: 0.93309 - acc: 0.6705 | val_loss: 1.24607 - val_acc: 0.5741 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4725  | total loss: 0.99639 | time: 6.937s
| Adam | epoch: 045 | loss: 0.99639 - acc: 0.6531 | val_loss: 1.24835 - val_acc: 0.5903 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4830  | total loss: 1.07235 | time: 6.944s
| Adam | epoch: 046 | loss: 1.07235 - acc: 0.5982 | val_loss: 1.25010 - val_acc: 0.5822 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4935  | total loss: 0.96875 | time: 6.917s
| Adam | epoch: 047 | loss: 0.96875 - acc: 0.6558 | val_loss: 1.23801 - val_acc: 0.5903 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5040  | total loss: 1.03244 | time: 6.909s
| Adam | epoch: 048 | loss: 1.03244 - acc: 0.6298 | val_loss: 1.25025 - val_acc: 0.5984 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5145  | total loss: 0.93304 | time: 6.915s
| Adam | epoch: 049 | loss: 0.93304 - acc: 0.6706 | val_loss: 1.26437 - val_acc: 0.5849 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5250  | total loss: 0.94878 | time: 6.930s
| Adam | epoch: 050 | loss: 0.94878 - acc: 0.6641 | val_loss: 1.25700 - val_acc: 0.5687 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5355  | total loss: 0.94782 | time: 6.914s
| Adam | epoch: 051 | loss: 0.94782 - acc: 0.6455 | val_loss: 1.28338 - val_acc: 0.5741 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5460  | total loss: 0.95199 | time: 6.956s
| Adam | epoch: 052 | loss: 0.95199 - acc: 0.6518 | val_loss: 1.29173 - val_acc: 0.5822 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5565  | total loss: 0.86902 | time: 6.920s
| Adam | epoch: 053 | loss: 0.86902 - acc: 0.6903 | val_loss: 1.29660 - val_acc: 0.5876 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5670  | total loss: 0.92182 | time: 6.915s
| Adam | epoch: 054 | loss: 0.92182 - acc: 0.6467 | val_loss: 1.29236 - val_acc: 0.5822 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5775  | total loss: 0.92804 | time: 6.909s
| Adam | epoch: 055 | loss: 0.92804 - acc: 0.6595 | val_loss: 1.30649 - val_acc: 0.5580 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5880  | total loss: 0.89258 | time: 6.916s
| Adam | epoch: 056 | loss: 0.89258 - acc: 0.6805 | val_loss: 1.29103 - val_acc: 0.5822 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5985  | total loss: 0.87124 | time: 6.901s
| Adam | epoch: 057 | loss: 0.87124 - acc: 0.6782 | val_loss: 1.31755 - val_acc: 0.5849 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6090  | total loss: 0.93860 | time: 6.924s
| Adam | epoch: 058 | loss: 0.93860 - acc: 0.6629 | val_loss: 1.31185 - val_acc: 0.5822 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6195  | total loss: 0.94113 | time: 6.932s
| Adam | epoch: 059 | loss: 0.94113 - acc: 0.6602 | val_loss: 1.31690 - val_acc: 0.5687 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6300  | total loss: 0.97235 | time: 6.935s
| Adam | epoch: 060 | loss: 0.97235 - acc: 0.6652 | val_loss: 1.31962 - val_acc: 0.5741 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6405  | total loss: 0.94480 | time: 6.911s
| Adam | epoch: 061 | loss: 0.94480 - acc: 0.6724 | val_loss: 1.34291 - val_acc: 0.5660 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6510  | total loss: 0.92861 | time: 6.919s
| Adam | epoch: 062 | loss: 0.92861 - acc: 0.6643 | val_loss: 1.35123 - val_acc: 0.5768 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6615  | total loss: 0.96645 | time: 6.922s
| Adam | epoch: 063 | loss: 0.96645 - acc: 0.6528 | val_loss: 1.34053 - val_acc: 0.5768 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6720  | total loss: 0.89250 | time: 6.926s
| Adam | epoch: 064 | loss: 0.89250 - acc: 0.6815 | val_loss: 1.31893 - val_acc: 0.5741 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6825  | total loss: 0.90402 | time: 6.890s
| Adam | epoch: 065 | loss: 0.90402 - acc: 0.6736 | val_loss: 1.32401 - val_acc: 0.5822 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6930  | total loss: 0.87904 | time: 6.934s
| Adam | epoch: 066 | loss: 0.87904 - acc: 0.6673 | val_loss: 1.32766 - val_acc: 0.5984 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7035  | total loss: 0.82153 | time: 6.917s
| Adam | epoch: 067 | loss: 0.82153 - acc: 0.7101 | val_loss: 1.34669 - val_acc: 0.5849 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7140  | total loss: 0.87364 | time: 6.898s
| Adam | epoch: 068 | loss: 0.87364 - acc: 0.6910 | val_loss: 1.34925 - val_acc: 0.5822 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7245  | total loss: 0.93322 | time: 6.964s
| Adam | epoch: 069 | loss: 0.93322 - acc: 0.6528 | val_loss: 1.34445 - val_acc: 0.5795 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7350  | total loss: 0.90110 | time: 6.912s
| Adam | epoch: 070 | loss: 0.90110 - acc: 0.6651 | val_loss: 1.36412 - val_acc: 0.5876 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7455  | total loss: 0.81875 | time: 6.908s
| Adam | epoch: 071 | loss: 0.81875 - acc: 0.7107 | val_loss: 1.37562 - val_acc: 0.5849 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7560  | total loss: 0.90464 | time: 6.901s
| Adam | epoch: 072 | loss: 0.90464 - acc: 0.6584 | val_loss: 1.38747 - val_acc: 0.5687 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7665  | total loss: 0.84131 | time: 6.918s
| Adam | epoch: 073 | loss: 0.84131 - acc: 0.7025 | val_loss: 1.35775 - val_acc: 0.5795 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7770  | total loss: 0.88510 | time: 6.925s
| Adam | epoch: 074 | loss: 0.88510 - acc: 0.6807 | val_loss: 1.37731 - val_acc: 0.5741 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7875  | total loss: 0.90443 | time: 6.921s
| Adam | epoch: 075 | loss: 0.90443 - acc: 0.6736 | val_loss: 1.41114 - val_acc: 0.5768 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7980  | total loss: 0.86601 | time: 6.943s
| Adam | epoch: 076 | loss: 0.86601 - acc: 0.6954 | val_loss: 1.39191 - val_acc: 0.5687 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8085  | total loss: 0.86512 | time: 6.917s
| Adam | epoch: 077 | loss: 0.86512 - acc: 0.6911 | val_loss: 1.42177 - val_acc: 0.5687 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8190  | total loss: 0.87175 | time: 6.926s
| Adam | epoch: 078 | loss: 0.87175 - acc: 0.6839 | val_loss: 1.42110 - val_acc: 0.5660 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8295  | total loss: 0.86393 | time: 6.933s
| Adam | epoch: 079 | loss: 0.86393 - acc: 0.6917 | val_loss: 1.38242 - val_acc: 0.5795 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8400  | total loss: 0.87139 | time: 6.923s
| Adam | epoch: 080 | loss: 0.87139 - acc: 0.6735 | val_loss: 1.35590 - val_acc: 0.5822 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8505  | total loss: 0.83584 | time: 6.893s
| Adam | epoch: 081 | loss: 0.83584 - acc: 0.6915 | val_loss: 1.39522 - val_acc: 0.5687 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8610  | total loss: 0.82095 | time: 6.926s
| Adam | epoch: 082 | loss: 0.82095 - acc: 0.7186 | val_loss: 1.40449 - val_acc: 0.5849 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8715  | total loss: 0.84128 | time: 6.929s
| Adam | epoch: 083 | loss: 0.84128 - acc: 0.6993 | val_loss: 1.38804 - val_acc: 0.5714 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8820  | total loss: 0.85429 | time: 6.926s
| Adam | epoch: 084 | loss: 0.85429 - acc: 0.7112 | val_loss: 1.39630 - val_acc: 0.5768 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8925  | total loss: 0.90730 | time: 6.904s
| Adam | epoch: 085 | loss: 0.90730 - acc: 0.6534 | val_loss: 1.42381 - val_acc: 0.5822 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9030  | total loss: 0.81048 | time: 6.936s
| Adam | epoch: 086 | loss: 0.81048 - acc: 0.7139 | val_loss: 1.45312 - val_acc: 0.5499 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9135  | total loss: 0.78249 | time: 6.952s
| Adam | epoch: 087 | loss: 0.78249 - acc: 0.7218 | val_loss: 1.46491 - val_acc: 0.5795 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9240  | total loss: 0.80772 | time: 6.917s
| Adam | epoch: 088 | loss: 0.80772 - acc: 0.7233 | val_loss: 1.47176 - val_acc: 0.5849 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9345  | total loss: 0.87267 | time: 6.989s
| Adam | epoch: 089 | loss: 0.87267 - acc: 0.7082 | val_loss: 1.49369 - val_acc: 0.5822 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9450  | total loss: 0.82688 | time: 6.943s
| Adam | epoch: 090 | loss: 0.82688 - acc: 0.7061 | val_loss: 1.48773 - val_acc: 0.6011 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9555  | total loss: 0.72562 | time: 7.063s
| Adam | epoch: 091 | loss: 0.72562 - acc: 0.7415 | val_loss: 1.45598 - val_acc: 0.5822 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9660  | total loss: 0.84440 | time: 7.083s
| Adam | epoch: 092 | loss: 0.84440 - acc: 0.6993 | val_loss: 1.42861 - val_acc: 0.6038 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9765  | total loss: 0.80496 | time: 7.134s
| Adam | epoch: 093 | loss: 0.80496 - acc: 0.7111 | val_loss: 1.45446 - val_acc: 0.5903 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9870  | total loss: 0.77157 | time: 6.943s
| Adam | epoch: 094 | loss: 0.77157 - acc: 0.7258 | val_loss: 1.50729 - val_acc: 0.5499 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9975  | total loss: 0.83463 | time: 6.927s
| Adam | epoch: 095 | loss: 0.83463 - acc: 0.7231 | val_loss: 1.49434 - val_acc: 0.5822 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 10080  | total loss: 0.84117 | time: 6.931s
| Adam | epoch: 096 | loss: 0.84117 - acc: 0.7189 | val_loss: 1.47882 - val_acc: 0.5795 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 10185  | total loss: 0.82167 | time: 6.941s
| Adam | epoch: 097 | loss: 0.82167 - acc: 0.6939 | val_loss: 1.48499 - val_acc: 0.5768 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 10290  | total loss: 0.70013 | time: 6.923s
| Adam | epoch: 098 | loss: 0.70013 - acc: 0.7688 | val_loss: 1.48328 - val_acc: 0.5768 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 10395  | total loss: 0.77095 | time: 6.942s
| Adam | epoch: 099 | loss: 0.77095 - acc: 0.7373 | val_loss: 1.47269 - val_acc: 0.5741 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 10500  | total loss: 0.84980 | time: 6.934s
| Adam | epoch: 100 | loss: 0.84980 - acc: 0.6733 | val_loss: 1.46857 - val_acc: 0.5876 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

