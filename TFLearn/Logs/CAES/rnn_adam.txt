Training Step: 108  | total loss: 1.61993 | time: 68.033s
| Adam | epoch: 001 | loss: 1.61993 - acc: 0.3516 | val_loss: 1.55541 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 216  | total loss: 1.60048 | time: 23.102s
| Adam | epoch: 002 | loss: 1.60048 - acc: 0.3514 | val_loss: 1.55147 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 324  | total loss: 1.57002 | time: 23.132s
| Adam | epoch: 003 | loss: 1.57002 - acc: 0.3604 | val_loss: 1.54740 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 432  | total loss: 1.60443 | time: 23.437s
| Adam | epoch: 004 | loss: 1.60443 - acc: 0.3417 | val_loss: 1.55373 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 540  | total loss: 1.62712 | time: 23.059s
| Adam | epoch: 005 | loss: 1.62712 - acc: 0.3448 | val_loss: 1.55652 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 648  | total loss: 1.65092 | time: 23.096s
| Adam | epoch: 006 | loss: 1.65092 - acc: 0.3166 | val_loss: 1.56162 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 756  | total loss: 1.60102 | time: 23.195s
| Adam | epoch: 007 | loss: 1.60102 - acc: 0.3411 | val_loss: 1.54620 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 864  | total loss: 1.59900 | time: 23.194s
| Adam | epoch: 008 | loss: 1.59900 - acc: 0.3134 | val_loss: 1.55396 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 972  | total loss: 1.60082 | time: 23.088s
| Adam | epoch: 009 | loss: 1.60082 - acc: 0.3469 | val_loss: 1.54852 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1080  | total loss: 1.63606 | time: 23.067s
| Adam | epoch: 010 | loss: 1.63606 - acc: 0.3291 | val_loss: 1.55541 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1188  | total loss: 1.61128 | time: 23.118s
| Adam | epoch: 011 | loss: 1.61128 - acc: 0.3692 | val_loss: 1.55794 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1296  | total loss: 1.57201 | time: 23.104s
| Adam | epoch: 012 | loss: 1.57201 - acc: 0.3485 | val_loss: 1.55288 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1404  | total loss: 1.60446 | time: 23.080s
| Adam | epoch: 013 | loss: 1.60446 - acc: 0.3578 | val_loss: 1.55771 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1512  | total loss: 1.59145 | time: 23.072s
| Adam | epoch: 014 | loss: 1.59145 - acc: 0.3470 | val_loss: 1.55010 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1620  | total loss: 1.56764 | time: 23.368s
| Adam | epoch: 015 | loss: 1.56764 - acc: 0.3506 | val_loss: 1.54521 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1728  | total loss: 1.59922 | time: 23.824s
| Adam | epoch: 016 | loss: 1.59922 - acc: 0.3632 | val_loss: 1.54751 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1836  | total loss: 1.62090 | time: 23.101s
| Adam | epoch: 017 | loss: 1.62090 - acc: 0.3463 | val_loss: 1.55732 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 1944  | total loss: 1.59757 | time: 23.149s
| Adam | epoch: 018 | loss: 1.59757 - acc: 0.3690 | val_loss: 1.55470 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2052  | total loss: 1.60098 | time: 23.123s
| Adam | epoch: 019 | loss: 1.60098 - acc: 0.3625 | val_loss: 1.55121 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2160  | total loss: 1.59852 | time: 23.116s
| Adam | epoch: 020 | loss: 1.59852 - acc: 0.3374 | val_loss: 1.55258 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2268  | total loss: 1.65389 | time: 23.047s
| Adam | epoch: 021 | loss: 1.65389 - acc: 0.3325 | val_loss: 1.55161 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2376  | total loss: 1.60396 | time: 23.074s
| Adam | epoch: 022 | loss: 1.60396 - acc: 0.3425 | val_loss: 1.54824 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2484  | total loss: 1.63363 | time: 23.142s
| Adam | epoch: 023 | loss: 1.63363 - acc: 0.3051 | val_loss: 1.55291 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2592  | total loss: 1.58490 | time: 23.091s
| Adam | epoch: 024 | loss: 1.58490 - acc: 0.3778 | val_loss: 1.55587 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2700  | total loss: 1.62196 | time: 23.146s
| Adam | epoch: 025 | loss: 1.62196 - acc: 0.3482 | val_loss: 1.56034 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2808  | total loss: 1.65057 | time: 23.065s
| Adam | epoch: 026 | loss: 1.65057 - acc: 0.3017 | val_loss: 1.55578 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 2916  | total loss: 1.57437 | time: 23.172s
| Adam | epoch: 027 | loss: 1.57437 - acc: 0.3788 | val_loss: 1.55345 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3024  | total loss: 1.62038 | time: 23.148s
| Adam | epoch: 028 | loss: 1.62038 - acc: 0.3263 | val_loss: 1.55109 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3132  | total loss: 1.66184 | time: 23.146s
| Adam | epoch: 029 | loss: 1.66184 - acc: 0.2964 | val_loss: 1.55671 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3240  | total loss: 1.61595 | time: 23.097s
| Adam | epoch: 030 | loss: 1.61595 - acc: 0.3285 | val_loss: 1.54911 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3348  | total loss: 1.56937 | time: 23.173s
| Adam | epoch: 031 | loss: 1.56937 - acc: 0.3824 | val_loss: 1.55246 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3456  | total loss: 1.58940 | time: 23.135s
| Adam | epoch: 032 | loss: 1.58940 - acc: 0.3807 | val_loss: 1.54978 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3564  | total loss: 1.60405 | time: 23.121s
| Adam | epoch: 033 | loss: 1.60405 - acc: 0.3256 | val_loss: 1.55018 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3672  | total loss: 1.62598 | time: 23.118s
| Adam | epoch: 034 | loss: 1.62598 - acc: 0.3574 | val_loss: 1.55409 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3780  | total loss: 1.61213 | time: 23.135s
| Adam | epoch: 035 | loss: 1.61213 - acc: 0.3327 | val_loss: 1.54930 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3888  | total loss: 1.61198 | time: 23.153s
| Adam | epoch: 036 | loss: 1.61198 - acc: 0.3329 | val_loss: 1.54971 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 3996  | total loss: 1.59558 | time: 23.116s
| Adam | epoch: 037 | loss: 1.59558 - acc: 0.3246 | val_loss: 1.55151 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4104  | total loss: 1.60708 | time: 23.159s
| Adam | epoch: 038 | loss: 1.60708 - acc: 0.3296 | val_loss: 1.55194 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4212  | total loss: 1.62218 | time: 23.113s
| Adam | epoch: 039 | loss: 1.62218 - acc: 0.3231 | val_loss: 1.55265 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4320  | total loss: 1.59883 | time: 23.098s
| Adam | epoch: 040 | loss: 1.59883 - acc: 0.3368 | val_loss: 1.55443 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4428  | total loss: 1.61276 | time: 23.090s
| Adam | epoch: 041 | loss: 1.61276 - acc: 0.3228 | val_loss: 1.55418 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4536  | total loss: 1.61796 | time: 23.124s
| Adam | epoch: 042 | loss: 1.61796 - acc: 0.3214 | val_loss: 1.55476 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4644  | total loss: 1.62483 | time: 23.153s
| Adam | epoch: 043 | loss: 1.62483 - acc: 0.3064 | val_loss: 1.54920 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4752  | total loss: 1.59546 | time: 23.136s
| Adam | epoch: 044 | loss: 1.59546 - acc: 0.3521 | val_loss: 1.55300 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4860  | total loss: 1.57761 | time: 23.113s
| Adam | epoch: 045 | loss: 1.57761 - acc: 0.3661 | val_loss: 1.54798 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 4968  | total loss: 1.60061 | time: 23.147s
| Adam | epoch: 046 | loss: 1.60061 - acc: 0.3243 | val_loss: 1.54914 - val_acc: 0.3648 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5076  | total loss: 1.62083 | time: 23.078s
| Adam | epoch: 047 | loss: 1.62083 - acc: 0.3333 | val_loss: 1.55748 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5184  | total loss: 1.62112 | time: 23.085s
| Adam | epoch: 048 | loss: 1.62112 - acc: 0.3428 | val_loss: 1.55067 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5292  | total loss: 1.61035 | time: 23.134s
| Adam | epoch: 049 | loss: 1.61035 - acc: 0.3202 | val_loss: 1.55466 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5400  | total loss: 1.61005 | time: 23.041s
| Adam | epoch: 050 | loss: 1.61005 - acc: 0.3476 | val_loss: 1.55013 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5508  | total loss: 1.65784 | time: 23.132s
| Adam | epoch: 051 | loss: 1.65784 - acc: 0.2964 | val_loss: 1.55283 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5616  | total loss: 1.61933 | time: 23.154s
| Adam | epoch: 052 | loss: 1.61933 - acc: 0.3621 | val_loss: 1.54947 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5724  | total loss: 1.64852 | time: 23.136s
| Adam | epoch: 053 | loss: 1.64852 - acc: 0.3276 | val_loss: 1.55868 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5832  | total loss: 1.63303 | time: 23.082s
| Adam | epoch: 054 | loss: 1.63303 - acc: 0.3485 | val_loss: 1.55460 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 5940  | total loss: 1.62100 | time: 23.131s
| Adam | epoch: 055 | loss: 1.62100 - acc: 0.3315 | val_loss: 1.55287 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6048  | total loss: 1.63729 | time: 23.113s
| Adam | epoch: 056 | loss: 1.63729 - acc: 0.3352 | val_loss: 1.55203 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6156  | total loss: 1.61322 | time: 23.099s
| Adam | epoch: 057 | loss: 1.61322 - acc: 0.3523 | val_loss: 1.55010 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6264  | total loss: 1.63053 | time: 23.229s
| Adam | epoch: 058 | loss: 1.63053 - acc: 0.3458 | val_loss: 1.55101 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6372  | total loss: 1.61919 | time: 23.139s
| Adam | epoch: 059 | loss: 1.61919 - acc: 0.3301 | val_loss: 1.55738 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6480  | total loss: 1.62045 | time: 23.140s
| Adam | epoch: 060 | loss: 1.62045 - acc: 0.3323 | val_loss: 1.54972 - val_acc: 0.3675 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6588  | total loss: 1.60989 | time: 23.092s
| Adam | epoch: 061 | loss: 1.60989 - acc: 0.3329 | val_loss: 1.54422 - val_acc: 0.3675 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6696  | total loss: 1.57681 | time: 23.130s
| Adam | epoch: 062 | loss: 1.57681 - acc: 0.3645 | val_loss: 1.55056 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6804  | total loss: 1.59679 | time: 23.077s
| Adam | epoch: 063 | loss: 1.59679 - acc: 0.3414 | val_loss: 1.55124 - val_acc: 0.3648 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 6912  | total loss: 1.61817 | time: 23.112s
| Adam | epoch: 064 | loss: 1.61817 - acc: 0.3255 | val_loss: 1.55379 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7020  | total loss: 1.59236 | time: 23.129s
| Adam | epoch: 065 | loss: 1.59236 - acc: 0.3507 | val_loss: 1.54845 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7128  | total loss: 1.56535 | time: 23.128s
| Adam | epoch: 066 | loss: 1.56535 - acc: 0.3609 | val_loss: 1.55186 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7236  | total loss: 1.64607 | time: 23.143s
| Adam | epoch: 067 | loss: 1.64607 - acc: 0.3071 | val_loss: 1.55606 - val_acc: 0.3648 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7344  | total loss: 1.59705 | time: 23.078s
| Adam | epoch: 068 | loss: 1.59705 - acc: 0.3310 | val_loss: 1.54280 - val_acc: 0.3675 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7452  | total loss: 1.61485 | time: 23.206s
| Adam | epoch: 069 | loss: 1.61485 - acc: 0.3322 | val_loss: 1.54805 - val_acc: 0.3727 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7560  | total loss: 1.62926 | time: 23.146s
| Adam | epoch: 070 | loss: 1.62926 - acc: 0.3501 | val_loss: 1.54591 - val_acc: 0.3780 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7668  | total loss: 1.58160 | time: 23.157s
| Adam | epoch: 071 | loss: 1.58160 - acc: 0.3695 | val_loss: 1.54422 - val_acc: 0.3675 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7776  | total loss: 1.59722 | time: 23.098s
| Adam | epoch: 072 | loss: 1.59722 - acc: 0.3390 | val_loss: 1.55101 - val_acc: 0.3150 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7884  | total loss: 1.59312 | time: 23.137s
| Adam | epoch: 073 | loss: 1.59312 - acc: 0.3529 | val_loss: 1.54361 - val_acc: 0.3753 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 7992  | total loss: 1.58154 | time: 23.164s
| Adam | epoch: 074 | loss: 1.58154 - acc: 0.3541 | val_loss: 1.55355 - val_acc: 0.3622 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8100  | total loss: 1.58914 | time: 23.229s
| Adam | epoch: 075 | loss: 1.58914 - acc: 0.3619 | val_loss: 1.55766 - val_acc: 0.3701 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8208  | total loss: 1.58917 | time: 23.076s
| Adam | epoch: 076 | loss: 1.58917 - acc: 0.3509 | val_loss: 1.53788 - val_acc: 0.3911 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8316  | total loss: 1.55240 | time: 23.161s
| Adam | epoch: 077 | loss: 1.55240 - acc: 0.3960 | val_loss: 1.54516 - val_acc: 0.3806 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8424  | total loss: 1.49621 | time: 23.135s
| Adam | epoch: 078 | loss: 1.49621 - acc: 0.4557 | val_loss: 1.51654 - val_acc: 0.4199 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8532  | total loss: 1.57603 | time: 23.152s
| Adam | epoch: 079 | loss: 1.57603 - acc: 0.4267 | val_loss: 1.53633 - val_acc: 0.4016 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8640  | total loss: 1.55393 | time: 23.092s
| Adam | epoch: 080 | loss: 1.55393 - acc: 0.3920 | val_loss: 1.49921 - val_acc: 0.4199 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8748  | total loss: 1.58667 | time: 23.085s
| Adam | epoch: 081 | loss: 1.58667 - acc: 0.4102 | val_loss: 1.57121 - val_acc: 0.3753 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8856  | total loss: 1.59303 | time: 23.072s
| Adam | epoch: 082 | loss: 1.59303 - acc: 0.3796 | val_loss: 1.49650 - val_acc: 0.4698 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 8964  | total loss: 1.59077 | time: 23.153s
| Adam | epoch: 083 | loss: 1.59077 - acc: 0.3898 | val_loss: 1.49937 - val_acc: 0.4304 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9072  | total loss: 1.44855 | time: 23.146s
| Adam | epoch: 084 | loss: 1.44855 - acc: 0.4758 | val_loss: 1.40173 - val_acc: 0.5066 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9180  | total loss: 1.45341 | time: 23.130s
| Adam | epoch: 085 | loss: 1.45341 - acc: 0.4725 | val_loss: 1.40398 - val_acc: 0.5092 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9288  | total loss: 1.47674 | time: 23.176s
| Adam | epoch: 086 | loss: 1.47674 - acc: 0.4478 | val_loss: 1.38948 - val_acc: 0.5302 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9396  | total loss: 1.41203 | time: 23.173s
| Adam | epoch: 087 | loss: 1.41203 - acc: 0.5057 | val_loss: 1.37360 - val_acc: 0.5249 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9504  | total loss: 1.44195 | time: 23.128s
| Adam | epoch: 088 | loss: 1.44195 - acc: 0.4768 | val_loss: 1.33753 - val_acc: 0.5276 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9612  | total loss: 1.35213 | time: 23.145s
| Adam | epoch: 089 | loss: 1.35213 - acc: 0.5246 | val_loss: 1.30938 - val_acc: 0.5223 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9720  | total loss: 1.38399 | time: 23.104s
| Adam | epoch: 090 | loss: 1.38399 - acc: 0.4962 | val_loss: 1.30192 - val_acc: 0.5459 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9828  | total loss: 1.37805 | time: 23.107s
| Adam | epoch: 091 | loss: 1.37805 - acc: 0.4879 | val_loss: 1.33372 - val_acc: 0.5302 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 9936  | total loss: 1.36200 | time: 23.162s
| Adam | epoch: 092 | loss: 1.36200 - acc: 0.5016 | val_loss: 1.31287 - val_acc: 0.5459 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10044  | total loss: 1.31570 | time: 23.171s
| Adam | epoch: 093 | loss: 1.31570 - acc: 0.5255 | val_loss: 1.30148 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10152  | total loss: 1.35411 | time: 23.182s
| Adam | epoch: 094 | loss: 1.35411 - acc: 0.4980 | val_loss: 1.29287 - val_acc: 0.5381 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10260  | total loss: 1.28788 | time: 23.156s
| Adam | epoch: 095 | loss: 1.28788 - acc: 0.5512 | val_loss: 1.26874 - val_acc: 0.5643 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10368  | total loss: 1.31503 | time: 23.142s
| Adam | epoch: 096 | loss: 1.31503 - acc: 0.5031 | val_loss: 1.28827 - val_acc: 0.5538 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10476  | total loss: 1.26467 | time: 23.153s
| Adam | epoch: 097 | loss: 1.26467 - acc: 0.5396 | val_loss: 1.30382 - val_acc: 0.5564 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10584  | total loss: 1.23251 | time: 23.155s
| Adam | epoch: 098 | loss: 1.23251 - acc: 0.5584 | val_loss: 1.25337 - val_acc: 0.5669 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10692  | total loss: 1.26184 | time: 23.128s
| Adam | epoch: 099 | loss: 1.26184 - acc: 0.5481 | val_loss: 1.25046 - val_acc: 0.5696 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

Training Step: 10800  | total loss: 1.25251 | time: 23.170s
| Adam | epoch: 100 | loss: 1.25251 - acc: 0.5641 | val_loss: 1.24673 - val_acc: 0.5591 -- iter: 3431/3431 

 -------------------------------------------------------------------------------- 

