Training Step: 56  | total loss: 1.61760 | time: 7.931s
| Adam | epoch: 001 | loss: 1.61760 - acc: 0.3561 | val_loss: 1.63485 - val_acc: 0.3450 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 112  | total loss: 1.59993 | time: 6.965s
| Adam | epoch: 002 | loss: 1.59993 - acc: 0.3542 | val_loss: 1.62113 - val_acc: 0.3450 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 168  | total loss: 1.53235 | time: 6.897s
| Adam | epoch: 003 | loss: 1.53235 - acc: 0.4053 | val_loss: 1.58551 - val_acc: 0.3962 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 224  | total loss: 1.49425 | time: 6.954s
| Adam | epoch: 004 | loss: 1.49425 - acc: 0.4340 | val_loss: 1.55138 - val_acc: 0.4178 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 280  | total loss: 1.49454 | time: 6.937s
| Adam | epoch: 005 | loss: 1.49454 - acc: 0.4237 | val_loss: 1.52402 - val_acc: 0.4286 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 336  | total loss: 1.48329 | time: 6.913s
| Adam | epoch: 006 | loss: 1.48329 - acc: 0.4341 | val_loss: 1.49491 - val_acc: 0.4205 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 392  | total loss: 1.41192 | time: 6.933s
| Adam | epoch: 007 | loss: 1.41192 - acc: 0.4708 | val_loss: 1.46541 - val_acc: 0.4474 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 448  | total loss: 1.35258 | time: 6.926s
| Adam | epoch: 008 | loss: 1.35258 - acc: 0.5035 | val_loss: 1.43662 - val_acc: 0.4717 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 504  | total loss: 1.32978 | time: 6.902s
| Adam | epoch: 009 | loss: 1.32978 - acc: 0.4959 | val_loss: 1.41458 - val_acc: 0.4717 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 560  | total loss: 1.32103 | time: 6.903s
| Adam | epoch: 010 | loss: 1.32103 - acc: 0.5107 | val_loss: 1.37531 - val_acc: 0.4960 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 616  | total loss: 1.32148 | time: 7.080s
| Adam | epoch: 011 | loss: 1.32148 - acc: 0.5061 | val_loss: 1.35888 - val_acc: 0.4906 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 672  | total loss: 1.22182 | time: 6.935s
| Adam | epoch: 012 | loss: 1.22182 - acc: 0.5589 | val_loss: 1.33355 - val_acc: 0.5067 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 728  | total loss: 1.23546 | time: 6.933s
| Adam | epoch: 013 | loss: 1.23546 - acc: 0.5696 | val_loss: 1.32701 - val_acc: 0.5175 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 784  | total loss: 1.17857 | time: 6.946s
| Adam | epoch: 014 | loss: 1.17857 - acc: 0.5757 | val_loss: 1.30568 - val_acc: 0.5391 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 840  | total loss: 1.18310 | time: 6.910s
| Adam | epoch: 015 | loss: 1.18310 - acc: 0.5690 | val_loss: 1.28492 - val_acc: 0.5148 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 896  | total loss: 1.18127 | time: 6.929s
| Adam | epoch: 016 | loss: 1.18127 - acc: 0.5727 | val_loss: 1.27177 - val_acc: 0.5364 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 952  | total loss: 1.18148 | time: 6.936s
| Adam | epoch: 017 | loss: 1.18148 - acc: 0.5714 | val_loss: 1.27538 - val_acc: 0.5526 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1008  | total loss: 1.13824 | time: 6.906s
| Adam | epoch: 018 | loss: 1.13824 - acc: 0.5977 | val_loss: 1.29744 - val_acc: 0.5310 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1064  | total loss: 1.09075 | time: 6.932s
| Adam | epoch: 019 | loss: 1.09075 - acc: 0.6128 | val_loss: 1.26104 - val_acc: 0.5526 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1120  | total loss: 1.09677 | time: 6.921s
| Adam | epoch: 020 | loss: 1.09677 - acc: 0.6078 | val_loss: 1.25772 - val_acc: 0.5283 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1176  | total loss: 1.11535 | time: 6.904s
| Adam | epoch: 021 | loss: 1.11535 - acc: 0.6165 | val_loss: 1.25993 - val_acc: 0.5337 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1232  | total loss: 1.03467 | time: 6.896s
| Adam | epoch: 022 | loss: 1.03467 - acc: 0.6308 | val_loss: 1.26528 - val_acc: 0.5337 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1288  | total loss: 1.03759 | time: 6.923s
| Adam | epoch: 023 | loss: 1.03759 - acc: 0.6222 | val_loss: 1.27549 - val_acc: 0.5148 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1344  | total loss: 1.06915 | time: 6.937s
| Adam | epoch: 024 | loss: 1.06915 - acc: 0.6008 | val_loss: 1.28466 - val_acc: 0.5418 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1400  | total loss: 1.14907 | time: 6.915s
| Adam | epoch: 025 | loss: 1.14907 - acc: 0.5965 | val_loss: 1.26269 - val_acc: 0.5256 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1456  | total loss: 1.00740 | time: 6.929s
| Adam | epoch: 026 | loss: 1.00740 - acc: 0.6415 | val_loss: 1.25153 - val_acc: 0.5391 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1512  | total loss: 1.15854 | time: 6.917s
| Adam | epoch: 027 | loss: 1.15854 - acc: 0.5959 | val_loss: 1.26819 - val_acc: 0.5526 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1568  | total loss: 1.12683 | time: 6.919s
| Adam | epoch: 028 | loss: 1.12683 - acc: 0.6076 | val_loss: 1.26241 - val_acc: 0.5499 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1624  | total loss: 1.02403 | time: 6.961s
| Adam | epoch: 029 | loss: 1.02403 - acc: 0.6382 | val_loss: 1.26135 - val_acc: 0.5445 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1680  | total loss: 0.98964 | time: 6.921s
| Adam | epoch: 030 | loss: 0.98964 - acc: 0.6465 | val_loss: 1.26646 - val_acc: 0.5472 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1736  | total loss: 1.11256 | time: 6.927s
| Adam | epoch: 031 | loss: 1.11256 - acc: 0.6190 | val_loss: 1.25298 - val_acc: 0.5553 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1792  | total loss: 0.97881 | time: 6.932s
| Adam | epoch: 032 | loss: 0.97881 - acc: 0.6414 | val_loss: 1.24465 - val_acc: 0.5499 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1848  | total loss: 0.97467 | time: 6.932s
| Adam | epoch: 033 | loss: 0.97467 - acc: 0.6385 | val_loss: 1.27341 - val_acc: 0.5418 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1904  | total loss: 0.91893 | time: 6.917s
| Adam | epoch: 034 | loss: 0.91893 - acc: 0.6764 | val_loss: 1.25353 - val_acc: 0.5526 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1960  | total loss: 0.94535 | time: 6.940s
| Adam | epoch: 035 | loss: 0.94535 - acc: 0.6633 | val_loss: 1.26723 - val_acc: 0.5445 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2016  | total loss: 0.96811 | time: 6.933s
| Adam | epoch: 036 | loss: 0.96811 - acc: 0.6597 | val_loss: 1.27783 - val_acc: 0.5202 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2072  | total loss: 0.94148 | time: 6.938s
| Adam | epoch: 037 | loss: 0.94148 - acc: 0.6740 | val_loss: 1.28054 - val_acc: 0.5283 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2128  | total loss: 0.95778 | time: 6.923s
| Adam | epoch: 038 | loss: 0.95778 - acc: 0.6686 | val_loss: 1.29165 - val_acc: 0.5229 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2184  | total loss: 0.93585 | time: 6.916s
| Adam | epoch: 039 | loss: 0.93585 - acc: 0.6598 | val_loss: 1.29868 - val_acc: 0.5310 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2240  | total loss: 0.94608 | time: 6.909s
| Adam | epoch: 040 | loss: 0.94608 - acc: 0.6467 | val_loss: 1.29128 - val_acc: 0.5256 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2296  | total loss: 0.92870 | time: 6.907s
| Adam | epoch: 041 | loss: 0.92870 - acc: 0.6683 | val_loss: 1.27750 - val_acc: 0.5391 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2352  | total loss: 0.91038 | time: 6.943s
| Adam | epoch: 042 | loss: 0.91038 - acc: 0.6747 | val_loss: 1.28012 - val_acc: 0.5526 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2408  | total loss: 0.91073 | time: 6.924s
| Adam | epoch: 043 | loss: 0.91073 - acc: 0.6908 | val_loss: 1.29835 - val_acc: 0.5229 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2464  | total loss: 0.89658 | time: 6.919s
| Adam | epoch: 044 | loss: 0.89658 - acc: 0.6805 | val_loss: 1.28586 - val_acc: 0.5445 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2520  | total loss: 0.87097 | time: 6.917s
| Adam | epoch: 045 | loss: 0.87097 - acc: 0.6934 | val_loss: 1.28461 - val_acc: 0.5445 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2576  | total loss: 0.88496 | time: 6.911s
| Adam | epoch: 046 | loss: 0.88496 - acc: 0.6749 | val_loss: 1.30571 - val_acc: 0.5229 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2632  | total loss: 0.85028 | time: 6.921s
| Adam | epoch: 047 | loss: 0.85028 - acc: 0.6957 | val_loss: 1.27845 - val_acc: 0.5310 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2688  | total loss: 0.81995 | time: 6.953s
| Adam | epoch: 048 | loss: 0.81995 - acc: 0.7168 | val_loss: 1.30209 - val_acc: 0.5418 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2744  | total loss: 0.83057 | time: 6.914s
| Adam | epoch: 049 | loss: 0.83057 - acc: 0.7081 | val_loss: 1.30946 - val_acc: 0.5391 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2800  | total loss: 0.81501 | time: 6.934s
| Adam | epoch: 050 | loss: 0.81501 - acc: 0.7079 | val_loss: 1.30724 - val_acc: 0.5472 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2856  | total loss: 0.85965 | time: 6.935s
| Adam | epoch: 051 | loss: 0.85965 - acc: 0.6977 | val_loss: 1.31215 - val_acc: 0.5445 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2912  | total loss: 0.84180 | time: 6.913s
| Adam | epoch: 052 | loss: 0.84180 - acc: 0.6926 | val_loss: 1.35450 - val_acc: 0.5256 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2968  | total loss: 0.76660 | time: 6.908s
| Adam | epoch: 053 | loss: 0.76660 - acc: 0.7403 | val_loss: 1.31349 - val_acc: 0.5580 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3024  | total loss: 0.82148 | time: 6.921s
| Adam | epoch: 054 | loss: 0.82148 - acc: 0.7221 | val_loss: 1.30795 - val_acc: 0.5391 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3080  | total loss: 0.82766 | time: 6.921s
| Adam | epoch: 055 | loss: 0.82766 - acc: 0.7013 | val_loss: 1.34255 - val_acc: 0.5472 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3136  | total loss: 0.80096 | time: 6.909s
| Adam | epoch: 056 | loss: 0.80096 - acc: 0.7185 | val_loss: 1.32757 - val_acc: 0.5418 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3192  | total loss: 0.79509 | time: 6.925s
| Adam | epoch: 057 | loss: 0.79509 - acc: 0.7072 | val_loss: 1.32454 - val_acc: 0.5526 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3248  | total loss: 0.77141 | time: 6.962s
| Adam | epoch: 058 | loss: 0.77141 - acc: 0.7261 | val_loss: 1.33779 - val_acc: 0.5310 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3304  | total loss: 0.75588 | time: 6.979s
| Adam | epoch: 059 | loss: 0.75588 - acc: 0.7355 | val_loss: 1.34973 - val_acc: 0.5580 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3360  | total loss: 0.72770 | time: 6.932s
| Adam | epoch: 060 | loss: 0.72770 - acc: 0.7375 | val_loss: 1.34321 - val_acc: 0.5418 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3416  | total loss: 0.75426 | time: 6.924s
| Adam | epoch: 061 | loss: 0.75426 - acc: 0.7285 | val_loss: 1.36864 - val_acc: 0.5364 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3472  | total loss: 0.73163 | time: 6.928s
| Adam | epoch: 062 | loss: 0.73163 - acc: 0.7534 | val_loss: 1.36072 - val_acc: 0.5526 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3528  | total loss: 0.75012 | time: 6.922s
| Adam | epoch: 063 | loss: 0.75012 - acc: 0.7385 | val_loss: 1.35240 - val_acc: 0.5418 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3584  | total loss: 0.82676 | time: 6.907s
| Adam | epoch: 064 | loss: 0.82676 - acc: 0.7069 | val_loss: 1.35434 - val_acc: 0.5391 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3640  | total loss: 0.75929 | time: 6.905s
| Adam | epoch: 065 | loss: 0.75929 - acc: 0.7349 | val_loss: 1.35465 - val_acc: 0.5633 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3696  | total loss: 0.70825 | time: 6.908s
| Adam | epoch: 066 | loss: 0.70825 - acc: 0.7471 | val_loss: 1.35562 - val_acc: 0.5553 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3752  | total loss: 0.72321 | time: 6.951s
| Adam | epoch: 067 | loss: 0.72321 - acc: 0.7475 | val_loss: 1.37394 - val_acc: 0.5526 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3808  | total loss: 0.74189 | time: 6.957s
| Adam | epoch: 068 | loss: 0.74189 - acc: 0.7528 | val_loss: 1.35974 - val_acc: 0.5606 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3864  | total loss: 0.72068 | time: 6.909s
| Adam | epoch: 069 | loss: 0.72068 - acc: 0.7521 | val_loss: 1.36578 - val_acc: 0.5553 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3920  | total loss: 0.74280 | time: 6.905s
| Adam | epoch: 070 | loss: 0.74280 - acc: 0.7337 | val_loss: 1.36999 - val_acc: 0.5364 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3976  | total loss: 0.72870 | time: 6.920s
| Adam | epoch: 071 | loss: 0.72870 - acc: 0.7515 | val_loss: 1.41322 - val_acc: 0.5256 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4032  | total loss: 0.74317 | time: 6.927s
| Adam | epoch: 072 | loss: 0.74317 - acc: 0.7363 | val_loss: 1.37223 - val_acc: 0.5499 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4088  | total loss: 0.75317 | time: 6.935s
| Adam | epoch: 073 | loss: 0.75317 - acc: 0.7481 | val_loss: 1.40532 - val_acc: 0.5526 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4144  | total loss: 0.74221 | time: 6.917s
| Adam | epoch: 074 | loss: 0.74221 - acc: 0.7531 | val_loss: 1.38370 - val_acc: 0.5283 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4200  | total loss: 0.70907 | time: 6.937s
| Adam | epoch: 075 | loss: 0.70907 - acc: 0.7473 | val_loss: 1.38631 - val_acc: 0.5418 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4256  | total loss: 0.71801 | time: 6.911s
| Adam | epoch: 076 | loss: 0.71801 - acc: 0.7422 | val_loss: 1.40690 - val_acc: 0.5283 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4312  | total loss: 0.67982 | time: 6.942s
| Adam | epoch: 077 | loss: 0.67982 - acc: 0.7584 | val_loss: 1.43748 - val_acc: 0.5418 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4368  | total loss: 0.77852 | time: 6.939s
| Adam | epoch: 078 | loss: 0.77852 - acc: 0.7447 | val_loss: 1.41751 - val_acc: 0.5391 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4424  | total loss: 0.79542 | time: 6.951s
| Adam | epoch: 079 | loss: 0.79542 - acc: 0.7319 | val_loss: 1.45491 - val_acc: 0.5094 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4480  | total loss: 0.68340 | time: 6.897s
| Adam | epoch: 080 | loss: 0.68340 - acc: 0.7493 | val_loss: 1.47722 - val_acc: 0.5202 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4536  | total loss: 0.66949 | time: 6.882s
| Adam | epoch: 081 | loss: 0.66949 - acc: 0.7585 | val_loss: 1.44521 - val_acc: 0.5310 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4592  | total loss: 0.67690 | time: 6.910s
| Adam | epoch: 082 | loss: 0.67690 - acc: 0.7736 | val_loss: 1.43907 - val_acc: 0.5472 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4648  | total loss: 0.64584 | time: 6.915s
| Adam | epoch: 083 | loss: 0.64584 - acc: 0.7685 | val_loss: 1.43157 - val_acc: 0.5229 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4704  | total loss: 0.70311 | time: 6.921s
| Adam | epoch: 084 | loss: 0.70311 - acc: 0.7384 | val_loss: 1.43529 - val_acc: 0.5364 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4760  | total loss: 0.66183 | time: 6.944s
| Adam | epoch: 085 | loss: 0.66183 - acc: 0.7628 | val_loss: 1.48535 - val_acc: 0.5229 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4816  | total loss: 0.69249 | time: 6.941s
| Adam | epoch: 086 | loss: 0.69249 - acc: 0.7579 | val_loss: 1.47469 - val_acc: 0.5256 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4872  | total loss: 0.65134 | time: 6.919s
| Adam | epoch: 087 | loss: 0.65134 - acc: 0.7618 | val_loss: 1.48755 - val_acc: 0.5175 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4928  | total loss: 0.93439 | time: 6.908s
| Adam | epoch: 088 | loss: 0.93439 - acc: 0.7139 | val_loss: 1.48063 - val_acc: 0.5175 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4984  | total loss: 0.73092 | time: 6.927s
| Adam | epoch: 089 | loss: 0.73092 - acc: 0.7291 | val_loss: 1.45106 - val_acc: 0.5445 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5040  | total loss: 0.67389 | time: 6.900s
| Adam | epoch: 090 | loss: 0.67389 - acc: 0.7630 | val_loss: 1.43100 - val_acc: 0.5499 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5096  | total loss: 0.65490 | time: 6.905s
| Adam | epoch: 091 | loss: 0.65490 - acc: 0.7678 | val_loss: 1.47292 - val_acc: 0.5229 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5152  | total loss: 0.66056 | time: 6.950s
| Adam | epoch: 092 | loss: 0.66056 - acc: 0.7633 | val_loss: 1.46434 - val_acc: 0.5229 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5208  | total loss: 0.65772 | time: 6.927s
| Adam | epoch: 093 | loss: 0.65772 - acc: 0.7701 | val_loss: 1.47121 - val_acc: 0.5364 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5264  | total loss: 0.66060 | time: 6.885s
| Adam | epoch: 094 | loss: 0.66060 - acc: 0.7516 | val_loss: 1.47135 - val_acc: 0.5337 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5320  | total loss: 0.67325 | time: 6.931s
| Adam | epoch: 095 | loss: 0.67325 - acc: 0.7564 | val_loss: 1.49262 - val_acc: 0.5445 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5376  | total loss: 0.65586 | time: 6.909s
| Adam | epoch: 096 | loss: 0.65586 - acc: 0.7761 | val_loss: 1.48975 - val_acc: 0.5472 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5432  | total loss: 0.63884 | time: 6.913s
| Adam | epoch: 097 | loss: 0.63884 - acc: 0.7751 | val_loss: 1.52134 - val_acc: 0.5337 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5488  | total loss: 0.63886 | time: 6.930s
| Adam | epoch: 098 | loss: 0.63886 - acc: 0.7621 | val_loss: 1.51373 - val_acc: 0.5445 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5544  | total loss: 0.62616 | time: 6.932s
| Adam | epoch: 099 | loss: 0.62616 - acc: 0.7859 | val_loss: 1.52184 - val_acc: 0.5256 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5600  | total loss: 0.66034 | time: 6.942s
| Adam | epoch: 100 | loss: 0.66034 - acc: 0.7690 | val_loss: 1.54495 - val_acc: 0.5175 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

