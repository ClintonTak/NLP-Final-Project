Training Step: 105  | total loss: 1.56241 | time: 66.937s
| Adam | epoch: 001 | loss: 1.56241 - acc: 0.3158 | val_loss: 1.66801 - val_acc: 0.3477 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 210  | total loss: 1.55545 | time: 22.348s
| Adam | epoch: 002 | loss: 1.55545 - acc: 0.3693 | val_loss: 1.65476 - val_acc: 0.3827 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 315  | total loss: 1.61810 | time: 22.465s
| Adam | epoch: 003 | loss: 1.61810 - acc: 0.3526 | val_loss: 1.64637 - val_acc: 0.3774 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 420  | total loss: 1.60550 | time: 22.662s
| Adam | epoch: 004 | loss: 1.60550 - acc: 0.3458 | val_loss: 1.65259 - val_acc: 0.3693 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 525  | total loss: 1.58772 | time: 22.593s
| Adam | epoch: 005 | loss: 1.58772 - acc: 0.3656 | val_loss: 1.64798 - val_acc: 0.3720 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 630  | total loss: 1.56974 | time: 22.525s
| Adam | epoch: 006 | loss: 1.56974 - acc: 0.3862 | val_loss: 1.64541 - val_acc: 0.3612 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 735  | total loss: 1.58767 | time: 22.350s
| Adam | epoch: 007 | loss: 1.58767 - acc: 0.3646 | val_loss: 1.65112 - val_acc: 0.3693 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 840  | total loss: 1.56128 | time: 22.497s
| Adam | epoch: 008 | loss: 1.56128 - acc: 0.3741 | val_loss: 1.65957 - val_acc: 0.3666 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 945  | total loss: 1.56467 | time: 22.575s
| Adam | epoch: 009 | loss: 1.56467 - acc: 0.3959 | val_loss: 1.67295 - val_acc: 0.3558 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1050  | total loss: 1.55745 | time: 22.671s
| Adam | epoch: 010 | loss: 1.55745 - acc: 0.3989 | val_loss: 1.65737 - val_acc: 0.3666 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1155  | total loss: 1.54626 | time: 22.426s
| Adam | epoch: 011 | loss: 1.54626 - acc: 0.3964 | val_loss: 1.66768 - val_acc: 0.3531 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1260  | total loss: 1.57562 | time: 22.433s
| Adam | epoch: 012 | loss: 1.57562 - acc: 0.3726 | val_loss: 1.67160 - val_acc: 0.3585 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1365  | total loss: 1.55822 | time: 22.548s
| Adam | epoch: 013 | loss: 1.55822 - acc: 0.3982 | val_loss: 1.67265 - val_acc: 0.3504 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1470  | total loss: 1.54226 | time: 22.676s
| Adam | epoch: 014 | loss: 1.54226 - acc: 0.3939 | val_loss: 1.67141 - val_acc: 0.3639 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1575  | total loss: 1.52151 | time: 22.492s
| Adam | epoch: 015 | loss: 1.52151 - acc: 0.4170 | val_loss: 1.68512 - val_acc: 0.3612 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1680  | total loss: 1.52871 | time: 22.348s
| Adam | epoch: 016 | loss: 1.52871 - acc: 0.4017 | val_loss: 1.67804 - val_acc: 0.3693 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1785  | total loss: 1.50515 | time: 22.433s
| Adam | epoch: 017 | loss: 1.50515 - acc: 0.4254 | val_loss: 1.68892 - val_acc: 0.3693 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1890  | total loss: 1.57279 | time: 22.371s
| Adam | epoch: 018 | loss: 1.57279 - acc: 0.4007 | val_loss: 1.68667 - val_acc: 0.3639 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 1995  | total loss: 1.46780 | time: 22.649s
| Adam | epoch: 019 | loss: 1.46780 - acc: 0.4438 | val_loss: 1.69617 - val_acc: 0.3585 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2100  | total loss: 1.51646 | time: 22.589s
| Adam | epoch: 020 | loss: 1.51646 - acc: 0.4261 | val_loss: 1.68957 - val_acc: 0.3558 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2205  | total loss: 1.45844 | time: 22.399s
| Adam | epoch: 021 | loss: 1.45844 - acc: 0.4560 | val_loss: 1.70699 - val_acc: 0.3639 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2310  | total loss: 1.52462 | time: 22.371s
| Adam | epoch: 022 | loss: 1.52462 - acc: 0.4009 | val_loss: 1.69230 - val_acc: 0.3747 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2415  | total loss: 1.45679 | time: 22.451s
| Adam | epoch: 023 | loss: 1.45679 - acc: 0.4513 | val_loss: 1.74210 - val_acc: 0.2992 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2520  | total loss: 1.47250 | time: 22.547s
| Adam | epoch: 024 | loss: 1.47250 - acc: 0.4155 | val_loss: 1.70303 - val_acc: 0.3315 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2625  | total loss: 1.44275 | time: 22.447s
| Adam | epoch: 025 | loss: 1.44275 - acc: 0.4352 | val_loss: 1.66910 - val_acc: 0.3612 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2730  | total loss: 1.50156 | time: 22.416s
| Adam | epoch: 026 | loss: 1.50156 - acc: 0.4433 | val_loss: 1.71743 - val_acc: 0.3315 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2835  | total loss: 1.40750 | time: 22.576s
| Adam | epoch: 027 | loss: 1.40750 - acc: 0.4867 | val_loss: 1.66922 - val_acc: 0.3585 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 2940  | total loss: 1.42679 | time: 22.385s
| Adam | epoch: 028 | loss: 1.42679 - acc: 0.4295 | val_loss: 1.67606 - val_acc: 0.3558 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3045  | total loss: 1.44316 | time: 22.672s
| Adam | epoch: 029 | loss: 1.44316 - acc: 0.4563 | val_loss: 1.69390 - val_acc: 0.3531 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3150  | total loss: 1.48820 | time: 22.492s
| Adam | epoch: 030 | loss: 1.48820 - acc: 0.4362 | val_loss: 1.58800 - val_acc: 0.4097 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3255  | total loss: 1.36269 | time: 22.451s
| Adam | epoch: 031 | loss: 1.36269 - acc: 0.4950 | val_loss: 1.64219 - val_acc: 0.3854 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3360  | total loss: 1.42692 | time: 22.518s
| Adam | epoch: 032 | loss: 1.42692 - acc: 0.4735 | val_loss: 1.64850 - val_acc: 0.3666 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3465  | total loss: 1.34021 | time: 22.588s
| Adam | epoch: 033 | loss: 1.34021 - acc: 0.4995 | val_loss: 1.64510 - val_acc: 0.3854 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3570  | total loss: 1.37743 | time: 22.473s
| Adam | epoch: 034 | loss: 1.37743 - acc: 0.5077 | val_loss: 1.66515 - val_acc: 0.4070 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3675  | total loss: 1.35307 | time: 22.415s
| Adam | epoch: 035 | loss: 1.35307 - acc: 0.5070 | val_loss: 1.65624 - val_acc: 0.4043 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3780  | total loss: 1.36046 | time: 22.469s
| Adam | epoch: 036 | loss: 1.36046 - acc: 0.4921 | val_loss: 1.65260 - val_acc: 0.4043 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3885  | total loss: 1.32582 | time: 22.525s
| Adam | epoch: 037 | loss: 1.32582 - acc: 0.5041 | val_loss: 1.64816 - val_acc: 0.4097 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 3990  | total loss: 1.31892 | time: 22.383s
| Adam | epoch: 038 | loss: 1.31892 - acc: 0.5204 | val_loss: 1.62598 - val_acc: 0.4205 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4095  | total loss: 1.32088 | time: 22.350s
| Adam | epoch: 039 | loss: 1.32088 - acc: 0.4927 | val_loss: 1.66956 - val_acc: 0.3827 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4200  | total loss: 1.27745 | time: 22.604s
| Adam | epoch: 040 | loss: 1.27745 - acc: 0.5318 | val_loss: 1.62225 - val_acc: 0.4178 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4305  | total loss: 1.23541 | time: 22.801s
| Adam | epoch: 041 | loss: 1.23541 - acc: 0.5598 | val_loss: 1.64219 - val_acc: 0.4151 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4410  | total loss: 1.26100 | time: 22.494s
| Adam | epoch: 042 | loss: 1.26100 - acc: 0.5427 | val_loss: 1.65804 - val_acc: 0.3854 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4515  | total loss: 1.22822 | time: 22.428s
| Adam | epoch: 043 | loss: 1.22822 - acc: 0.5486 | val_loss: 1.71006 - val_acc: 0.3693 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4620  | total loss: 1.27608 | time: 22.496s
| Adam | epoch: 044 | loss: 1.27608 - acc: 0.5124 | val_loss: 1.65472 - val_acc: 0.3935 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4725  | total loss: 1.29499 | time: 22.426s
| Adam | epoch: 045 | loss: 1.29499 - acc: 0.5223 | val_loss: 1.70818 - val_acc: 0.3639 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4830  | total loss: 1.29136 | time: 22.478s
| Adam | epoch: 046 | loss: 1.29136 - acc: 0.5289 | val_loss: 1.66187 - val_acc: 0.4313 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 4935  | total loss: 1.22171 | time: 22.337s
| Adam | epoch: 047 | loss: 1.22171 - acc: 0.5611 | val_loss: 1.68253 - val_acc: 0.4367 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5040  | total loss: 1.16585 | time: 22.399s
| Adam | epoch: 048 | loss: 1.16585 - acc: 0.5815 | val_loss: 1.72807 - val_acc: 0.3585 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5145  | total loss: 1.19094 | time: 22.484s
| Adam | epoch: 049 | loss: 1.19094 - acc: 0.5570 | val_loss: 1.74665 - val_acc: 0.4097 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5250  | total loss: 1.14027 | time: 22.475s
| Adam | epoch: 050 | loss: 1.14027 - acc: 0.5894 | val_loss: 1.68392 - val_acc: 0.4178 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5355  | total loss: 1.16815 | time: 22.427s
| Adam | epoch: 051 | loss: 1.16815 - acc: 0.5855 | val_loss: 1.64907 - val_acc: 0.4259 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5460  | total loss: 1.15944 | time: 22.424s
| Adam | epoch: 052 | loss: 1.15944 - acc: 0.5847 | val_loss: 1.73879 - val_acc: 0.3801 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5565  | total loss: 1.20648 | time: 22.413s
| Adam | epoch: 053 | loss: 1.20648 - acc: 0.5618 | val_loss: 1.70618 - val_acc: 0.3881 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5670  | total loss: 1.13176 | time: 22.377s
| Adam | epoch: 054 | loss: 1.13176 - acc: 0.5626 | val_loss: 1.76867 - val_acc: 0.3962 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5775  | total loss: 1.11532 | time: 22.428s
| Adam | epoch: 055 | loss: 1.11532 - acc: 0.5955 | val_loss: 1.73537 - val_acc: 0.4043 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5880  | total loss: 1.15639 | time: 22.443s
| Adam | epoch: 056 | loss: 1.15639 - acc: 0.5831 | val_loss: 1.76035 - val_acc: 0.4178 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 5985  | total loss: 1.11719 | time: 22.423s
| Adam | epoch: 057 | loss: 1.11719 - acc: 0.5907 | val_loss: 1.74201 - val_acc: 0.4178 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6090  | total loss: 1.18513 | time: 22.401s
| Adam | epoch: 058 | loss: 1.18513 - acc: 0.5585 | val_loss: 1.76374 - val_acc: 0.3908 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6195  | total loss: 1.15213 | time: 22.389s
| Adam | epoch: 059 | loss: 1.15213 - acc: 0.5942 | val_loss: 1.73740 - val_acc: 0.4232 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6300  | total loss: 1.04243 | time: 22.458s
| Adam | epoch: 060 | loss: 1.04243 - acc: 0.6099 | val_loss: 1.71637 - val_acc: 0.4394 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6405  | total loss: 1.15094 | time: 22.545s
| Adam | epoch: 061 | loss: 1.15094 - acc: 0.5569 | val_loss: 1.75171 - val_acc: 0.4070 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6510  | total loss: 1.09603 | time: 22.530s
| Adam | epoch: 062 | loss: 1.09603 - acc: 0.6018 | val_loss: 1.76918 - val_acc: 0.4124 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6615  | total loss: 1.03386 | time: 22.428s
| Adam | epoch: 063 | loss: 1.03386 - acc: 0.6330 | val_loss: 1.80393 - val_acc: 0.4340 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6720  | total loss: 1.10665 | time: 22.448s
| Adam | epoch: 064 | loss: 1.10665 - acc: 0.5994 | val_loss: 1.75681 - val_acc: 0.4259 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6825  | total loss: 1.00836 | time: 22.560s
| Adam | epoch: 065 | loss: 1.00836 - acc: 0.6222 | val_loss: 1.81711 - val_acc: 0.4070 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 6930  | total loss: 0.99394 | time: 22.530s
| Adam | epoch: 066 | loss: 0.99394 - acc: 0.6531 | val_loss: 1.77532 - val_acc: 0.4340 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7035  | total loss: 1.05776 | time: 22.414s
| Adam | epoch: 067 | loss: 1.05776 - acc: 0.6051 | val_loss: 1.79366 - val_acc: 0.4447 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7140  | total loss: 1.03651 | time: 22.457s
| Adam | epoch: 068 | loss: 1.03651 - acc: 0.6294 | val_loss: 1.79051 - val_acc: 0.4286 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7245  | total loss: 1.03891 | time: 22.422s
| Adam | epoch: 069 | loss: 1.03891 - acc: 0.6202 | val_loss: 1.86766 - val_acc: 0.4097 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7350  | total loss: 0.98440 | time: 22.408s
| Adam | epoch: 070 | loss: 0.98440 - acc: 0.6367 | val_loss: 1.82170 - val_acc: 0.4205 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7455  | total loss: 1.00917 | time: 22.465s
| Adam | epoch: 071 | loss: 1.00917 - acc: 0.6437 | val_loss: 1.85015 - val_acc: 0.4124 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7560  | total loss: 1.05849 | time: 22.328s
| Adam | epoch: 072 | loss: 1.05849 - acc: 0.6262 | val_loss: 1.78228 - val_acc: 0.4259 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7665  | total loss: 0.97058 | time: 22.409s
| Adam | epoch: 073 | loss: 0.97058 - acc: 0.6439 | val_loss: 1.84114 - val_acc: 0.4097 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7770  | total loss: 0.90734 | time: 22.267s
| Adam | epoch: 074 | loss: 0.90734 - acc: 0.6852 | val_loss: 1.86403 - val_acc: 0.4178 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7875  | total loss: 0.93342 | time: 22.525s
| Adam | epoch: 075 | loss: 0.93342 - acc: 0.6566 | val_loss: 1.88879 - val_acc: 0.4286 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 7980  | total loss: 1.02153 | time: 22.384s
| Adam | epoch: 076 | loss: 1.02153 - acc: 0.6163 | val_loss: 1.81817 - val_acc: 0.4420 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8085  | total loss: 0.89871 | time: 22.521s
| Adam | epoch: 077 | loss: 0.89871 - acc: 0.6686 | val_loss: 1.90425 - val_acc: 0.4178 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8190  | total loss: 0.91268 | time: 22.408s
| Adam | epoch: 078 | loss: 0.91268 - acc: 0.6519 | val_loss: 1.91645 - val_acc: 0.4070 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8295  | total loss: 0.93399 | time: 22.570s
| Adam | epoch: 079 | loss: 0.93399 - acc: 0.6674 | val_loss: 1.90286 - val_acc: 0.4178 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8400  | total loss: 0.95727 | time: 22.460s
| Adam | epoch: 080 | loss: 0.95727 - acc: 0.6511 | val_loss: 1.86912 - val_acc: 0.4124 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8505  | total loss: 0.91859 | time: 22.465s
| Adam | epoch: 081 | loss: 0.91859 - acc: 0.6422 | val_loss: 1.94240 - val_acc: 0.4367 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8610  | total loss: 0.88771 | time: 22.497s
| Adam | epoch: 082 | loss: 0.88771 - acc: 0.6922 | val_loss: 1.94470 - val_acc: 0.4259 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8715  | total loss: 0.88806 | time: 22.543s
| Adam | epoch: 083 | loss: 0.88806 - acc: 0.6882 | val_loss: 1.91466 - val_acc: 0.4394 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8820  | total loss: 0.84433 | time: 22.448s
| Adam | epoch: 084 | loss: 0.84433 - acc: 0.6872 | val_loss: 1.89179 - val_acc: 0.4259 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 8925  | total loss: 0.87664 | time: 22.542s
| Adam | epoch: 085 | loss: 0.87664 - acc: 0.6988 | val_loss: 2.01759 - val_acc: 0.4286 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9030  | total loss: 0.92273 | time: 22.455s
| Adam | epoch: 086 | loss: 0.92273 - acc: 0.6816 | val_loss: 2.00835 - val_acc: 0.4043 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9135  | total loss: 0.89394 | time: 22.409s
| Adam | epoch: 087 | loss: 0.89394 - acc: 0.6731 | val_loss: 2.00413 - val_acc: 0.3962 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9240  | total loss: 0.83301 | time: 22.354s
| Adam | epoch: 088 | loss: 0.83301 - acc: 0.6993 | val_loss: 2.04364 - val_acc: 0.4016 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9345  | total loss: 0.80986 | time: 22.535s
| Adam | epoch: 089 | loss: 0.80986 - acc: 0.7057 | val_loss: 2.04380 - val_acc: 0.4016 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9450  | total loss: 0.87085 | time: 22.602s
| Adam | epoch: 090 | loss: 0.87085 - acc: 0.6751 | val_loss: 2.01312 - val_acc: 0.4097 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9555  | total loss: 0.82766 | time: 22.340s
| Adam | epoch: 091 | loss: 0.82766 - acc: 0.6824 | val_loss: 2.06268 - val_acc: 0.4097 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9660  | total loss: 0.81020 | time: 22.427s
| Adam | epoch: 092 | loss: 0.81020 - acc: 0.6958 | val_loss: 1.96924 - val_acc: 0.4313 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9765  | total loss: 0.84533 | time: 22.368s
| Adam | epoch: 093 | loss: 0.84533 - acc: 0.7187 | val_loss: 2.00415 - val_acc: 0.4070 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9870  | total loss: 0.74224 | time: 22.423s
| Adam | epoch: 094 | loss: 0.74224 - acc: 0.7245 | val_loss: 2.09949 - val_acc: 0.4205 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 9975  | total loss: 0.76500 | time: 22.510s
| Adam | epoch: 095 | loss: 0.76500 - acc: 0.7134 | val_loss: 2.13529 - val_acc: 0.4124 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 10080  | total loss: 0.80743 | time: 22.406s
| Adam | epoch: 096 | loss: 0.80743 - acc: 0.7166 | val_loss: 2.05003 - val_acc: 0.4097 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 10185  | total loss: 0.81919 | time: 22.477s
| Adam | epoch: 097 | loss: 0.81919 - acc: 0.6940 | val_loss: 2.09181 - val_acc: 0.4097 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 10290  | total loss: 0.71077 | time: 22.443s
| Adam | epoch: 098 | loss: 0.71077 - acc: 0.7422 | val_loss: 2.20869 - val_acc: 0.3774 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 10395  | total loss: 0.75284 | time: 22.429s
| Adam | epoch: 099 | loss: 0.75284 - acc: 0.7428 | val_loss: 2.15092 - val_acc: 0.3774 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

Training Step: 10500  | total loss: 0.68841 | time: 22.411s
| Adam | epoch: 100 | loss: 0.68841 - acc: 0.7697 | val_loss: 2.20487 - val_acc: 0.3962 -- iter: 3341/3341 

 -------------------------------------------------------------------------------- 

